{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NvRrg8YvTPT"
   },
   "source": [
    "# **Project: Multitask Learning for Geometric Shape Classification and Counting**\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "In this project, you will design, implement, and evaluate a **multitask neural network** that performs **two tasks simultaneously**:\n",
    "\n",
    "1. **Classification** – identify which pair of geometric shape types appears in a 28×28 binary image (135 possible configurations).\n",
    "2. **Regression** – predict how many shapes of each type are present (6 regression targets).\n",
    "\n",
    "This project focuses on **multi-task learning**, i.e., using one shared model to learn several related tasks at once. You will compare how adding an auxiliary task affects performance and training dynamics.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Dataset\n",
    "\n",
    "You will use the **Geometric Shape Numbers (GSN)** dataset:\n",
    "\n",
    "```bash\n",
    "!wget https://github.com/marcin119a/data/raw/refs/heads/main/data_gsn.zip\n",
    "!unzip data_gsn.zip &> /dev/null\n",
    "!rm data_gsn.zip\n",
    "```\n",
    "\n",
    "This will create a directory `data/` containing:\n",
    "\n",
    "* **10,000 images** (28×28x1, grayscale)\n",
    "* **labels.csv** – counts of each of six shape types per image\n",
    "\n",
    "Each image contains exactly **two types** of geometric figures (out of six) and **10 shapes total**.\n",
    "\n",
    "**Shape classes:**\n",
    "\n",
    "| Index | Shape type     |\n",
    "| ----: | -------------- |\n",
    "|     0 | square         |\n",
    "|     1 | circle         |\n",
    "|     2 | triangle up    |\n",
    "|     3 | triangle right |\n",
    "|     4 | triangle down  |\n",
    "|     5 | triangle left  |\n",
    "\n",
    "Example row from `labels.csv`:\n",
    "\n",
    "```\n",
    "name,squares,circles,up,right,down,left\n",
    "img_00000.png,0,0,0,4,0,6\n",
    "```\n",
    "\n",
    "Here, the image contains **4 right-pointing triangles** and **6 left-pointing triangles**.\n",
    "\n",
    "**Split:**\n",
    "\n",
    "* Training: first 9,000 samples\n",
    "* Validation: last 1,000 samples\n",
    "\n",
    "Examples:\n",
    "![example.png](data:image/png;base64,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)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Tasks and objectives\n",
    "\n",
    "You must design a **multitask deep learning system** that:\n",
    "\n",
    "1. **Classifies** each image into one of **135 possible configurations**, representing:\n",
    "\n",
    "   * which **two shape classes** appear, and\n",
    "   * how their counts (1–9) sum to 10.\n",
    "\n",
    "   → Example: \"3 circles + 7 squares\" is one configuration class.\n",
    "\n",
    "2. **Regresses** the number of shapes of each type (a 6-dimensional real-valued output).\n",
    "\n",
    "3. Combines both objectives in a **joint loss** function (Hint: losses are implemented in PyTorch):\n",
    "\n",
    "\n",
    "$$ Loss = \\text{NLLLoss(classification)} + \\lambda_{\\text{cnt}} \\cdot \\text{SmoothL1Loss(regression)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Model requirements\n",
    "\n",
    "### Architecture constraints\n",
    "\n",
    "You must use **exactly this feature extractor (backbone)**:\n",
    "\n",
    "```python\n",
    "nn.Sequential(\n",
    "    nn.Conv2d(1, 8, 3, stride=1, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(8, 16, 3, stride=1, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(64 * 28 * 28, 256), nn.ReLU()\n",
    ")\n",
    "```\n",
    "\n",
    "Then add **two separate heads**:\n",
    "\n",
    "* `head_cls`: outputs log-probabilities for 135 classes\n",
    "* `head_cnt`: outputs 6 regression values (counts)\n",
    "\n",
    "The model must return two outputs: `(log_probs, counts)`.\n",
    "\n",
    "You may add dropout or batch normalization inside the heads, **but you must not modify the backbone**.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Training setup\n",
    "\n",
    "* Optimizer: **Adam**, learning rate = 1e-3\n",
    "* Epochs: up to **100** (use **early stopping**)\n",
    "* Batch sizes: **64** (train), **1000** (validation)\n",
    "* Device: GPU allowed for Notebook, but your **final code must run on GPU within ~30 minutes**\n",
    "* Random seed: set `torch.manual_seed(1)` for reproducibility\n",
    "* Split: **exactly 9,000 train / 1,000 validation**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Data preprocessing and augmentation\n",
    "\n",
    "You must implement a **PyTorch `Dataset` class** that:\n",
    "\n",
    "* Reads `labels.csv`\n",
    "* Loads the corresponding image (from `data/`)\n",
    "* Returns both:\n",
    "  * the image (as a tensor)\n",
    "  * the labels (counts for 6 shapes)\n",
    "* Optionally applies transformations\n",
    "\n",
    "### Required augmentations\n",
    "\n",
    "You must implement **at least three** of the following:\n",
    "\n",
    "1. Random horizontal flip\n",
    "2. Random vertical flip\n",
    "3. Random 90° rotation (must correctly rotate orientation labels: up → right → down → left)\n",
    "4. Random brightness/contrast (mild)\n",
    "5. Gaussian noise\n",
    "6. Random erasing (small areas only)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Evaluation metrics\n",
    "\n",
    "Implement and report the following metrics on the validation set:\n",
    "\n",
    "### (a) **Classification (135-way)**\n",
    "\n",
    "* Top-1 accuracy\n",
    "* Macro F1-score\n",
    "* Per-pair accuracy (aggregate by unordered shape pair, e.g. {circle, up})\n",
    "\n",
    "### (b) **Regression (6-D counts)**\n",
    "\n",
    "* RMSE per class and overall\n",
    "* MAE per class and overall\n",
    "\n",
    "Also plot:\n",
    "\n",
    "* Training and validation losses\n",
    "* Validation accuracy and RMSE over epochs\n",
    "\n",
    "**Important**: This task is not about finding the best architecture; we expect at least 50% accuracy, but achieving results higher than that will not affect the grade for the assignment**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Experiments and analysis\n",
    "\n",
    "You must train and compare **three model settings**:\n",
    "\n",
    "| Setting | Description                                      |\n",
    "| :------ | :----------------------------------------------- |\n",
    "| 1       | **Classification-only:** λ_cnt = 0               |\n",
    "| 2       | **Regression-only:** classification loss ignored |\n",
    "| 3       | **Multitask:** λ_cnt = with your choose          |\n",
    "\n",
    "For each experiment:\n",
    "\n",
    "* Train until early stopping\n",
    "* Record loss, accuracy, RMSE, and runtime\n",
    "* Compare results and explain how λ influences learning\n",
    "* Discuss whether multitask learning improves the main tasks\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Final deliverables\n",
    "\n",
    "You must submit .zip project with:\n",
    "\n",
    "1. **Code** (`.ipynb` or `.py`) that:\n",
    "\n",
    "   * Downloads and extracts the dataset\n",
    "   * Defines dataset, dataloaders, model, loss, training loop, evaluation, and plotting\n",
    "   * Can run start-to-end without interaction, and finishes within 30 minutes on Colab T4 GPUs\n",
    "   * Includes three experiment configurations\n",
    "\n",
    "2. **Report (2–4 pages, PDF)** including:\n",
    "   * Section on (EDA) Exploratory Data Analysis in your report: no more than 3 graphs or tables describing the data set.\n",
    "   * Model architecture\n",
    "   * Description and justification of augmentations\n",
    "   * Results table (loss, accuracy, RMSE for all runs)\n",
    "   * Learning curves\n",
    "   * Discussion on multitask effects\n",
    "\n",
    "3. **README.md**:\n",
    "\n",
    "   * Link to Colab version of task for fast replication.\n",
    "   * Approximate runtime and resource requirements\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Grading rubric\n",
    "\n",
    "Component\tDescription\tPoints\n",
    "1. Implementation correctness\tCorrect use of the fixed backbone, two-headed model, and proper training loop (classification + regression).\t30%\n",
    "2. Data & augmentations\tProper dataset loading, preprocessing, and at least three augmentations with brief justification.\t20%\n",
    "3. Evaluation & experiments\tCorrect computation of metrics (accuracy, F1, RMSE) and completion of all three λ configurations (λ=0, regression-only, your choice λ).\t30%\n",
    "4. Report & analysis\n",
    "A clear separation of concerns (e.g. headers in notebooks, modules in code) and concise 2–4 page report with results tables, learning curves, confusion matrix, and short discussion on multitask effects and error examples.\n",
    "20%\n",
    "\n",
    "###### Readability and modularity will be considered within each grading component. Clear structure (headers in notebooks, docstrings, modular code) significantly improves evaluation speed. Emphasize using clear headers to help reviewers navigate efficiently.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUmggC-uvcGR",
    "outputId": "685adc40-8b27-43d1-8932-356d29319417"
   },
   "outputs": [],
   "source": [
    "# !wget  https://github.com/marcin119a/data/raw/refs/heads/main/data_gsn.zip\n",
    "# !unzip data_gsn.zip &> /dev/null\n",
    "# !rm data_gsn.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clsXRR2XUjf-"
   },
   "source": [
    "## Calculating labels for classification problem\n",
    "\n",
    "There are 135 combinations. This comes from:\n",
    "$$\\binom{6}{2}\\cdot 9 = 15\\cdot9 = 135$$\n",
    "\n",
    "We propose the following labeling: <br>\n",
    "For counting label $$[a_0, a_1, a_2, a_3, a_4, a_5]$$ with the only non-zero elements $a_i$ and $a_j$, where $i<j$ we will use a label equal to:\n",
    "$$ f(i, j)\\cdot9+a_i-1$$\n",
    "Where $f(g, h)$, where $g<h$, is a simple indexing function: <br>\n",
    "$$f(g,h) = \\binom{h}{2}+g$$\n",
    "where $0\\leq g<h\\leq5$. This provides us with unique labels from $0$ to $134$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSqeLuQ1Uqpg",
    "outputId": "ae7cd756-761c-4a76-d35d-3cd1473f035f"
   },
   "outputs": [],
   "source": [
    "import math as mth\n",
    "\n",
    "def cnt_to_cls_idx(cnt_label : list[int]) -> int:\n",
    "  a_1, i_1, i_2 = 0, 0, 0\n",
    "  for i, cnt in enumerate(cnt_label):\n",
    "    if cnt > 0:\n",
    "      if not a_1:\n",
    "        a_1 = cnt\n",
    "        i_1 = i\n",
    "      else:\n",
    "        i_2 = i\n",
    "        break\n",
    "  cls_idx = (mth.comb(i_2, 2)+i_1)*9+a_1-1\n",
    "  return cls_idx\n",
    "\n",
    "def cls_idx_to_cnt(cls_idx : int) -> list[int]:\n",
    "    if not (0 <= cls_idx <= 134):\n",
    "        raise ValueError(\"cls_idx must be in [0, 134] for 6 labels and counts 1..9\")\n",
    "\n",
    "    a_1 = (cls_idx % 9) + 1\n",
    "    pair_idx = cls_idx // 9\n",
    "    i_2 = 1\n",
    "    while mth.comb(i_2 + 1, 2) <= pair_idx:\n",
    "        i_2 += 1\n",
    "    i_1 = pair_idx - mth.comb(i_2, 2)\n",
    "\n",
    "    cnt_label = [0]*6\n",
    "    cnt_label[i_1] = a_1\n",
    "    cnt_label[i_2] = 10 - a_1\n",
    "    return cnt_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9AfvBMdhdLW"
   },
   "source": [
    "Applying and testing the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xs6a3_uSYYNL"
   },
   "source": [
    "## Adding new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "eAGB4xBvYcg3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_PATH = \"./data/labels.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "label_cols = df.columns[1:]\n",
    "n_images = len(df)\n",
    "\n",
    "class_indices = []\n",
    "for i in range(n_images):\n",
    "    cnt_label = df[label_cols].iloc[i].values\n",
    "    class_idx = cnt_to_cls_idx(cnt_label)\n",
    "    class_indices.append(class_idx)\n",
    "\n",
    "df[\"class_idx\"] = class_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhOb2Wyoyfer"
   },
   "source": [
    "## Exploring the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbjAlQiVyjY8",
    "outputId": "4b349731-9ccb-4a09-d0b0-dde0e864fea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA OVERVIEW ===\n",
      "Images: 10000\n",
      "Count label columns: ['squares', 'circles', 'up', 'right', 'down', 'left']\n",
      "Number of classes: 135\n",
      "\n",
      "=== COUNT LABELS SUMMARY ===\n",
      "Total sum of all counts: 100000\n",
      "\n",
      "Per-label totals:\n",
      "squares    16574\n",
      "circles    17149\n",
      "up         16530\n",
      "right      16770\n",
      "down       16857\n",
      "left       16120\n",
      "dtype: int64\n",
      "\n",
      "Per-label percentage of total (%):\n",
      "squares    16.57\n",
      "circles    17.15\n",
      "up         16.53\n",
      "right      16.77\n",
      "down       16.86\n",
      "left       16.12\n",
      "dtype: float64\n",
      "\n",
      "Presence percentage per label (%% of images with >0):\n",
      "squares    32.79\n",
      "circles    34.10\n",
      "up         33.19\n",
      "right      33.54\n",
      "down       33.67\n",
      "left       32.71\n",
      "dtype: float64\n",
      "\n",
      "Mean of non-zero values per label:\n",
      "squares    5.055\n",
      "circles    5.029\n",
      "up         4.980\n",
      "right      5.000\n",
      "down       5.007\n",
      "left       4.928\n",
      "dtype: float64\n",
      "\n",
      "=== CONSTRAINT CHECKS ===\n",
      "Images with exactly 2 non-zero count labels: 100.00%\n",
      "Images with sum(counts) == 10: 100.00%\n",
      "Images satisfying both: 100.00%\n",
      "\n",
      "Correlation matrix between count labels:\n",
      "         squares  circles     up  right   down   left\n",
      "squares    1.000   -0.202 -0.202 -0.206 -0.200 -0.192\n",
      "circles   -0.202    1.000 -0.209 -0.201 -0.208 -0.195\n",
      "up        -0.202   -0.209  1.000 -0.191 -0.197 -0.198\n",
      "right     -0.206   -0.201 -0.191  1.000 -0.207 -0.197\n",
      "down      -0.200   -0.208 -0.197 -0.207  1.000 -0.196\n",
      "left      -0.192   -0.195 -0.198 -0.197 -0.196  1.000\n",
      "Classes used: 105/135 (77.78%)\n",
      "Top 10 classes (id, count, % of images):\n",
      " class_id  count  pct_of_images\n",
      "       41    120           1.20\n",
      "       74    115           1.15\n",
      "       52    112           1.12\n",
      "       79    112           1.12\n",
      "       49    109           1.09\n",
      "        5    108           1.08\n",
      "       32    107           1.07\n",
      "      103    107           1.07\n",
      "      121    107           1.07\n",
      "       86    106           1.06\n",
      "\n",
      "Least 10 classes (id, count, % of images):\n",
      " class_id  count  pct_of_images\n",
      "       91     58           0.58\n",
      "       10     75           0.75\n",
      "       33     78           0.78\n",
      "      112     79           0.79\n",
      "      120     79           0.79\n",
      "       21     80           0.80\n",
      "       23     80           0.80\n",
      "       84     81           0.81\n",
      "      118     81           0.81\n",
      "       76     82           0.82\n",
      "Unused common classes:\n",
      "[0, 8, 9, 17, 18, 26, 27, 35, 36, 44, 45, 53, 54, 62, 63, 71, 72, 80, 81, 89, 90, 98, 99, 107, 108, 116, 117, 125, 126, 134]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "cnt_label_cols = df.columns[1:7]\n",
    "n_images = len(df)\n",
    "\n",
    "\n",
    "# --- COUNT LABELS ANALYSIS ---\n",
    "total_shapes     = df[cnt_label_cols].sum().sum()\n",
    "shape_totals     = df[cnt_label_cols].sum()\n",
    "shape_percentage = 100 * shape_totals / total_shapes\n",
    "\n",
    "corr = df[cnt_label_cols].corr(numeric_only=True)\n",
    "nonzero_means = df[cnt_label_cols].replace(0, np.nan).mean()\n",
    "presence_percentage = 100 * (df[cnt_label_cols] > 0).sum() / n_images\n",
    "\n",
    "# Per-image constraints\n",
    "nonzero_per_image = (df[cnt_label_cols] > 0).sum(axis=1)\n",
    "sum_per_image     = df[cnt_label_cols].sum(axis=1)\n",
    "\n",
    "prop_exact_two_nonzero = (nonzero_per_image == 2).mean() * 100\n",
    "prop_sum_eq_10         = (sum_per_image == 10).mean() * 100\n",
    "prop_both_constraints  = ((nonzero_per_image == 2) & (sum_per_image == 10)).mean() * 100\n",
    "\n",
    "# --- CLASS INDEX ANALYSIS (robust) ---\n",
    "n_classes = 135\n",
    "\n",
    "# counts for all classes [0..n_classes-1], missing -> 0\n",
    "class_counts_raw = df[\"class_idx\"].value_counts()          # counts only for seen classes\n",
    "class_counts_full = class_counts_raw.reindex(range(n_classes), fill_value=0)\n",
    "\n",
    "# summary table: count + % of images containing that class\n",
    "class_presence_pct = 100 * class_counts_full / n_images\n",
    "class_summary = pd.DataFrame({\n",
    "    \"class_id\": range(n_classes),\n",
    "    \"count\": class_counts_full.values,\n",
    "    \"pct_of_images\": class_presence_pct.values\n",
    "})\n",
    "\n",
    "# stats\n",
    "num_used_classes = int((class_counts_full > 0).sum())\n",
    "pct_classes_used = 100 * num_used_classes / n_classes\n",
    "unused_classes = class_summary.loc[class_summary[\"count\"] == 0, \"class_id\"].tolist()\n",
    "\n",
    "# top / bottom 10 (including unseen)\n",
    "top10_classes = class_summary.sort_values(\"count\", ascending=False).head(10)\n",
    "least10_present = (\n",
    "    class_summary[class_summary[\"count\"] > 0]\n",
    "    .sort_values([\"count\", \"class_id\"], ascending=[True, True])\n",
    "    .head(10)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# --- PRINT SUMMARY ---\n",
    "print(\"=== DATA OVERVIEW ===\")\n",
    "print(f\"Images: {n_images}\")\n",
    "print(f\"Count label columns: {list(label_cols)}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "\n",
    "print(\"\\n=== COUNT LABELS SUMMARY ===\")\n",
    "print(f\"Total sum of all counts: {int(total_shapes)}\")\n",
    "print(\"\\nPer-label totals:\")\n",
    "print(shape_totals)\n",
    "print(\"\\nPer-label percentage of total (%):\")\n",
    "print(shape_percentage.round(2))\n",
    "print(\"\\nPresence percentage per label (%% of images with >0):\")\n",
    "print(presence_percentage.round(2))\n",
    "print(\"\\nMean of non-zero values per label:\")\n",
    "print(nonzero_means.round(3))\n",
    "\n",
    "print(\"\\n=== CONSTRAINT CHECKS ===\")\n",
    "print(f\"Images with exactly 2 non-zero count labels: {prop_exact_two_nonzero:.2f}%\")\n",
    "print(f\"Images with sum(counts) == 10: {prop_sum_eq_10:.2f}%\")\n",
    "print(f\"Images satisfying both: {prop_both_constraints:.2f}%\")\n",
    "\n",
    "print(\"\\nCorrelation matrix between count labels:\")\n",
    "print(corr.round(3))\n",
    "\n",
    "print(f\"Classes used: {num_used_classes}/{n_classes} ({pct_classes_used:.2f}%)\")\n",
    "print(\"Top 10 classes (id, count, % of images):\")\n",
    "print(top10_classes[[\"class_id\", \"count\", \"pct_of_images\"]].to_string(index=False))\n",
    "\n",
    "print(\"\\nLeast 10 classes (id, count, % of images):\")\n",
    "print(least10_present[[\"class_id\", \"count\", \"pct_of_images\"]].to_string(index=False))\n",
    "print(\"Unused common classes:\")\n",
    "print(unused_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVQLy-7S7_WW"
   },
   "source": [
    "## Conclusions\n",
    "The dataset is well balanced: all shapes appear with similar frequency, there are no strong correlations between shape types, and whenever a shape is present its average count is close to 5 out of 10. Based on this, not much data augmentation is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4QwKRS1uwnD"
   },
   "source": [
    "## Dataset Class\n",
    "Each transform is applied independently with a fixed probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ake3FpnUpxP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Noooak7Y18Bx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class MultitaskDataset(Dataset):\n",
    "  def __init__(self, root: str, transforms=None, transform_prob: float = 0.3, normalize: bool = True):\n",
    "    self.root = Path(root)\n",
    "    self.df = pd.read_csv(root)\n",
    "    self.transforms = transforms or []\n",
    "    self.transform_prob = transform_prob\n",
    "    self.normalize = normalize\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img_path = self.root.parent / self.df.iloc[idx, 0]\n",
    "    image = Image.open(img_path).convert('L')\n",
    "    label_cnt = self.df.iloc[idx, 1:7].tolist()\n",
    "\n",
    "    # Apply each transform independently with probability p\n",
    "    for t in self.transforms:\n",
    "      if torch.rand(1).item() < self.transform_prob:\n",
    "        image, label_cnt = t(image, label_cnt)\n",
    "\n",
    "    cls_idx = cnt_to_cls_idx(label_cnt)\n",
    "    image = TF.to_tensor(image)\n",
    "    if self.normalize:\n",
    "      image = (image - 0.5) / 0.5\n",
    "    return image, torch.tensor(label_cnt, dtype=torch.float32), cls_idx\n",
    "\n",
    "def horizontal_flip(image, labels_cnt):\n",
    "  # left/right triangle swap (indices 3 and 5)\n",
    "  labels_cnt[3], labels_cnt[5] = labels_cnt[5], labels_cnt[3]\n",
    "  return image.transpose(Image.FLIP_LEFT_RIGHT), labels_cnt\n",
    "\n",
    "def vertical_flip(image, labels_cnt):\n",
    "  # up/down triangle swap (indices 2 and 4)\n",
    "  labels_cnt[2], labels_cnt[4] = labels_cnt[4], labels_cnt[2]\n",
    "  return image.transpose(Image.FLIP_TOP_BOTTOM), labels_cnt\n",
    "\n",
    "def rotation(image, labels_cnt):\n",
    "  # 90° CW or CCW rotation; cycle orientations\n",
    "  if torch.rand(1).item() < 0.5:  # CCW (-90)\n",
    "    labels_cnt[2], labels_cnt[3], labels_cnt[4], labels_cnt[5] = labels_cnt[5], labels_cnt[2], labels_cnt[3], labels_cnt[4]\n",
    "    return image.rotate(-90), labels_cnt\n",
    "  else:  # CW (+90)\n",
    "    labels_cnt[2], labels_cnt[3], labels_cnt[4], labels_cnt[5] = labels_cnt[3], labels_cnt[4], labels_cnt[5], labels_cnt[2]\n",
    "    return image.rotate(90), labels_cnt\n",
    "\n",
    "def gaussian_noise(image, labels_cnt):\n",
    "  t = TF.to_tensor(image)\n",
    "  t = t + torch.randn_like(t) * 0.02\n",
    "  t = torch.clamp(t, 0.0, 1.0)\n",
    "  return TF.to_pil_image(t), labels_cnt\n",
    "\n",
    "def random_erasing(image, labels_cnt):\n",
    "  # very small black patches\n",
    "  n_patches = torch.randint(1, 4, (1,)).item()\n",
    "  w_patch, h_patch = 2, 2\n",
    "  width, height = image.size\n",
    "  for _ in range(n_patches):\n",
    "    i = torch.randint(0, width - w_patch, (1,)).item()\n",
    "    j = torch.randint(0, height - h_patch, (1,)).item()\n",
    "    image.paste(0, (i, j, i + w_patch, j + h_patch))\n",
    "  return image, labels_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tt-RooZK6cgr"
   },
   "source": [
    "## Test Transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uPDx9O686fkE",
    "outputId": "1a7538b7-975c-40a7-e276-0f00797ebea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transform\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGIdJREFUeJzt3X9oVff9x/HX1cZT65ILQZN774yXUJSNKkKtU0OrUvBiYFLrBraFEf8ROqIQ0jLmyjDbH0aE+lfWycqQlbXTf9QJlUmG+WFxjiCWiiuSYlwyzCUYxr0xzhtsPt8/8vXSa6LmHu+97/vj+YAPNOece8/7fu6n9+Un95xPAs45JwAADCywLgAAULkIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJh5zrqAR01PT+v27duqrq5WIBCwLgcAkCXnnCYmJhSJRLRgwZPnOkUXQrdv31ZDQ4N1GQCAZzQyMqLly5c/8Zii+3VcdXW1dQkAgByYz+d53kLoo48+UmNjo55//nmtW7dOFy9enNfj+BUcAJSH+Xye5yWETp48qba2Nn3wwQe6evWqXnvtNTU3N2t4eDgfpwMAlKhAPlbR3rBhg15++WX9/ve/T2/74Q9/qJ07d6qzs/OJj00mkwoGg7kuCQBQYIlEQjU1NU88JuczoampKV25ckWxWCxjeywW06VLl2Ydn0qllEwmMxoAoDLkPITu3Lmjb7/9VvX19Rnb6+vrFY/HZx3f2dmpYDCYblwZBwCVI28XJjz6hZRzbs4vqQ4cOKBEIpFuIyMj+SoJAFBkcn6f0NKlS7Vw4cJZs56xsbFZsyNJ8jxPnuflugwAQAnI+Uxo0aJFWrdunbq7uzO2d3d3q6mpKdenAwCUsLysmNDe3q6f/exneuWVV7Rp0yb94Q9/0PDwsN599918nA4AUKLyEkK7d+/W+Pi4fvvb32p0dFSrV6/WuXPnFI1G83E6AECJyst9Qs+C+4QAIH/8fOT7XcnG5D4hAADmixACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJm8rKINAJWqyNaEzolsX1M2C1EzEwIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmGEVbQDIoUAgUJDzlMtq3cyEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmGEBUwAoQX4XSi22hU+ZCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADDDAqYA8Bh+Fvv0u7BoofipL5+LnjITAgCYIYQAAGZyHkIdHR0KBAIZLRQK5fo0AIAykJfvhF566SX9/e9/T/+8cOHCfJwGAFDi8hJCzz33HLMfAMBT5eU7ocHBQUUiETU2Nuqtt97SzZs3H3tsKpVSMpnMaACAypDzENqwYYM++eQTnT9/Xh9//LHi8biampo0Pj4+5/GdnZ0KBoPp1tDQkOuSAABFKuDyeQG4pMnJSb344ov6xS9+ofb29ln7U6mUUqlU+udkMkkQASgK5XifkB/Z9kMymVQwGFQikVBNTc0Tj837zapLlizRmjVrNDg4OOd+z/PkeV6+ywAAFKG83yeUSqX09ddfKxwO5/tUAIASk/MQev/999XX16ehoSH985//1E9/+lMlk0m1tLTk+lQAgBKX81/H/ec//9Hbb7+tO3fuaNmyZdq4caMuX76saDSa61MBAEpc3i9MyNbDL7QAAKVtPhcmsHYcAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMPOcdQEAUE6cc1k/JhAI5KGS0sBMCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJmyWcDUz6KBflXyYoMAcq+SP7+YCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBTNguY+uF3IT8/iw0W26KBAFAMmAkBAMwQQgAAM1mHUH9/v3bs2KFIJKJAIKAzZ85k7HfOqaOjQ5FIRIsXL9bWrVt1/fr1XNULACgjWYfQ5OSk1q5dq66urjn3HzlyREePHlVXV5cGBgYUCoW0bds2TUxMPHOxAIAy456BJHf69On0z9PT0y4UCrnDhw+nt92/f98Fg0F37NixeT1nIpFwkrJufusv9nPRaLTSasWukH2RSCSeWk9OvxMaGhpSPB5XLBZLb/M8T1u2bNGlS5fmfEwqlVIymcxoAIDKkNMQisfjkqT6+vqM7fX19el9j+rs7FQwGEy3hoaGXJYEAChiebk67tF7Ypxzj71P5sCBA0okEuk2MjKSj5IAAEUopzerhkIhSTMzonA4nN4+NjY2a3b0kOd58jwvl2UAAEpETmdCjY2NCoVC6u7uTm+bmppSX1+fmpqacnkqAEAZyHomdPfuXX3zzTfpn4eGhvTll1+qtrZWK1asUFtbmw4dOqSVK1dq5cqVOnTokF544QW98847OS0cAFAGsr28r6enZ85L8VpaWpxzM5dpHzx40IVCIed5ntu8ebO7du3avJ+fS7RpNFopt2JXyL6YzyXagf8vqmgkk0kFg8GsH+fnZRRyUdFirw/+8d7iuwr1kVoKYyiRSKimpuaJx7B2HADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADATE7/sioez8+Kt6zOXL54b/FdlfzeMhMCAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghgVMfSjU4pMseorv4r0tDfR5dpgJAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMMMCpgVSboue+j0XCov3FsWOmRAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzLGBaxPwuPpktFqvEowq14C7ATAgAYIYQAgCYyTqE+vv7tWPHDkUiEQUCAZ05cyZj/549exQIBDLaxo0bc1UvAKCMZB1Ck5OTWrt2rbq6uh57zPbt2zU6Oppu586de6YiAQDlKesLE5qbm9Xc3PzEYzzPUygU8l0UAKAy5OU7od7eXtXV1WnVqlXau3evxsbGHntsKpVSMpnMaACAypDzEGpubtann36qCxcu6MMPP9TAwIBef/11pVKpOY/v7OxUMBhMt4aGhlyXBAAoUgH3DDejBAIBnT59Wjt37nzsMaOjo4pGozpx4oR27do1a38qlcoIqGQy6SuICnlfQ6Hu3ykU7u94NuU2HvxiHOFRiURCNTU1Tzwm7zerhsNhRaNRDQ4Ozrnf8zx5npfvMgAARSjv9wmNj49rZGRE4XA436cCAJSYrGdCd+/e1TfffJP+eWhoSF9++aVqa2tVW1urjo4O/eQnP1E4HNatW7f0q1/9SkuXLtWbb76Z08IBAGXAZamnp8dJmtVaWlrcvXv3XCwWc8uWLXNVVVVuxYoVrqWlxQ0PD8/7+ROJxJzP/7Tmh5/z+D1XMfPbD7TyHA9+Wb8PtOJriUTiqePmmS5MyIdkMqlgMJj14/y8jGK/MMFPfYXsB8wosv+FSgpjr7zN58IE1o4DAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJjJ+19W9Ws+q6+WkmJeEdvvKtCsgIzvYjzAD2ZCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBTtAqbZKvaFO/2eqxD8LjxZqAVWUXi8TygUZkIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMlM0Cpn6wSCNKCeMV5YiZEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADNls4Cpc65g5yq3hSQL2Xd+zlXs/V2o+gr5PvlR7O8TihMzIQCAGUIIAGAmqxDq7OzU+vXrVV1drbq6Ou3cuVM3btzIOMY5p46ODkUiES1evFhbt27V9evXc1o0AKA8ZBVCfX19am1t1eXLl9Xd3a0HDx4oFotpcnIyfcyRI0d09OhRdXV1aWBgQKFQSNu2bdPExETOiwcAlDj3DMbGxpwk19fX55xzbnp62oVCIXf48OH0Mffv33fBYNAdO3ZsXs+ZSCScJJdIJJ6ltLySlHWjNv/8vKZybMXOun9oxdfm8zn+TN8JJRIJSVJtba0kaWhoSPF4XLFYLH2M53nasmWLLl26NOdzpFIpJZPJjAYAqAy+Q8g5p/b2dr366qtavXq1JCkej0uS6uvrM46tr69P73tUZ2engsFgujU0NPgtCQBQYnyH0L59+/TVV1/pL3/5y6x9j94v4Jx77D0EBw4cUCKRSLeRkRG/JQEASoyvm1X379+vs2fPqr+/X8uXL09vD4VCkmZmROFwOL19bGxs1uzoIc/z5HmenzIAACUuq5mQc0779u3TqVOndOHCBTU2Nmbsb2xsVCgUUnd3d3rb1NSU+vr61NTUlJuKAQBlI6uZUGtrqz777DP99a9/VXV1dfp7nmAwqMWLFysQCKitrU2HDh3SypUrtXLlSh06dEgvvPCC3nnnnby8AABACcvFJZjHjx9PHzM9Pe0OHjzoQqGQ8zzPbd682V27dm3e5+AS7fKtzS8/r6kcW7Gz7h9a8bX5fI4H/n/wFI1kMqlgMKhEIqGamhrrcubEgpXFz+975KfP/ZyL93YGi56Wt/l8jrN2HADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADAjK+/rIrssTpzYRWyHwp1LsYDyhEzIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGZYwLRA/Cw+idJQzO9tIWvzs1hqoRb2RfFiJgQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMC5ii6LFgZWngfYIfzIQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYKZsFTFk8sTTwPgH4LmZCAAAzhBAAwExWIdTZ2an169erurpadXV12rlzp27cuJFxzJ49exQIBDLaxo0bc1o0AKA8ZBVCfX19am1t1eXLl9Xd3a0HDx4oFotpcnIy47jt27drdHQ03c6dO5fTogEA5SGrCxP+9re/Zfx8/Phx1dXV6cqVK9q8eXN6u+d5CoVCuakQAFC2nuk7oUQiIUmqra3N2N7b26u6ujqtWrVKe/fu1djY2GOfI5VKKZlMZjQAQGUIOOecnwc65/TGG2/ov//9ry5evJjefvLkSX3ve99TNBrV0NCQfv3rX+vBgwe6cuWKPM+b9TwdHR36zW9+M2t7IpFQTU3N/F8Il/5KmnlfihnvE1A55vM57juEWltb9fnnn+uLL77Q8uXLH3vc6OiootGoTpw4oV27ds3an0qllEql0j8nk0k1NDQQQj4RQgCKxXw+x33drLp//36dPXtW/f39TwwgSQqHw4pGoxocHJxzv+d5c86QAADlL6sQcs5p//79On36tHp7e9XY2PjUx4yPj2tkZEThcNh3kQCA8pTVhQmtra3685//rM8++0zV1dWKx+OKx+P63//+J0m6e/eu3n//ff3jH//QrVu31Nvbqx07dmjp0qV688038/ICAAAlzGVB0pzt+PHjzjnn7t2752KxmFu2bJmrqqpyK1ascC0tLW54eHje50gkEk6SSyQS2ZT22NoqrRU76/6h0WiFa/P5HM/613FPsnjxYp0/fz6bpwQAVLCiXUU7GAxal4CnKOYr3Z72D6ZcKuZ+KKRC9Tn9XV5YwBQAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAICZol3AFIVTjgtC+n1NfhbhLOaFOwu5kKsf5Tj2kB1mQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwU3RrxxX7WlfFLplMWpdQ0sqt/8rt9aC0zOfzvOhCaGJiwrqEkhYMBq1LKGnl1n/l9npQWiYmJp46BgOuyKYe09PTun37tqqrq2etsJtMJtXQ0KCRkRHV1NQYVWiPfphBP8ygH2bQDzOKoR+cc5qYmFAkEtGCBU/+1qfoZkILFizQ8uXLn3hMTU1NRQ+yh+iHGfTDDPphBv0ww7of5jsL58IEAIAZQggAYKakQsjzPB08eFCe51mXYop+mEE/zKAfZtAPM0qtH4ruwgQAQOUoqZkQAKC8EEIAADOEEADADCEEADBTUiH00UcfqbGxUc8//7zWrVunixcvWpdUUB0dHQoEAhktFApZl5V3/f392rFjhyKRiAKBgM6cOZOx3zmnjo4ORSIRLV68WFu3btX169dtis2jp/XDnj17Zo2PjRs32hSbJ52dnVq/fr2qq6tVV1ennTt36saNGxnHVMJ4mE8/lMp4KJkQOnnypNra2vTBBx/o6tWreu2119Tc3Kzh4WHr0grqpZde0ujoaLpdu3bNuqS8m5yc1Nq1a9XV1TXn/iNHjujo0aPq6urSwMCAQqGQtm3bVnbrED6tHyRp+/btGePj3LlzBaww//r6+tTa2qrLly+ru7tbDx48UCwW0+TkZPqYShgP8+kHqUTGgysRP/rRj9y7776bse0HP/iB++Uvf2lUUeEdPHjQrV271roMU5Lc6dOn0z9PT0+7UCjkDh8+nN52//59FwwG3bFjxwwqLIxH+8E551paWtwbb7xhUo+VsbExJ8n19fU55yp3PDzaD86VzngoiZnQ1NSUrly5olgslrE9Fovp0qVLRlXZGBwcVCQSUWNjo9566y3dvHnTuiRTQ0NDisfjGWPD8zxt2bKl4saGJPX29qqurk6rVq3S3r17NTY2Zl1SXiUSCUlSbW2tpModD4/2w0OlMB5KIoTu3Lmjb7/9VvX19Rnb6+vrFY/HjaoqvA0bNuiTTz7R+fPn9fHHHysej6upqUnj4+PWpZl5+P5X+tiQpObmZn366ae6cOGCPvzwQw0MDOj1119XKpWyLi0vnHNqb2/Xq6++qtWrV0uqzPEwVz9IpTMeim4V7Sd59E87OOdmbStnzc3N6f9es2aNNm3apBdffFF/+tOf1N7ebliZvUofG5K0e/fu9H+vXr1ar7zyiqLRqD7//HPt2rXLsLL82Ldvn7766it98cUXs/ZV0nh4XD+UyngoiZnQ0qVLtXDhwln/khkbG5v1L55KsmTJEq1Zs0aDg4PWpZh5eHUgY2O2cDisaDRaluNj//79Onv2rHp6ejL+9EuljYfH9cNcinU8lEQILVq0SOvWrVN3d3fG9u7ubjU1NRlVZS+VSunrr79WOBy2LsVMY2OjQqFQxtiYmppSX19fRY8NSRofH9fIyEhZjQ/nnPbt26dTp07pwoULamxszNhfKePhaf0wl6IdD4YXRWTlxIkTrqqqyv3xj390//rXv1xbW5tbsmSJu3XrlnVpBfPee++53t5ed/PmTXf58mX34x//2FVXV5d9H0xMTLirV6+6q1evOknu6NGj7urVq+7f//63c865w4cPu2Aw6E6dOuWuXbvm3n77bRcOh10ymTSuPLee1A8TExPuvffec5cuXXJDQ0Oup6fHbdq0yX3/+98vq374+c9/7oLBoOvt7XWjo6Ppdu/evfQxlTAentYPpTQeSiaEnHPud7/7nYtGo27RokXu5ZdfzrgcsRLs3r3bhcNhV1VV5SKRiNu1a5e7fv26dVl519PT4yTNai0tLc65mctyDx486EKhkPM8z23evNldu3bNtug8eFI/3Lt3z8ViMbds2TJXVVXlVqxY4VpaWtzw8LB12Tk11+uX5I4fP54+phLGw9P6oZTGA3/KAQBgpiS+EwIAlCdCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABm/g9XzufCvB5EfwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 6, 0, 0, 39]\n",
      "Horizontal flip\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 6, 39]\n",
      "Vertical flip\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 6, 0, 0, 39]\n",
      "Rotation\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGJ5JREFUeJzt3X9oVff9x/HX1eqZdcmFoMm9d8YQirKhItQ6NdQfFLwYmNS6gW1hxH+EjiiILWOuDLP9YcRR2R9ZJytDVtZO/1EnVFYyNLHFOUQsDa5IinHJMJdgGOfEOG+w+Xz/yLx8r4kxud573+fe+3zAB8y5J7nvfO4n9+Un99x3Is45JwAADMyxLgAAULkIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJh5zrqAx42Pj+vOnTuqqqpSJBKxLgcAMEvOOY2MjCiRSGjOnOn3OqELoTt37qi+vt66DADAMxoYGNCSJUumPSd0IVRVVVW0+/J9v2j3VSzRaNS6BACQNLPn84KF0Pvvv69f//rXGhwc1IoVK/Sb3/xGGzdufOrnFfNXcNXV1UW7LwCoNDN5Pi/IhQmnTp3S/v379e677+r69evauHGjmpub1d/fX4i7AwCUqEghumivW7dOL774on73u99ljn3ve9/Tjh071N7ePu3nBkFQtF8plWMDcS7mABAWvu8/9TdOed8JjY2N6dq1a0omk1nHk8mkLl++POn8dDqtIAiyBgCgMuQ9hO7evatvvvlGdXV1Wcfr6uqUSqUmnd/e3q5oNJoZXBkHAJWjYG9WffzXQs65KX9VdPDgQfm+nxkDAwOFKgkAEDJ5vzpu0aJFmjt37qRdz9DQ0KTdkSR5nifP8/JdBgCgBOR9JzR//nytWbNGnZ2dWcc7OzvV1NSU77sDAJSwgrxP6MCBA/rxj3+sl156SRs2bNDvf/979ff366233irE3QEASlRBQmjXrl0aHh7Wr371Kw0ODmrlypU6f/68GhoaCnF3AIASVZD3CT2LXN8nFLJvIy94zw+AUmbyPiEAAGaKEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAmYJ00baQS7PPYjY9pRnphGLNOfMNlAZ2QgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM2XTRbuY6NAcfrl26+axBYqLnRAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzNDBFznJtEhpmuXxPND0FcsdOCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJmKbmAa9saTYW+mGfb5AxB+7IQAAGYIIQCAmbyHUFtbmyKRSNaIxWL5vhsAQBkoyGtCK1as0N/+9rfMx3Pnzi3E3QAASlxBQui5555j9wMAeKqCvCbU29urRCKhxsZGvf7667p169YTz02n0wqCIGsAACpD3kNo3bp1+vDDD/Xpp5/qgw8+UCqVUlNTk4aHh6c8v729XdFoNDPq6+vzXRIAIKQiLpc3o8zC6OioXnjhBf30pz/VgQMHJt2eTqeVTqczHwdBQBD9T9jfJwQA0/F9X9XV1dOeU/A3qy5cuFCrVq1Sb2/vlLd7nifP8wpdBgAghAr+PqF0Oq2vvvpK8Xi80HcFACgxeQ+hd955R93d3err69M//vEP/ehHP1IQBGppacn3XQEASlzefx3373//W2+88Ybu3r2rxYsXa/369bpy5YoaGhryfVcAgBJX8AsTZisIAkWjUesyAADPaCYXJtA7DgBghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJh5zroAACgnzrlZf04kEilAJVMLW33shAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJihgSlQxnJpVikVt6FmMeQ6D5gw2/kLgkDRaHRG57ITAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYGpkCJKGYTzlzuq1hNT8PejDTszV9zqa+Qc85OCABghhACAJiZdQhdunRJ27dvVyKRUCQS0dmzZ7Nud86pra1NiURCCxYs0JYtW3Tjxo181QsAKCOzDqHR0VGtXr1aHR0dU95+9OhRHTt2TB0dHbp69apisZi2bt2qkZGRZy4WAFBm3DOQ5M6cOZP5eHx83MViMXfkyJHMsQcPHrhoNOqOHz8+o6/p+76TxGAwHhthxzxMsF4nYZjzR8/jvu8/9dy8vibU19enVCqlZDKZOeZ5njZv3qzLly9P+TnpdFpBEGQNAEBlyGsIpVIpSVJdXV3W8bq6usxtj2tvb1c0Gs2M+vr6fJYEAAixglwd9/h16M65J16bfvDgQfm+nxkDAwOFKAkAEEJ5fbNqLBaTNLEjisfjmeNDQ0OTdkePeJ4nz/PyWQYAoETkdSfU2NioWCymzs7OzLGxsTF1d3erqakpn3cFACgDs94J3bt3T19//XXm476+Pn3xxReqqanR0qVLtX//fh0+fFjLli3TsmXLdPjwYT3//PN6880381o4AKAMzPbSu4sXL055CV9LS4tzbuIy7UOHDrlYLOY8z3ObNm1yPT09s760j8FgZI+wYx4mWK+TMMz5bC7Rjvxv0kIjCAJFo1HrMoCCCtmPnZmwNdPMh7A3MM3FbOf80fO47/uqrq6e9lx6xwEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzOT1L6sClSjsXZ2Ru3LsiJ2LQs4DOyEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmaGAK/D80Iy2uXOY7l2aauT6uxaov7GY7D0EQKBqNzuhcdkIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDM0MAUZYlGpPj/cm0qyjoqPHZCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzNDAFGUp14aVKE/FbESay30Vc72GrSkrOyEAgBlCCABgZtYhdOnSJW3fvl2JREKRSERnz57Nun337t2KRCJZY/369fmqFwBQRmYdQqOjo1q9erU6OjqeeM62bds0ODiYGefPn3+mIgEA5WnWFyY0Nzerubl52nM8z1MsFsu5KABAZSjIa0JdXV2qra3V8uXLtWfPHg0NDT3x3HQ6rSAIsgYAoDLkPYSam5v10Ucf6cKFC3rvvfd09epVvfLKK0qn01Oe397ermg0mhn19fX5LgkAEFIR9wwXjUciEZ05c0Y7dux44jmDg4NqaGjQyZMntXPnzkm3p9PprIAKgoAgApBXYXtvzOPK7X1CQRAoGo3K931VV1dPe27B36waj8fV0NCg3t7eKW/3PE+e5xW6DABACBX8fULDw8MaGBhQPB4v9F0BAErMrHdC9+7d09dff535uK+vT1988YVqampUU1OjtrY2/fCHP1Q8Htft27f185//XIsWLdJrr72W18IBAGXAzdLFixedpEmjpaXF3b9/3yWTSbd48WI3b948t3TpUtfS0uL6+/tn/PV935/y6zMYDEauI+zKbS4ePY/7vv/Uc5/pwoRCePSCFgBYK9bTY9gvTMi1vplcmEDvOACAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAmYL/ZVUAsBayPxZgqpgdu2eCnRAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzNDAFUFLKsRlpLt9T2BqR5oqdEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADM0MAWQF+XYWDTMcp3vsDU+ZScEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADA1MAQO5NJ8sZuPJMNdHo9RnE7bHlp0QAMAMIQQAMDOrEGpvb9fatWtVVVWl2tpa7dixQzdv3sw6xzmntrY2JRIJLViwQFu2bNGNGzfyWjQAoDzMKoS6u7vV2tqqK1euqLOzUw8fPlQymdTo6GjmnKNHj+rYsWPq6OjQ1atXFYvFtHXrVo2MjOS9eABAiXPPYGhoyEly3d3dzjnnxsfHXSwWc0eOHMmc8+DBAxeNRt3x48dn9DV933eSGIyyHrmgvtxrw7PJ9bHyff+pX/uZXhPyfV+SVFNTI0nq6+tTKpVSMpnMnON5njZv3qzLly9P+TXS6bSCIMgaAIDKkHMIOed04MABvfzyy1q5cqUkKZVKSZLq6uqyzq2rq8vc9rj29nZFo9HMqK+vz7UkAECJyTmE9u7dqy+//FJ//vOfJ932+DXlzrknXmd+8OBB+b6fGQMDA7mWBAAoMTm9WXXfvn06d+6cLl26pCVLlmSOx2IxSRM7ong8njk+NDQ0aXf0iOd58jwvlzIAACVuVjsh55z27t2r06dP68KFC2psbMy6vbGxUbFYTJ2dnZljY2Nj6u7uVlNTU34qBgCUjVnthFpbW/Xxxx/rL3/5i6qqqjKv80SjUS1YsECRSET79+/X4cOHtWzZMi1btkyHDx/W888/rzfffLMg3wAAoITl4zK9EydOZM4ZHx93hw4dcrFYzHme5zZt2uR6enpmfB9cos2ohJEL6su9NjybXB+rmVyiHfnfHYRGEASKRqPWZQAzlsuPUC4NIYv5o1rMZqnFELKnubL36Hnc931VV1dPey694wAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZnL6y6pAuSpWR+xiybU2uk5PCPNjWy7YCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDA1OUpVwbcBarYWWxGoQWcx7C3PS0mI1caXo6O+yEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmKGBKUIv7E0kw9y4M1dhn/NiKcfvKWzYCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDA1MUVTk2xgx7fcVSrMe2HBvG5qJc1h07IQCAGUIIAGBmViHU3t6utWvXqqqqSrW1tdqxY4du3ryZdc7u3bsViUSyxvr16/NaNACgPMwqhLq7u9Xa2qorV66os7NTDx8+VDKZ1OjoaNZ527Zt0+DgYGacP38+r0UDAMrDrC5M+Otf/5r18YkTJ1RbW6tr165p06ZNmeOe5ykWi+WnQgBA2Xqm14R835ck1dTUZB3v6upSbW2tli9frj179mhoaOiJXyOdTisIgqwBAKgMEZfj9Y7OOb366qv6z3/+o88++yxz/NSpU/r2t7+thoYG9fX16Re/+IUePnyoa9euyfO8SV+nra1Nv/zlL3P/DlBSyvESbUzgEu3iKoWfC9/3VV1dPe05OYdQa2urPvnkE33++edasmTJE88bHBxUQ0ODTp48qZ07d066PZ1OK51OZz4OgkD19fW5lIQSQAiVL0KouErh52ImIZTTm1X37dunc+fO6dKlS9MGkCTF43E1NDSot7d3yts9z5tyhwQAKH+zCiHnnPbt26czZ86oq6tLjY2NT/2c4eFhDQwMKB6P51wkAKA8zerChNbWVv3pT3/Sxx9/rKqqKqVSKaVSKf33v/+VJN27d0/vvPOO/v73v+v27dvq6urS9u3btWjRIr322msF+QYAACXMzYKkKceJEyecc87dv3/fJZNJt3jxYjdv3jy3dOlS19LS4vr7+2d8H77vP/F+GKU/cmFdMyNcjy0mWD/eMxm+7z/1+8j5woRCCYJA0WjUugwUSC7LrRRegEXxHtuQPWWZKYWfi4JdmAAUE086paEUnhQRPjQwBQCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYGpigqmlyWhlyaxtJotrhyne+w/QyyEwIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAmdD1jqP/FGAvCALrElAGZvJ8HroQGhkZsS4BqHjRaNS6BJSBkZGRp66liAvZ1mN8fFx37txRVVXVpG6vQRCovr5eAwMDqq6uNqrQHvMwgXmYwDxMYB4mhGEenHMaGRlRIpHQnDnTv+oTup3QnDlztGTJkmnPqa6uruhF9gjzMIF5mMA8TGAeJljPw0x301yYAAAwQwgBAMyUVAh5nqdDhw7J8zzrUkwxDxOYhwnMwwTmYUKpzUPoLkwAAFSOktoJAQDKCyEEADBDCAEAzBBCAAAzJRVC77//vhobG/Wtb31La9as0WeffWZdUlG1tbUpEolkjVgsZl1WwV26dEnbt29XIpFQJBLR2bNns253zqmtrU2JREILFizQli1bdOPGDZtiC+hp87B79+5J62P9+vU2xRZIe3u71q5dq6qqKtXW1mrHjh26efNm1jmVsB5mMg+lsh5KJoROnTql/fv3691339X169e1ceNGNTc3q7+/37q0olqxYoUGBwczo6enx7qkghsdHdXq1avV0dEx5e1Hjx7VsWPH1NHRoatXryoWi2nr1q1l14fwafMgSdu2bctaH+fPny9ihYXX3d2t1tZWXblyRZ2dnXr48KGSyaRGR0cz51TCepjJPEglsh5cifj+97/v3nrrraxj3/3ud93PfvYzo4qK79ChQ2716tXWZZiS5M6cOZP5eHx83MViMXfkyJHMsQcPHrhoNOqOHz9uUGFxPD4PzjnX0tLiXn31VZN6rAwNDTlJrru72zlXuevh8XlwrnTWQ0nshMbGxnTt2jUlk8ms48lkUpcvXzaqykZvb68SiYQaGxv1+uuv69atW9Ylmerr61MqlcpaG57nafPmzRW3NiSpq6tLtbW1Wr58ufbs2aOhoSHrkgrK931JUk1NjaTKXQ+Pz8MjpbAeSiKE7t69q2+++UZ1dXVZx+vq6pRKpYyqKr5169bpww8/1KeffqoPPvhAqVRKTU1NGh4eti7NzKPHv9LXhiQ1Nzfro48+0oULF/Tee+/p6tWreuWVV5ROp61LKwjnnA4cOKCXX35ZK1eulFSZ62GqeZBKZz2Erov2dB7/0w7OuUnHyllzc3Pm36tWrdKGDRv0wgsv6I9//KMOHDhgWJm9Sl8bkrRr167Mv1euXKmXXnpJDQ0N+uSTT7Rz507Dygpj7969+vLLL/X5559Puq2S1sOT5qFU1kNJ7IQWLVqkuXPnTvqfzNDQ0KT/8VSShQsXatWqVert7bUuxcyjqwNZG5PF43E1NDSU5frYt2+fzp07p4sXL2b96ZdKWw9PmoephHU9lEQIzZ8/X2vWrFFnZ2fW8c7OTjU1NRlVZS+dTuurr75SPB63LsVMY2OjYrFY1toYGxtTd3d3Ra8NSRoeHtbAwEBZrQ/nnPbu3avTp0/rwoULamxszLq9UtbD0+ZhKqFdD4YXRczKyZMn3bx589wf/vAH989//tPt37/fLVy40N2+fdu6tKJ5++23XVdXl7t165a7cuWK+8EPfuCqqqrKfg5GRkbc9evX3fXr150kd+zYMXf9+nX3r3/9yznn3JEjR1w0GnWnT592PT097o033nDxeNwFQWBceX5NNw8jIyPu7bffdpcvX3Z9fX3u4sWLbsOGDe473/lOWc3DT37yExeNRl1XV5cbHBzMjPv372fOqYT18LR5KKX1UDIh5Jxzv/3tb11DQ4ObP3++e/HFF7MuR6wEu3btcvF43M2bN88lEgm3c+dOd+PGDeuyCu7ixYtO0qTR0tLinJu4LPfQoUMuFos5z/Pcpk2bXE9Pj23RBTDdPNy/f98lk0m3ePFiN2/ePLd06VLX0tLi+vv7rcvOq6m+f0nuxIkTmXMqYT08bR5KaT3wpxwAAGZK4jUhAEB5IoQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYOb/ALm5z10RUrQDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 6, 0, 0, 0, 39]\n",
      "Gaussian noise\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 6, 0, 0, 39]\n",
      "Random erasing\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 6, 0, 0, 39]\n"
     ]
    }
   ],
   "source": [
    "from IPython.utils.path import random\n",
    "idx = 200\n",
    "img = Image.open(Path(\"./data/labels.csv\").parent / df.iloc[idx, 0]).convert('L')\n",
    "print(\"No transform\")\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "print(df.iloc[idx, 1:].tolist())\n",
    "print(\"Horizontal flip\")\n",
    "imgt, label = horizontal_flip(img, df.iloc[idx, 1:].tolist())\n",
    "plt.imshow(imgt, cmap='gray')\n",
    "plt.show()\n",
    "print(label)\n",
    "print(\"Vertical flip\")\n",
    "imgt, label = vertical_flip(img, df.iloc[idx, 1:].tolist())\n",
    "plt.imshow(imgt, cmap='gray')\n",
    "plt.show()\n",
    "print(label)\n",
    "print(\"Rotation\")\n",
    "imgt, label = rotation(img, df.iloc[idx, 1:].tolist())\n",
    "plt.imshow(imgt, cmap='gray')\n",
    "plt.show()\n",
    "print(label)\n",
    "print(\"Gaussian noise\")\n",
    "imgt, label = gaussian_noise(img, df.iloc[idx, 1:].tolist())\n",
    "plt.imshow(imgt, cmap='gray')\n",
    "plt.show()\n",
    "print(label)\n",
    "print(\"Random erasing\")\n",
    "imgt, label = random_erasing(img, df.iloc[idx, 1:].tolist())\n",
    "plt.imshow(imgt, cmap='gray')\n",
    "plt.show()\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vE1fwqZovBc1"
   },
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "uDskVAXfvkFn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import os\n",
    "\n",
    "# Reproducible generator\n",
    "g = torch.Generator().manual_seed(1)\n",
    "\n",
    "augment_list = [horizontal_flip, vertical_flip, rotation]  # , gaussian_noise, random_erasing]\n",
    "\n",
    "train_base = MultitaskDataset(\n",
    "    root=\"./data/labels.csv\",\n",
    "    transforms=augment_list,\n",
    "    transform_prob=0.6,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "test_base = MultitaskDataset(\n",
    "    root=\"./data/labels.csv\",\n",
    "    transforms=[],\n",
    "    transform_prob=0.0,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "n = len(train_base)\n",
    "split = int(0.9 * n)  # keep last 10% as hold-out test set\n",
    "train_idx = list(range(split))\n",
    "test_idx  = list(range(split, n))\n",
    "assert (len(train_idx), len(test_idx)) == (9000, 1000)\n",
    "\n",
    "# ---- Create validation split from the training portion ----\n",
    "val_ratio = 0.1  # use 10% of the training portion for validation\n",
    "perm = torch.randperm(len(train_idx), generator=g)\n",
    "val_size = int(len(train_idx) * val_ratio)\n",
    "val_perm = perm[:val_size]\n",
    "train_perm = perm[val_size:]\n",
    "\n",
    "val_idx = [train_idx[i] for i in val_perm.tolist()]\n",
    "new_train_idx = [train_idx[i] for i in train_perm.tolist()]\n",
    "\n",
    "train_ds = Subset(train_base, new_train_idx)\n",
    "val_ds   = Subset(train_base, val_idx)\n",
    "test_ds  = Subset(test_base,  test_idx)\n",
    "\n",
    "num_workers = min(4, os.cpu_count() // 2)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,  batch_size=256, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=1000, shuffle=False, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ObxxKDb9YDw"
   },
   "source": [
    "## Network structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Ps2PbavO95CD"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MultiTaskNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=1, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, 3, stride=1, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(64 * 28 * 28, 256), nn.ReLU()\n",
    "        )\n",
    "        self.head_cls = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 135)\n",
    "        )\n",
    "        self.head_cnt = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        logits = self.head_cls(feat)\n",
    "        log_probs = F.log_softmax(logits, dim=1)\n",
    "        counts = self.head_cnt(feat)\n",
    "        return log_probs, counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D32dQyZbHAhT"
   },
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8mlBVi99dzr"
   },
   "source": [
    "## Visualiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ria9VZF0G6k1"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class TrainingVisualizer:\n",
    "#     def __init__(self, lr):\n",
    "#         self.lr = lr\n",
    "#         self.first_linear_layer = None\n",
    "\n",
    "#     def attach(self, model: nn.Module):\n",
    "#         \"\"\"Znajdź pierwszą warstwę liniową w modelu i zapamiętaj referencję.\"\"\"\n",
    "#         self.first_linear_layer = None\n",
    "#         for m in model.modules():\n",
    "#             if isinstance(m, nn.Linear):\n",
    "#                 self.first_linear_layer = m\n",
    "#                 break\n",
    "\n",
    "#     def plot_gradients_and_loss(self, batch_idx: int, loss: float):\n",
    "#         layer = self.first_linear_layer\n",
    "#         # Jeśli nie znaleziono warstwy lub brak gradientu – po prostu pomiń\n",
    "#         if layer is None or layer.weight is None or layer.weight.grad is None:\n",
    "#             return\n",
    "\n",
    "#         # Zabezpieczenia przed dzieleniem przez zero / NaN\n",
    "#         w_std = layer.weight.detach().std()\n",
    "#         g_std = layer.weight.grad.detach().std()\n",
    "#         if w_std == 0 or torch.isnan(w_std) or torch.isnan(g_std):\n",
    "#             return\n",
    "\n",
    "#         grad_to_weight_ratio = (self.lr * g_std / w_std).item()\n",
    "\n",
    "#         # ...tu Twoje rysowanie / logowanie:\n",
    "#         # self.writer.add_scalar(\"train/loss\", loss, batch_idx)\n",
    "#         # self.writer.add_scalar(\"train/grad_to_weight_ratio\", grad_to_weight_ratio, batch_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnAgvVKy9i7F"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "nM1ILMQ07fTq"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    log_interval: int,\n",
    "    verbose: bool = False,\n",
    "    lambda_cnt: float = 0.1,\n",
    "    label_smoothing: float = 0.05\n",
    ") -> dict:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_total = 0\n",
    "    correct_cls = 0\n",
    "    correct_pair = 0\n",
    "\n",
    "    for batch_idx, (data, target_cnt, target_cls) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target_cls = target_cls.to(device).long()\n",
    "        target_cnt = target_cnt.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        log_probs, counts = model(data)\n",
    "\n",
    "        # Label smoothing\n",
    "        if label_smoothing > 0:\n",
    "            n_classes = log_probs.size(1)\n",
    "            smooth_val = label_smoothing / (n_classes - 1)\n",
    "            target_dist = torch.full_like(log_probs, smooth_val)\n",
    "            target_dist.scatter_(1, target_cls.unsqueeze(1), 1.0 - label_smoothing)\n",
    "            loss_cls = -(target_dist * log_probs).sum(dim=1).mean()\n",
    "        else:\n",
    "            loss_cls = F.nll_loss(log_probs, target_cls)\n",
    "\n",
    "        loss_cnt = F.smooth_l1_loss(counts, target_cnt)\n",
    "        loss = loss_cls + lambda_cnt * loss_cnt\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = data.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        n_total += batch_size\n",
    "\n",
    "        preds = log_probs.argmax(dim=1)\n",
    "        correct_cls += (preds == target_cls).sum().item()\n",
    "        correct_pair += ((preds // 9) == (target_cls // 9)).sum().item()\n",
    "\n",
    "        if verbose and batch_idx % log_interval == 0:\n",
    "            done = batch_idx * batch_size\n",
    "            print(f\"Train Epoch: {epoch} [{done}/{len(train_loader.dataset)}] Loss={loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / n_total\n",
    "    top1 = correct_cls / n_total\n",
    "    pair_acc = correct_pair / n_total\n",
    "    return {\"loss\": avg_loss, \"top1\": top1, \"pair_acc\": pair_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "FwU7CYdY1h4C"
   },
   "outputs": [],
   "source": [
    "def test(\n",
    "    model: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    "    epoch: int,\n",
    "    lambda_cnt: float = 0.5,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    n_classes = 135\n",
    "    n_reg_targets = 6\n",
    "\n",
    "    total_loss_cls = 0.0\n",
    "    total_loss_cnt = 0.0\n",
    "    n_total = 0\n",
    "\n",
    "    # classification metrics\n",
    "    n_correct_cls = 0\n",
    "    n_correct_pair = 0  # per-pair accuracy\n",
    "    conf_mat = torch.zeros(n_classes, n_classes, dtype=torch.long)\n",
    "\n",
    "    # regression metrics\n",
    "    sum_sq_err_per_class = torch.zeros(n_reg_targets)\n",
    "    sum_abs_err_per_class = torch.zeros(n_reg_targets)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target_cnt, target_cls in test_loader:\n",
    "            data = data.to(device)\n",
    "            target_cls = target_cls.to(device).long()\n",
    "            target_cnt = target_cnt.to(device).float()\n",
    "\n",
    "            log_probs, counts = model(data)\n",
    "\n",
    "            loss_cls = F.nll_loss(log_probs, target_cls, reduction=\"sum\")\n",
    "            loss_cnt = F.smooth_l1_loss(counts, target_cnt, reduction=\"sum\")\n",
    "\n",
    "            batch_size = data.size(0)\n",
    "            total_loss_cls += loss_cls.item()\n",
    "            total_loss_cnt += loss_cnt.item()\n",
    "            n_total += batch_size\n",
    "\n",
    "            pred_cls = log_probs.argmax(dim=1)\n",
    "\n",
    "            n_correct_cls += (pred_cls == target_cls).sum().item()\n",
    "\n",
    "            true_pair_idx = target_cls // 9\n",
    "            pred_pair_idx = pred_cls // 9\n",
    "            n_correct_pair += (true_pair_idx == pred_pair_idx).sum().item()\n",
    "\n",
    "            for t, p in zip(target_cls.view(-1), pred_cls.view(-1)):\n",
    "                conf_mat[t.item(), p.item()] += 1\n",
    "\n",
    "            diff = counts - target_cnt          # (B, 6)\n",
    "            sq_err = diff ** 2\n",
    "            abs_err = diff.abs()\n",
    "\n",
    "            sum_sq_err_per_class += sq_err.sum(dim=0).cpu()\n",
    "            sum_abs_err_per_class += abs_err.sum(dim=0).cpu()\n",
    "\n",
    "    # average losses\n",
    "    avg_loss_cls = total_loss_cls / n_total\n",
    "    avg_loss_cnt = total_loss_cnt / n_total\n",
    "    avg_loss_total = avg_loss_cls + lambda_cnt * avg_loss_cnt\n",
    "\n",
    "    # --- classification: top-1 & per-pair ---\n",
    "    top1_acc = n_correct_cls / n_total\n",
    "    pair_acc = n_correct_pair / n_total\n",
    "\n",
    "    # --- macro F1 over 135 classes ---\n",
    "    f1_per_class = []\n",
    "    for c in range(n_classes):\n",
    "        tp = conf_mat[c, c].item()\n",
    "        fp = conf_mat[:, c].sum().item() - tp\n",
    "        fn = conf_mat[c, :].sum().item() - tp\n",
    "\n",
    "        if tp == 0 and fp == 0 and fn == 0:\n",
    "            f1 = 0.0  # class never appears\n",
    "        else:\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            if precision + recall == 0:\n",
    "                f1 = 0.0\n",
    "            else:\n",
    "                f1 = 2 * precision * recall / (precision + recall)\n",
    "        f1_per_class.append(f1)\n",
    "\n",
    "    macro_f1 = sum(f1_per_class) / n_classes\n",
    "\n",
    "    # --- regression: RMSE / MAE per class + overall ---\n",
    "    num_samples = n_total\n",
    "    rmse_per_class = (sum_sq_err_per_class / num_samples).sqrt()\n",
    "    mae_per_class = sum_abs_err_per_class / num_samples\n",
    "\n",
    "    num_elements = n_total * n_reg_targets\n",
    "    rmse_overall = (sum_sq_err_per_class.sum() / num_elements) ** 0.5\n",
    "    mae_overall = sum_abs_err_per_class.sum() / num_elements\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nTest set (epoch {epoch}):\")\n",
    "        print(f\"  Classification (135-way):\")\n",
    "        print(f\"    Top-1 accuracy: {100.0 * top1_acc:.2f}%\")\n",
    "        print(f\"    Macro F1-score: {macro_f1:.4f}\")\n",
    "        print(f\"    Per-pair accuracy (unordered pair): {100.0 * pair_acc:.2f}%\")\n",
    "\n",
    "        print(f\"\\n  Regression (6-D counts):\")\n",
    "        class_names = [\"squares\", \"circles\", \"up\", \"right\", \"down\", \"left\"]\n",
    "        print(\"    RMSE per class:\")\n",
    "        for name, v in zip(class_names, rmse_per_class):\n",
    "            print(f\"      {name:7s}: {v:.4f}\")\n",
    "        print(\"    MAE per class:\")\n",
    "        for name, v in zip(class_names, mae_per_class):\n",
    "            print(f\"      {name:7s}: {v:.4f}\")\n",
    "        print(f\"    RMSE overall: {rmse_overall:.4f}\")\n",
    "        print(f\"    MAE overall: {mae_overall:.4f}\")\n",
    "\n",
    "        print(f\"\\n  Losses:\")\n",
    "        print(f\"    cls={avg_loss_cls:.4f}, cnt={avg_loss_cnt:.4f}, total={avg_loss_total:.4f}\\n\")\n",
    "\n",
    "    # return everything so we can log/plot\n",
    "    return {\n",
    "        \"loss_cls\": avg_loss_cls,\n",
    "        \"loss_cnt\": avg_loss_cnt,\n",
    "        \"loss_total\": avg_loss_total,\n",
    "        \"top1\": top1_acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"pair_acc\": pair_acc,\n",
    "        \"rmse_per_class\": rmse_per_class,\n",
    "        \"mae_per_class\": mae_per_class,\n",
    "        \"rmse_overall\": rmse_overall.item(),\n",
    "        \"mae_overall\": mae_overall.item(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg_dRGdo3D44"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "kYxMHoc43HRA"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lambda_cnt = 1      # auxiliary regression weight\n",
    "lr = 1e-3             # lowered LR\n",
    "weight_decay = 1e-4   # regularization for large linear layer\n",
    "log_interval = 20\n",
    "label_smoothing = 0.05\n",
    "\n",
    "# Early stopping hyperparameters (added)\n",
    "early_stopping_patience = 10\n",
    "early_stopping_min_delta = 0.0  # minimum improvement to reset patience\n",
    "\n",
    "train_losses = []\n",
    "train_top1 = []\n",
    "train_pair_acc = []\n",
    "val_losses = []\n",
    "val_top1 = []\n",
    "val_pair_acc = []\n",
    "val_rmse_overall = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSVAJwY0dxqo"
   },
   "source": [
    "### Fixes Applied\n",
    "- Per-transform probability augmentation (safer).\n",
    "- Orientation labels kept consistent after spatial ops.\n",
    "- Input normalization (centered).\n",
    "- Label smoothing for 135-way classification.\n",
    "- Tracking train top-1 and pair accuracy to detect underfitting.\n",
    "- Added auxiliary regression loss (lambda_cnt=0.1).\n",
    "- Reduced LR and added weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GnzDL1pSAot5",
    "outputId": "c6bfe403-0588-4db4-861a-3a41a2be10ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/8100] Loss=6.4146\n",
      "Train Epoch: 1 [1280/8100] Loss=6.2121\n",
      "Train Epoch: 1 [2560/8100] Loss=6.1944\n",
      "Train Epoch: 1 [1280/8100] Loss=6.2121\n",
      "Train Epoch: 1 [2560/8100] Loss=6.1944\n",
      "Train Epoch: 1 [3840/8100] Loss=6.1515\n",
      "Train Epoch: 1 [3840/8100] Loss=6.1515\n",
      "Train Epoch: 1 [5120/8100] Loss=6.1261\n",
      "Train Epoch: 1 [6400/8100] Loss=6.1707\n",
      "Train Epoch: 1 [5120/8100] Loss=6.1261\n",
      "Train Epoch: 1 [6400/8100] Loss=6.1707\n",
      "Train Epoch: 1 [7680/8100] Loss=6.1249\n",
      "Train Epoch: 1 [7680/8100] Loss=6.1249\n",
      "\n",
      "Test set (epoch 1):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 1.22%\n",
      "    Macro F1-score: 0.0004\n",
      "    Per-pair accuracy (unordered pair): 9.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 2.9944\n",
      "      circles: 2.8320\n",
      "      up     : 2.7985\n",
      "      right  : 2.7721\n",
      "      down   : 2.9164\n",
      "      left   : 2.9165\n",
      "    MAE per class:\n",
      "      squares: 1.9293\n",
      "      circles: 1.7056\n",
      "      up     : 1.6756\n",
      "      right  : 1.7426\n",
      "      down   : 1.8046\n",
      "      left   : 1.8156\n",
      "    RMSE overall: 2.8727\n",
      "    MAE overall: 1.7789\n",
      "\n",
      "  Losses:\n",
      "    cls=4.6659, cnt=8.3876, total=13.0535\n",
      "\n",
      "Improved val loss to 13.0535 at epoch 1\n",
      "\n",
      "Test set (epoch 1):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 1.22%\n",
      "    Macro F1-score: 0.0004\n",
      "    Per-pair accuracy (unordered pair): 9.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 2.9944\n",
      "      circles: 2.8320\n",
      "      up     : 2.7985\n",
      "      right  : 2.7721\n",
      "      down   : 2.9164\n",
      "      left   : 2.9165\n",
      "    MAE per class:\n",
      "      squares: 1.9293\n",
      "      circles: 1.7056\n",
      "      up     : 1.6756\n",
      "      right  : 1.7426\n",
      "      down   : 1.8046\n",
      "      left   : 1.8156\n",
      "    RMSE overall: 2.8727\n",
      "    MAE overall: 1.7789\n",
      "\n",
      "  Losses:\n",
      "    cls=4.6659, cnt=8.3876, total=13.0535\n",
      "\n",
      "Improved val loss to 13.0535 at epoch 1\n",
      "Train Epoch: 2 [0/8100] Loss=6.1060\n",
      "Train Epoch: 2 [1280/8100] Loss=5.7293\n",
      "Train Epoch: 2 [0/8100] Loss=6.1060\n",
      "Train Epoch: 2 [1280/8100] Loss=5.7293\n",
      "Train Epoch: 2 [2560/8100] Loss=5.6000\n",
      "Train Epoch: 2 [2560/8100] Loss=5.6000\n",
      "Train Epoch: 2 [3840/8100] Loss=5.4445\n",
      "Train Epoch: 2 [5120/8100] Loss=4.6744\n",
      "Train Epoch: 2 [3840/8100] Loss=5.4445\n",
      "Train Epoch: 2 [5120/8100] Loss=4.6744\n",
      "Train Epoch: 2 [6400/8100] Loss=4.5497\n",
      "Train Epoch: 2 [6400/8100] Loss=4.5497\n",
      "Train Epoch: 2 [7680/8100] Loss=4.6223\n",
      "Train Epoch: 2 [7680/8100] Loss=4.6223\n",
      "\n",
      "Test set (epoch 2):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 9.00%\n",
      "    Macro F1-score: 0.0340\n",
      "    Per-pair accuracy (unordered pair): 42.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 1.8507\n",
      "      circles: 2.6761\n",
      "      up     : 1.7299\n",
      "      right  : 1.4991\n",
      "      down   : 2.5400\n",
      "      left   : 1.5094\n",
      "    MAE per class:\n",
      "      squares: 1.2445\n",
      "      circles: 1.7287\n",
      "      up     : 1.0815\n",
      "      right  : 0.8933\n",
      "      down   : 1.6330\n",
      "      left   : 1.0255\n",
      "    RMSE overall: 2.0231\n",
      "    MAE overall: 1.2678\n",
      "\n",
      "  Losses:\n",
      "    cls=3.2414, cnt=5.5494, total=8.7907\n",
      "\n",
      "Improved val loss to 8.7907 at epoch 2\n",
      "\n",
      "Test set (epoch 2):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 9.00%\n",
      "    Macro F1-score: 0.0340\n",
      "    Per-pair accuracy (unordered pair): 42.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 1.8507\n",
      "      circles: 2.6761\n",
      "      up     : 1.7299\n",
      "      right  : 1.4991\n",
      "      down   : 2.5400\n",
      "      left   : 1.5094\n",
      "    MAE per class:\n",
      "      squares: 1.2445\n",
      "      circles: 1.7287\n",
      "      up     : 1.0815\n",
      "      right  : 0.8933\n",
      "      down   : 1.6330\n",
      "      left   : 1.0255\n",
      "    RMSE overall: 2.0231\n",
      "    MAE overall: 1.2678\n",
      "\n",
      "  Losses:\n",
      "    cls=3.2414, cnt=5.5494, total=8.7907\n",
      "\n",
      "Improved val loss to 8.7907 at epoch 2\n",
      "Train Epoch: 3 [0/8100] Loss=4.4757\n",
      "Train Epoch: 3 [1280/8100] Loss=4.1990\n",
      "Train Epoch: 3 [0/8100] Loss=4.4757\n",
      "Train Epoch: 3 [1280/8100] Loss=4.1990\n",
      "Train Epoch: 3 [2560/8100] Loss=4.2536\n",
      "Train Epoch: 3 [2560/8100] Loss=4.2536\n",
      "Train Epoch: 3 [3840/8100] Loss=3.8085\n",
      "Train Epoch: 3 [5120/8100] Loss=4.0843\n",
      "Train Epoch: 3 [3840/8100] Loss=3.8085\n",
      "Train Epoch: 3 [5120/8100] Loss=4.0843\n",
      "Train Epoch: 3 [6400/8100] Loss=4.1988\n",
      "Train Epoch: 3 [6400/8100] Loss=4.1988\n",
      "Train Epoch: 3 [7680/8100] Loss=3.6096\n",
      "Train Epoch: 3 [7680/8100] Loss=3.6096\n",
      "\n",
      "Test set (epoch 3):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 18.33%\n",
      "    Macro F1-score: 0.0884\n",
      "    Per-pair accuracy (unordered pair): 61.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 1.4634\n",
      "      circles: 2.4591\n",
      "      up     : 1.4286\n",
      "      right  : 1.1195\n",
      "      down   : 1.2725\n",
      "      left   : 1.3687\n",
      "    MAE per class:\n",
      "      squares: 0.8741\n",
      "      circles: 1.6069\n",
      "      up     : 0.8205\n",
      "      right  : 0.7418\n",
      "      down   : 0.7963\n",
      "      left   : 0.8788\n",
      "    RMSE overall: 1.5798\n",
      "    MAE overall: 0.9531\n",
      "\n",
      "  Losses:\n",
      "    cls=2.6551, cnt=3.8851, total=6.5402\n",
      "\n",
      "Improved val loss to 6.5402 at epoch 3\n",
      "\n",
      "Test set (epoch 3):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 18.33%\n",
      "    Macro F1-score: 0.0884\n",
      "    Per-pair accuracy (unordered pair): 61.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 1.4634\n",
      "      circles: 2.4591\n",
      "      up     : 1.4286\n",
      "      right  : 1.1195\n",
      "      down   : 1.2725\n",
      "      left   : 1.3687\n",
      "    MAE per class:\n",
      "      squares: 0.8741\n",
      "      circles: 1.6069\n",
      "      up     : 0.8205\n",
      "      right  : 0.7418\n",
      "      down   : 0.7963\n",
      "      left   : 0.8788\n",
      "    RMSE overall: 1.5798\n",
      "    MAE overall: 0.9531\n",
      "\n",
      "  Losses:\n",
      "    cls=2.6551, cnt=3.8851, total=6.5402\n",
      "\n",
      "Improved val loss to 6.5402 at epoch 3\n",
      "Train Epoch: 4 [0/8100] Loss=3.7913\n",
      "Train Epoch: 4 [1280/8100] Loss=3.8173\n",
      "Train Epoch: 4 [0/8100] Loss=3.7913\n",
      "Train Epoch: 4 [1280/8100] Loss=3.8173\n",
      "Train Epoch: 4 [2560/8100] Loss=3.3682\n",
      "Train Epoch: 4 [2560/8100] Loss=3.3682\n",
      "Train Epoch: 4 [3840/8100] Loss=3.5077\n",
      "Train Epoch: 4 [5120/8100] Loss=3.4509\n",
      "Train Epoch: 4 [3840/8100] Loss=3.5077\n",
      "Train Epoch: 4 [5120/8100] Loss=3.4509\n",
      "Train Epoch: 4 [6400/8100] Loss=3.2688\n",
      "Train Epoch: 4 [6400/8100] Loss=3.2688\n",
      "Train Epoch: 4 [7680/8100] Loss=3.0254\n",
      "Train Epoch: 4 [7680/8100] Loss=3.0254\n",
      "\n",
      "Test set (epoch 4):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 24.00%\n",
      "    Macro F1-score: 0.1309\n",
      "    Per-pair accuracy (unordered pair): 75.33%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 1.2401\n",
      "      circles: 1.3484\n",
      "      up     : 1.2142\n",
      "      right  : 1.0937\n",
      "      down   : 1.4700\n",
      "      left   : 1.0954\n",
      "    MAE per class:\n",
      "      squares: 0.7255\n",
      "      circles: 0.9041\n",
      "      up     : 0.7607\n",
      "      right  : 0.6335\n",
      "      down   : 0.7859\n",
      "      left   : 0.6482\n",
      "    RMSE overall: 1.2508\n",
      "    MAE overall: 0.7430\n",
      "\n",
      "  Losses:\n",
      "    cls=2.2754, cnt=2.8288, total=5.1042\n",
      "\n",
      "Improved val loss to 5.1042 at epoch 4\n",
      "\n",
      "Test set (epoch 4):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 24.00%\n",
      "    Macro F1-score: 0.1309\n",
      "    Per-pair accuracy (unordered pair): 75.33%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 1.2401\n",
      "      circles: 1.3484\n",
      "      up     : 1.2142\n",
      "      right  : 1.0937\n",
      "      down   : 1.4700\n",
      "      left   : 1.0954\n",
      "    MAE per class:\n",
      "      squares: 0.7255\n",
      "      circles: 0.9041\n",
      "      up     : 0.7607\n",
      "      right  : 0.6335\n",
      "      down   : 0.7859\n",
      "      left   : 0.6482\n",
      "    RMSE overall: 1.2508\n",
      "    MAE overall: 0.7430\n",
      "\n",
      "  Losses:\n",
      "    cls=2.2754, cnt=2.8288, total=5.1042\n",
      "\n",
      "Improved val loss to 5.1042 at epoch 4\n",
      "Train Epoch: 5 [0/8100] Loss=3.0926\n",
      "Train Epoch: 5 [1280/8100] Loss=3.1458\n",
      "Train Epoch: 5 [0/8100] Loss=3.0926\n",
      "Train Epoch: 5 [1280/8100] Loss=3.1458\n",
      "Train Epoch: 5 [2560/8100] Loss=3.1810\n",
      "Train Epoch: 5 [2560/8100] Loss=3.1810\n",
      "Train Epoch: 5 [3840/8100] Loss=2.8437\n",
      "Train Epoch: 5 [5120/8100] Loss=2.8997\n",
      "Train Epoch: 5 [3840/8100] Loss=2.8437\n",
      "Train Epoch: 5 [5120/8100] Loss=2.8997\n",
      "Train Epoch: 5 [6400/8100] Loss=2.8665\n",
      "Train Epoch: 5 [6400/8100] Loss=2.8665\n",
      "Train Epoch: 5 [7680/8100] Loss=3.0049\n",
      "Train Epoch: 5 [7680/8100] Loss=3.0049\n",
      "\n",
      "Test set (epoch 5):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 28.33%\n",
      "    Macro F1-score: 0.1602\n",
      "    Per-pair accuracy (unordered pair): 81.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 1.1291\n",
      "      circles: 1.0311\n",
      "      up     : 1.1444\n",
      "      right  : 0.9205\n",
      "      down   : 1.2617\n",
      "      left   : 0.8866\n",
      "    MAE per class:\n",
      "      squares: 0.6859\n",
      "      circles: 0.7116\n",
      "      up     : 0.6667\n",
      "      right  : 0.5435\n",
      "      down   : 0.6584\n",
      "      left   : 0.5381\n",
      "    RMSE overall: 1.0703\n",
      "    MAE overall: 0.6340\n",
      "\n",
      "  Losses:\n",
      "    cls=2.0544, cnt=2.2608, total=4.3152\n",
      "\n",
      "Improved val loss to 4.3152 at epoch 5\n",
      "\n",
      "Test set (epoch 5):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 28.33%\n",
      "    Macro F1-score: 0.1602\n",
      "    Per-pair accuracy (unordered pair): 81.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 1.1291\n",
      "      circles: 1.0311\n",
      "      up     : 1.1444\n",
      "      right  : 0.9205\n",
      "      down   : 1.2617\n",
      "      left   : 0.8866\n",
      "    MAE per class:\n",
      "      squares: 0.6859\n",
      "      circles: 0.7116\n",
      "      up     : 0.6667\n",
      "      right  : 0.5435\n",
      "      down   : 0.6584\n",
      "      left   : 0.5381\n",
      "    RMSE overall: 1.0703\n",
      "    MAE overall: 0.6340\n",
      "\n",
      "  Losses:\n",
      "    cls=2.0544, cnt=2.2608, total=4.3152\n",
      "\n",
      "Improved val loss to 4.3152 at epoch 5\n",
      "Train Epoch: 6 [0/8100] Loss=2.7535\n",
      "Train Epoch: 6 [1280/8100] Loss=2.9405\n",
      "Train Epoch: 6 [0/8100] Loss=2.7535\n",
      "Train Epoch: 6 [1280/8100] Loss=2.9405\n",
      "Train Epoch: 6 [2560/8100] Loss=2.8124\n",
      "Train Epoch: 6 [2560/8100] Loss=2.8124\n",
      "Train Epoch: 6 [3840/8100] Loss=2.7807\n",
      "Train Epoch: 6 [5120/8100] Loss=2.9266\n",
      "Train Epoch: 6 [3840/8100] Loss=2.7807\n",
      "Train Epoch: 6 [5120/8100] Loss=2.9266\n",
      "Train Epoch: 6 [6400/8100] Loss=2.7929\n",
      "Train Epoch: 6 [6400/8100] Loss=2.7929\n",
      "Train Epoch: 6 [7680/8100] Loss=2.6435\n",
      "Train Epoch: 6 [7680/8100] Loss=2.6435\n",
      "\n",
      "Test set (epoch 6):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 29.67%\n",
      "    Macro F1-score: 0.1705\n",
      "    Per-pair accuracy (unordered pair): 84.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.9494\n",
      "      circles: 0.8227\n",
      "      up     : 1.0509\n",
      "      right  : 0.8887\n",
      "      down   : 1.0502\n",
      "      left   : 1.0364\n",
      "    MAE per class:\n",
      "      squares: 0.6058\n",
      "      circles: 0.5259\n",
      "      up     : 0.5536\n",
      "      right  : 0.4834\n",
      "      down   : 0.5979\n",
      "      left   : 0.5636\n",
      "    RMSE overall: 0.9703\n",
      "    MAE overall: 0.5550\n",
      "\n",
      "  Losses:\n",
      "    cls=1.9342, cnt=1.9329, total=3.8671\n",
      "\n",
      "Improved val loss to 3.8671 at epoch 6\n",
      "\n",
      "Test set (epoch 6):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 29.67%\n",
      "    Macro F1-score: 0.1705\n",
      "    Per-pair accuracy (unordered pair): 84.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.9494\n",
      "      circles: 0.8227\n",
      "      up     : 1.0509\n",
      "      right  : 0.8887\n",
      "      down   : 1.0502\n",
      "      left   : 1.0364\n",
      "    MAE per class:\n",
      "      squares: 0.6058\n",
      "      circles: 0.5259\n",
      "      up     : 0.5536\n",
      "      right  : 0.4834\n",
      "      down   : 0.5979\n",
      "      left   : 0.5636\n",
      "    RMSE overall: 0.9703\n",
      "    MAE overall: 0.5550\n",
      "\n",
      "  Losses:\n",
      "    cls=1.9342, cnt=1.9329, total=3.8671\n",
      "\n",
      "Improved val loss to 3.8671 at epoch 6\n",
      "Train Epoch: 7 [0/8100] Loss=2.8019\n",
      "Train Epoch: 7 [1280/8100] Loss=2.6239\n",
      "Train Epoch: 7 [0/8100] Loss=2.8019\n",
      "Train Epoch: 7 [1280/8100] Loss=2.6239\n",
      "Train Epoch: 7 [2560/8100] Loss=2.6584\n",
      "Train Epoch: 7 [2560/8100] Loss=2.6584\n",
      "Train Epoch: 7 [3840/8100] Loss=2.3816\n",
      "Train Epoch: 7 [5120/8100] Loss=2.5214\n",
      "Train Epoch: 7 [3840/8100] Loss=2.3816\n",
      "Train Epoch: 7 [5120/8100] Loss=2.5214\n",
      "Train Epoch: 7 [6400/8100] Loss=2.5703\n",
      "Train Epoch: 7 [6400/8100] Loss=2.5703\n",
      "Train Epoch: 7 [7680/8100] Loss=2.4472\n",
      "Train Epoch: 7 [7680/8100] Loss=2.4472\n",
      "\n",
      "Test set (epoch 7):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 29.44%\n",
      "    Macro F1-score: 0.1835\n",
      "    Per-pair accuracy (unordered pair): 84.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.9072\n",
      "      circles: 0.8299\n",
      "      up     : 0.9024\n",
      "      right  : 0.8272\n",
      "      down   : 0.9383\n",
      "      left   : 0.8375\n",
      "    MAE per class:\n",
      "      squares: 0.5272\n",
      "      circles: 0.5437\n",
      "      up     : 0.4921\n",
      "      right  : 0.4693\n",
      "      down   : 0.6186\n",
      "      left   : 0.4509\n",
      "    RMSE overall: 0.8748\n",
      "    MAE overall: 0.5170\n",
      "\n",
      "  Losses:\n",
      "    cls=1.8634, cnt=1.7069, total=3.5702\n",
      "\n",
      "Improved val loss to 3.5702 at epoch 7\n",
      "\n",
      "Test set (epoch 7):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 29.44%\n",
      "    Macro F1-score: 0.1835\n",
      "    Per-pair accuracy (unordered pair): 84.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.9072\n",
      "      circles: 0.8299\n",
      "      up     : 0.9024\n",
      "      right  : 0.8272\n",
      "      down   : 0.9383\n",
      "      left   : 0.8375\n",
      "    MAE per class:\n",
      "      squares: 0.5272\n",
      "      circles: 0.5437\n",
      "      up     : 0.4921\n",
      "      right  : 0.4693\n",
      "      down   : 0.6186\n",
      "      left   : 0.4509\n",
      "    RMSE overall: 0.8748\n",
      "    MAE overall: 0.5170\n",
      "\n",
      "  Losses:\n",
      "    cls=1.8634, cnt=1.7069, total=3.5702\n",
      "\n",
      "Improved val loss to 3.5702 at epoch 7\n",
      "Train Epoch: 8 [0/8100] Loss=2.6037\n",
      "Train Epoch: 8 [1280/8100] Loss=2.3898\n",
      "Train Epoch: 8 [0/8100] Loss=2.6037\n",
      "Train Epoch: 8 [1280/8100] Loss=2.3898\n",
      "Train Epoch: 8 [2560/8100] Loss=2.5252\n",
      "Train Epoch: 8 [2560/8100] Loss=2.5252\n",
      "Train Epoch: 8 [3840/8100] Loss=2.3484\n",
      "Train Epoch: 8 [5120/8100] Loss=2.3775\n",
      "Train Epoch: 8 [3840/8100] Loss=2.3484\n",
      "Train Epoch: 8 [5120/8100] Loss=2.3775\n",
      "Train Epoch: 8 [6400/8100] Loss=2.5325\n",
      "Train Epoch: 8 [6400/8100] Loss=2.5325\n",
      "Train Epoch: 8 [7680/8100] Loss=2.5174\n",
      "Train Epoch: 8 [7680/8100] Loss=2.5174\n",
      "\n",
      "Test set (epoch 8):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 32.44%\n",
      "    Macro F1-score: 0.1963\n",
      "    Per-pair accuracy (unordered pair): 85.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.7666\n",
      "      circles: 1.1437\n",
      "      up     : 0.8138\n",
      "      right  : 0.8369\n",
      "      down   : 0.8274\n",
      "      left   : 0.8298\n",
      "    MAE per class:\n",
      "      squares: 0.4518\n",
      "      circles: 0.6257\n",
      "      up     : 0.4960\n",
      "      right  : 0.4479\n",
      "      down   : 0.4946\n",
      "      left   : 0.4778\n",
      "    RMSE overall: 0.8786\n",
      "    MAE overall: 0.4990\n",
      "\n",
      "  Losses:\n",
      "    cls=1.8241, cnt=1.6707, total=3.4949\n",
      "\n",
      "Improved val loss to 3.4949 at epoch 8\n",
      "\n",
      "Test set (epoch 8):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 32.44%\n",
      "    Macro F1-score: 0.1963\n",
      "    Per-pair accuracy (unordered pair): 85.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.7666\n",
      "      circles: 1.1437\n",
      "      up     : 0.8138\n",
      "      right  : 0.8369\n",
      "      down   : 0.8274\n",
      "      left   : 0.8298\n",
      "    MAE per class:\n",
      "      squares: 0.4518\n",
      "      circles: 0.6257\n",
      "      up     : 0.4960\n",
      "      right  : 0.4479\n",
      "      down   : 0.4946\n",
      "      left   : 0.4778\n",
      "    RMSE overall: 0.8786\n",
      "    MAE overall: 0.4990\n",
      "\n",
      "  Losses:\n",
      "    cls=1.8241, cnt=1.6707, total=3.4949\n",
      "\n",
      "Improved val loss to 3.4949 at epoch 8\n",
      "Train Epoch: 9 [0/8100] Loss=2.3868\n",
      "Train Epoch: 9 [1280/8100] Loss=2.4409\n",
      "Train Epoch: 9 [0/8100] Loss=2.3868\n",
      "Train Epoch: 9 [1280/8100] Loss=2.4409\n",
      "Train Epoch: 9 [2560/8100] Loss=2.4601\n",
      "Train Epoch: 9 [2560/8100] Loss=2.4601\n",
      "Train Epoch: 9 [3840/8100] Loss=2.4535\n",
      "Train Epoch: 9 [5120/8100] Loss=2.4324\n",
      "Train Epoch: 9 [3840/8100] Loss=2.4535\n",
      "Train Epoch: 9 [5120/8100] Loss=2.4324\n",
      "Train Epoch: 9 [6400/8100] Loss=2.2142\n",
      "Train Epoch: 9 [6400/8100] Loss=2.2142\n",
      "Train Epoch: 9 [7680/8100] Loss=2.1877\n",
      "Train Epoch: 9 [7680/8100] Loss=2.1877\n",
      "\n",
      "Test set (epoch 9):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 30.44%\n",
      "    Macro F1-score: 0.1916\n",
      "    Per-pair accuracy (unordered pair): 86.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.7819\n",
      "      circles: 0.7577\n",
      "      up     : 0.8478\n",
      "      right  : 0.8118\n",
      "      down   : 0.7819\n",
      "      left   : 1.0695\n",
      "    MAE per class:\n",
      "      squares: 0.5335\n",
      "      circles: 0.4278\n",
      "      up     : 0.5156\n",
      "      right  : 0.4375\n",
      "      down   : 0.4838\n",
      "      left   : 0.5533\n",
      "    RMSE overall: 0.8484\n",
      "    MAE overall: 0.4919\n",
      "\n",
      "  Losses:\n",
      "    cls=1.8277, cnt=1.6105, total=3.4382\n",
      "\n",
      "Improved val loss to 3.4382 at epoch 9\n",
      "\n",
      "Test set (epoch 9):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 30.44%\n",
      "    Macro F1-score: 0.1916\n",
      "    Per-pair accuracy (unordered pair): 86.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.7819\n",
      "      circles: 0.7577\n",
      "      up     : 0.8478\n",
      "      right  : 0.8118\n",
      "      down   : 0.7819\n",
      "      left   : 1.0695\n",
      "    MAE per class:\n",
      "      squares: 0.5335\n",
      "      circles: 0.4278\n",
      "      up     : 0.5156\n",
      "      right  : 0.4375\n",
      "      down   : 0.4838\n",
      "      left   : 0.5533\n",
      "    RMSE overall: 0.8484\n",
      "    MAE overall: 0.4919\n",
      "\n",
      "  Losses:\n",
      "    cls=1.8277, cnt=1.6105, total=3.4382\n",
      "\n",
      "Improved val loss to 3.4382 at epoch 9\n",
      "Train Epoch: 10 [0/8100] Loss=2.3106\n",
      "Train Epoch: 10 [1280/8100] Loss=2.1533\n",
      "Train Epoch: 10 [0/8100] Loss=2.3106\n",
      "Train Epoch: 10 [1280/8100] Loss=2.1533\n",
      "Train Epoch: 10 [2560/8100] Loss=2.3694\n",
      "Train Epoch: 10 [2560/8100] Loss=2.3694\n",
      "Train Epoch: 10 [3840/8100] Loss=2.1198\n",
      "Train Epoch: 10 [5120/8100] Loss=2.3737\n",
      "Train Epoch: 10 [3840/8100] Loss=2.1198\n",
      "Train Epoch: 10 [5120/8100] Loss=2.3737\n",
      "Train Epoch: 10 [6400/8100] Loss=2.3841\n",
      "Train Epoch: 10 [6400/8100] Loss=2.3841\n",
      "Train Epoch: 10 [7680/8100] Loss=2.3957\n",
      "Train Epoch: 10 [7680/8100] Loss=2.3957\n",
      "\n",
      "Test set (epoch 10):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 36.44%\n",
      "    Macro F1-score: 0.2375\n",
      "    Per-pair accuracy (unordered pair): 87.67%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.8250\n",
      "      circles: 0.7064\n",
      "      up     : 0.7880\n",
      "      right  : 0.7321\n",
      "      down   : 0.8388\n",
      "      left   : 0.7375\n",
      "    MAE per class:\n",
      "      squares: 0.4500\n",
      "      circles: 0.3785\n",
      "      up     : 0.4327\n",
      "      right  : 0.4425\n",
      "      down   : 0.4899\n",
      "      left   : 0.4222\n",
      "    RMSE overall: 0.7729\n",
      "    MAE overall: 0.4360\n",
      "\n",
      "  Losses:\n",
      "    cls=1.6765, cnt=1.3773, total=3.0538\n",
      "\n",
      "Improved val loss to 3.0538 at epoch 10\n",
      "\n",
      "Test set (epoch 10):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 36.44%\n",
      "    Macro F1-score: 0.2375\n",
      "    Per-pair accuracy (unordered pair): 87.67%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.8250\n",
      "      circles: 0.7064\n",
      "      up     : 0.7880\n",
      "      right  : 0.7321\n",
      "      down   : 0.8388\n",
      "      left   : 0.7375\n",
      "    MAE per class:\n",
      "      squares: 0.4500\n",
      "      circles: 0.3785\n",
      "      up     : 0.4327\n",
      "      right  : 0.4425\n",
      "      down   : 0.4899\n",
      "      left   : 0.4222\n",
      "    RMSE overall: 0.7729\n",
      "    MAE overall: 0.4360\n",
      "\n",
      "  Losses:\n",
      "    cls=1.6765, cnt=1.3773, total=3.0538\n",
      "\n",
      "Improved val loss to 3.0538 at epoch 10\n",
      "Train Epoch: 11 [0/8100] Loss=2.2562\n",
      "Train Epoch: 11 [1280/8100] Loss=2.0333\n",
      "Train Epoch: 11 [0/8100] Loss=2.2562\n",
      "Train Epoch: 11 [1280/8100] Loss=2.0333\n",
      "Train Epoch: 11 [2560/8100] Loss=2.1872\n",
      "Train Epoch: 11 [2560/8100] Loss=2.1872\n",
      "Train Epoch: 11 [3840/8100] Loss=2.2147\n",
      "Train Epoch: 11 [5120/8100] Loss=2.2423\n",
      "Train Epoch: 11 [3840/8100] Loss=2.2147\n",
      "Train Epoch: 11 [5120/8100] Loss=2.2423\n",
      "Train Epoch: 11 [6400/8100] Loss=2.4498\n",
      "Train Epoch: 11 [6400/8100] Loss=2.4498\n",
      "Train Epoch: 11 [7680/8100] Loss=2.1829\n",
      "Train Epoch: 11 [7680/8100] Loss=2.1829\n",
      "\n",
      "Test set (epoch 11):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 37.56%\n",
      "    Macro F1-score: 0.2448\n",
      "    Per-pair accuracy (unordered pair): 90.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6933\n",
      "      circles: 0.6065\n",
      "      up     : 0.7179\n",
      "      right  : 0.7106\n",
      "      down   : 0.7567\n",
      "      left   : 0.7919\n",
      "    MAE per class:\n",
      "      squares: 0.3870\n",
      "      circles: 0.3632\n",
      "      up     : 0.3903\n",
      "      right  : 0.3999\n",
      "      down   : 0.4227\n",
      "      left   : 0.4225\n",
      "    RMSE overall: 0.7151\n",
      "    MAE overall: 0.3976\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5794, cnt=1.2040, total=2.7833\n",
      "\n",
      "Improved val loss to 2.7833 at epoch 11\n",
      "\n",
      "Test set (epoch 11):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 37.56%\n",
      "    Macro F1-score: 0.2448\n",
      "    Per-pair accuracy (unordered pair): 90.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6933\n",
      "      circles: 0.6065\n",
      "      up     : 0.7179\n",
      "      right  : 0.7106\n",
      "      down   : 0.7567\n",
      "      left   : 0.7919\n",
      "    MAE per class:\n",
      "      squares: 0.3870\n",
      "      circles: 0.3632\n",
      "      up     : 0.3903\n",
      "      right  : 0.3999\n",
      "      down   : 0.4227\n",
      "      left   : 0.4225\n",
      "    RMSE overall: 0.7151\n",
      "    MAE overall: 0.3976\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5794, cnt=1.2040, total=2.7833\n",
      "\n",
      "Improved val loss to 2.7833 at epoch 11\n",
      "Train Epoch: 12 [0/8100] Loss=2.1139\n",
      "Train Epoch: 12 [1280/8100] Loss=2.0452\n",
      "Train Epoch: 12 [0/8100] Loss=2.1139\n",
      "Train Epoch: 12 [1280/8100] Loss=2.0452\n",
      "Train Epoch: 12 [2560/8100] Loss=2.2391\n",
      "Train Epoch: 12 [2560/8100] Loss=2.2391\n",
      "Train Epoch: 12 [3840/8100] Loss=2.1353\n",
      "Train Epoch: 12 [5120/8100] Loss=2.1574\n",
      "Train Epoch: 12 [3840/8100] Loss=2.1353\n",
      "Train Epoch: 12 [5120/8100] Loss=2.1574\n",
      "Train Epoch: 12 [6400/8100] Loss=2.0261\n",
      "Train Epoch: 12 [6400/8100] Loss=2.0261\n",
      "Train Epoch: 12 [7680/8100] Loss=2.1512\n",
      "Train Epoch: 12 [7680/8100] Loss=2.1512\n",
      "\n",
      "Test set (epoch 12):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 42.67%\n",
      "    Macro F1-score: 0.2830\n",
      "    Per-pair accuracy (unordered pair): 91.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6836\n",
      "      circles: 0.6238\n",
      "      up     : 0.6928\n",
      "      right  : 0.6912\n",
      "      down   : 0.7483\n",
      "      left   : 0.7520\n",
      "    MAE per class:\n",
      "      squares: 0.3950\n",
      "      circles: 0.3514\n",
      "      up     : 0.3809\n",
      "      right  : 0.4065\n",
      "      down   : 0.3954\n",
      "      left   : 0.4397\n",
      "    RMSE overall: 0.6999\n",
      "    MAE overall: 0.3948\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5221, cnt=1.1701, total=2.6922\n",
      "\n",
      "Improved val loss to 2.6922 at epoch 12\n",
      "\n",
      "Test set (epoch 12):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 42.67%\n",
      "    Macro F1-score: 0.2830\n",
      "    Per-pair accuracy (unordered pair): 91.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6836\n",
      "      circles: 0.6238\n",
      "      up     : 0.6928\n",
      "      right  : 0.6912\n",
      "      down   : 0.7483\n",
      "      left   : 0.7520\n",
      "    MAE per class:\n",
      "      squares: 0.3950\n",
      "      circles: 0.3514\n",
      "      up     : 0.3809\n",
      "      right  : 0.4065\n",
      "      down   : 0.3954\n",
      "      left   : 0.4397\n",
      "    RMSE overall: 0.6999\n",
      "    MAE overall: 0.3948\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5221, cnt=1.1701, total=2.6922\n",
      "\n",
      "Improved val loss to 2.6922 at epoch 12\n",
      "Train Epoch: 13 [0/8100] Loss=2.0087\n",
      "Train Epoch: 13 [1280/8100] Loss=2.2694\n",
      "Train Epoch: 13 [0/8100] Loss=2.0087\n",
      "Train Epoch: 13 [1280/8100] Loss=2.2694\n",
      "Train Epoch: 13 [2560/8100] Loss=2.2552\n",
      "Train Epoch: 13 [2560/8100] Loss=2.2552\n",
      "Train Epoch: 13 [3840/8100] Loss=2.2490\n",
      "Train Epoch: 13 [5120/8100] Loss=2.0117\n",
      "Train Epoch: 13 [3840/8100] Loss=2.2490\n",
      "Train Epoch: 13 [5120/8100] Loss=2.0117\n",
      "Train Epoch: 13 [6400/8100] Loss=2.3217\n",
      "Train Epoch: 13 [6400/8100] Loss=2.3217\n",
      "Train Epoch: 13 [7680/8100] Loss=2.1512\n",
      "Train Epoch: 13 [7680/8100] Loss=2.1512\n",
      "\n",
      "Test set (epoch 13):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 38.11%\n",
      "    Macro F1-score: 0.2407\n",
      "    Per-pair accuracy (unordered pair): 89.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6578\n",
      "      circles: 0.6825\n",
      "      up     : 0.8037\n",
      "      right  : 0.7774\n",
      "      down   : 0.9053\n",
      "      left   : 0.6518\n",
      "    MAE per class:\n",
      "      squares: 0.4030\n",
      "      circles: 0.4639\n",
      "      up     : 0.4340\n",
      "      right  : 0.4044\n",
      "      down   : 0.4656\n",
      "      left   : 0.3596\n",
      "    RMSE overall: 0.7520\n",
      "    MAE overall: 0.4217\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5842, cnt=1.3272, total=2.9114\n",
      "\n",
      "No improvement (val loss 2.9114); patience 1/10\n",
      "\n",
      "Test set (epoch 13):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 38.11%\n",
      "    Macro F1-score: 0.2407\n",
      "    Per-pair accuracy (unordered pair): 89.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6578\n",
      "      circles: 0.6825\n",
      "      up     : 0.8037\n",
      "      right  : 0.7774\n",
      "      down   : 0.9053\n",
      "      left   : 0.6518\n",
      "    MAE per class:\n",
      "      squares: 0.4030\n",
      "      circles: 0.4639\n",
      "      up     : 0.4340\n",
      "      right  : 0.4044\n",
      "      down   : 0.4656\n",
      "      left   : 0.3596\n",
      "    RMSE overall: 0.7520\n",
      "    MAE overall: 0.4217\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5842, cnt=1.3272, total=2.9114\n",
      "\n",
      "No improvement (val loss 2.9114); patience 1/10\n",
      "Train Epoch: 14 [0/8100] Loss=2.3068\n",
      "Train Epoch: 14 [1280/8100] Loss=2.1477\n",
      "Train Epoch: 14 [0/8100] Loss=2.3068\n",
      "Train Epoch: 14 [1280/8100] Loss=2.1477\n",
      "Train Epoch: 14 [2560/8100] Loss=2.1990\n",
      "Train Epoch: 14 [2560/8100] Loss=2.1990\n",
      "Train Epoch: 14 [3840/8100] Loss=2.0356\n",
      "Train Epoch: 14 [5120/8100] Loss=2.2350\n",
      "Train Epoch: 14 [3840/8100] Loss=2.0356\n",
      "Train Epoch: 14 [5120/8100] Loss=2.2350\n",
      "Train Epoch: 14 [6400/8100] Loss=1.9701\n",
      "Train Epoch: 14 [6400/8100] Loss=1.9701\n",
      "Train Epoch: 14 [7680/8100] Loss=2.1906\n",
      "Train Epoch: 14 [7680/8100] Loss=2.1906\n",
      "\n",
      "Test set (epoch 14):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 40.67%\n",
      "    Macro F1-score: 0.2743\n",
      "    Per-pair accuracy (unordered pair): 91.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6674\n",
      "      circles: 0.7005\n",
      "      up     : 0.6835\n",
      "      right  : 0.6735\n",
      "      down   : 0.6844\n",
      "      left   : 0.7127\n",
      "    MAE per class:\n",
      "      squares: 0.3776\n",
      "      circles: 0.3883\n",
      "      up     : 0.3801\n",
      "      right  : 0.3913\n",
      "      down   : 0.4107\n",
      "      left   : 0.4089\n",
      "    RMSE overall: 0.6872\n",
      "    MAE overall: 0.3928\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4739, cnt=1.1622, total=2.6360\n",
      "\n",
      "Improved val loss to 2.6360 at epoch 14\n",
      "\n",
      "Test set (epoch 14):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 40.67%\n",
      "    Macro F1-score: 0.2743\n",
      "    Per-pair accuracy (unordered pair): 91.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6674\n",
      "      circles: 0.7005\n",
      "      up     : 0.6835\n",
      "      right  : 0.6735\n",
      "      down   : 0.6844\n",
      "      left   : 0.7127\n",
      "    MAE per class:\n",
      "      squares: 0.3776\n",
      "      circles: 0.3883\n",
      "      up     : 0.3801\n",
      "      right  : 0.3913\n",
      "      down   : 0.4107\n",
      "      left   : 0.4089\n",
      "    RMSE overall: 0.6872\n",
      "    MAE overall: 0.3928\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4739, cnt=1.1622, total=2.6360\n",
      "\n",
      "Improved val loss to 2.6360 at epoch 14\n",
      "Train Epoch: 15 [0/8100] Loss=2.0940\n",
      "Train Epoch: 15 [1280/8100] Loss=1.9468\n",
      "Train Epoch: 15 [0/8100] Loss=2.0940\n",
      "Train Epoch: 15 [1280/8100] Loss=1.9468\n",
      "Train Epoch: 15 [2560/8100] Loss=2.0748\n",
      "Train Epoch: 15 [2560/8100] Loss=2.0748\n",
      "Train Epoch: 15 [3840/8100] Loss=2.2065\n",
      "Train Epoch: 15 [5120/8100] Loss=2.2967\n",
      "Train Epoch: 15 [3840/8100] Loss=2.2065\n",
      "Train Epoch: 15 [5120/8100] Loss=2.2967\n",
      "Train Epoch: 15 [6400/8100] Loss=1.9799\n",
      "Train Epoch: 15 [6400/8100] Loss=1.9799\n",
      "Train Epoch: 15 [7680/8100] Loss=2.1455\n",
      "Train Epoch: 15 [7680/8100] Loss=2.1455\n",
      "\n",
      "Test set (epoch 15):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 41.44%\n",
      "    Macro F1-score: 0.2710\n",
      "    Per-pair accuracy (unordered pair): 91.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.7036\n",
      "      circles: 0.7110\n",
      "      up     : 0.8860\n",
      "      right  : 0.6854\n",
      "      down   : 0.7733\n",
      "      left   : 0.6861\n",
      "    MAE per class:\n",
      "      squares: 0.4534\n",
      "      circles: 0.3877\n",
      "      up     : 0.4602\n",
      "      right  : 0.3483\n",
      "      down   : 0.4214\n",
      "      left   : 0.4284\n",
      "    RMSE overall: 0.7443\n",
      "    MAE overall: 0.4166\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4857, cnt=1.2885, total=2.7742\n",
      "\n",
      "No improvement (val loss 2.7742); patience 1/10\n",
      "\n",
      "Test set (epoch 15):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 41.44%\n",
      "    Macro F1-score: 0.2710\n",
      "    Per-pair accuracy (unordered pair): 91.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.7036\n",
      "      circles: 0.7110\n",
      "      up     : 0.8860\n",
      "      right  : 0.6854\n",
      "      down   : 0.7733\n",
      "      left   : 0.6861\n",
      "    MAE per class:\n",
      "      squares: 0.4534\n",
      "      circles: 0.3877\n",
      "      up     : 0.4602\n",
      "      right  : 0.3483\n",
      "      down   : 0.4214\n",
      "      left   : 0.4284\n",
      "    RMSE overall: 0.7443\n",
      "    MAE overall: 0.4166\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4857, cnt=1.2885, total=2.7742\n",
      "\n",
      "No improvement (val loss 2.7742); patience 1/10\n",
      "Train Epoch: 16 [0/8100] Loss=1.9798\n",
      "Train Epoch: 16 [1280/8100] Loss=1.9381\n",
      "Train Epoch: 16 [0/8100] Loss=1.9798\n",
      "Train Epoch: 16 [1280/8100] Loss=1.9381\n",
      "Train Epoch: 16 [2560/8100] Loss=2.0760\n",
      "Train Epoch: 16 [2560/8100] Loss=2.0760\n",
      "Train Epoch: 16 [3840/8100] Loss=2.1023\n",
      "Train Epoch: 16 [5120/8100] Loss=1.9991\n",
      "Train Epoch: 16 [3840/8100] Loss=2.1023\n",
      "Train Epoch: 16 [5120/8100] Loss=1.9991\n",
      "Train Epoch: 16 [6400/8100] Loss=2.0517\n",
      "Train Epoch: 16 [6400/8100] Loss=2.0517\n",
      "Train Epoch: 16 [7680/8100] Loss=2.0218\n",
      "Train Epoch: 16 [7680/8100] Loss=2.0218\n",
      "\n",
      "Test set (epoch 16):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 40.89%\n",
      "    Macro F1-score: 0.2873\n",
      "    Per-pair accuracy (unordered pair): 91.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5754\n",
      "      circles: 0.6079\n",
      "      up     : 0.7695\n",
      "      right  : 0.7190\n",
      "      down   : 0.7457\n",
      "      left   : 0.6532\n",
      "    MAE per class:\n",
      "      squares: 0.3416\n",
      "      circles: 0.3384\n",
      "      up     : 0.3980\n",
      "      right  : 0.4350\n",
      "      down   : 0.4053\n",
      "      left   : 0.3963\n",
      "    RMSE overall: 0.6822\n",
      "    MAE overall: 0.3858\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4490, cnt=1.1288, total=2.5778\n",
      "\n",
      "Improved val loss to 2.5778 at epoch 16\n",
      "\n",
      "Test set (epoch 16):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 40.89%\n",
      "    Macro F1-score: 0.2873\n",
      "    Per-pair accuracy (unordered pair): 91.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5754\n",
      "      circles: 0.6079\n",
      "      up     : 0.7695\n",
      "      right  : 0.7190\n",
      "      down   : 0.7457\n",
      "      left   : 0.6532\n",
      "    MAE per class:\n",
      "      squares: 0.3416\n",
      "      circles: 0.3384\n",
      "      up     : 0.3980\n",
      "      right  : 0.4350\n",
      "      down   : 0.4053\n",
      "      left   : 0.3963\n",
      "    RMSE overall: 0.6822\n",
      "    MAE overall: 0.3858\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4490, cnt=1.1288, total=2.5778\n",
      "\n",
      "Improved val loss to 2.5778 at epoch 16\n",
      "Train Epoch: 17 [0/8100] Loss=1.9776\n",
      "Train Epoch: 17 [1280/8100] Loss=1.9869\n",
      "Train Epoch: 17 [0/8100] Loss=1.9776\n",
      "Train Epoch: 17 [1280/8100] Loss=1.9869\n",
      "Train Epoch: 17 [2560/8100] Loss=1.8199\n",
      "Train Epoch: 17 [2560/8100] Loss=1.8199\n",
      "Train Epoch: 17 [3840/8100] Loss=2.0037\n",
      "Train Epoch: 17 [5120/8100] Loss=1.8815\n",
      "Train Epoch: 17 [3840/8100] Loss=2.0037\n",
      "Train Epoch: 17 [5120/8100] Loss=1.8815\n",
      "Train Epoch: 17 [6400/8100] Loss=2.0708\n",
      "Train Epoch: 17 [6400/8100] Loss=2.0708\n",
      "Train Epoch: 17 [7680/8100] Loss=2.0621\n",
      "Train Epoch: 17 [7680/8100] Loss=2.0621\n",
      "\n",
      "Test set (epoch 17):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 38.67%\n",
      "    Macro F1-score: 0.2653\n",
      "    Per-pair accuracy (unordered pair): 91.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5798\n",
      "      circles: 0.5928\n",
      "      up     : 0.7514\n",
      "      right  : 0.6987\n",
      "      down   : 0.8506\n",
      "      left   : 0.7005\n",
      "    MAE per class:\n",
      "      squares: 0.3410\n",
      "      circles: 0.3788\n",
      "      up     : 0.3987\n",
      "      right  : 0.3712\n",
      "      down   : 0.4599\n",
      "      left   : 0.3652\n",
      "    RMSE overall: 0.7017\n",
      "    MAE overall: 0.3858\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5121, cnt=1.1774, total=2.6895\n",
      "\n",
      "No improvement (val loss 2.6895); patience 1/10\n",
      "\n",
      "Test set (epoch 17):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 38.67%\n",
      "    Macro F1-score: 0.2653\n",
      "    Per-pair accuracy (unordered pair): 91.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5798\n",
      "      circles: 0.5928\n",
      "      up     : 0.7514\n",
      "      right  : 0.6987\n",
      "      down   : 0.8506\n",
      "      left   : 0.7005\n",
      "    MAE per class:\n",
      "      squares: 0.3410\n",
      "      circles: 0.3788\n",
      "      up     : 0.3987\n",
      "      right  : 0.3712\n",
      "      down   : 0.4599\n",
      "      left   : 0.3652\n",
      "    RMSE overall: 0.7017\n",
      "    MAE overall: 0.3858\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5121, cnt=1.1774, total=2.6895\n",
      "\n",
      "No improvement (val loss 2.6895); patience 1/10\n",
      "Train Epoch: 18 [0/8100] Loss=2.0399\n",
      "Train Epoch: 18 [1280/8100] Loss=1.9825\n",
      "Train Epoch: 18 [0/8100] Loss=2.0399\n",
      "Train Epoch: 18 [1280/8100] Loss=1.9825\n",
      "Train Epoch: 18 [2560/8100] Loss=1.9545\n",
      "Train Epoch: 18 [2560/8100] Loss=1.9545\n",
      "Train Epoch: 18 [3840/8100] Loss=1.9904\n",
      "Train Epoch: 18 [5120/8100] Loss=1.9329\n",
      "Train Epoch: 18 [3840/8100] Loss=1.9904\n",
      "Train Epoch: 18 [5120/8100] Loss=1.9329\n",
      "Train Epoch: 18 [6400/8100] Loss=1.8823\n",
      "Train Epoch: 18 [6400/8100] Loss=1.8823\n",
      "Train Epoch: 18 [7680/8100] Loss=2.0560\n",
      "Train Epoch: 18 [7680/8100] Loss=2.0560\n",
      "\n",
      "Test set (epoch 18):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 39.89%\n",
      "    Macro F1-score: 0.2719\n",
      "    Per-pair accuracy (unordered pair): 91.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6853\n",
      "      circles: 0.6190\n",
      "      up     : 0.9807\n",
      "      right  : 0.6592\n",
      "      down   : 0.6600\n",
      "      left   : 0.6664\n",
      "    MAE per class:\n",
      "      squares: 0.3848\n",
      "      circles: 0.3723\n",
      "      up     : 0.5237\n",
      "      right  : 0.3649\n",
      "      down   : 0.3618\n",
      "      left   : 0.3629\n",
      "    RMSE overall: 0.7221\n",
      "    MAE overall: 0.3951\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5017, cnt=1.2213, total=2.7230\n",
      "\n",
      "No improvement (val loss 2.7230); patience 2/10\n",
      "\n",
      "Test set (epoch 18):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 39.89%\n",
      "    Macro F1-score: 0.2719\n",
      "    Per-pair accuracy (unordered pair): 91.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6853\n",
      "      circles: 0.6190\n",
      "      up     : 0.9807\n",
      "      right  : 0.6592\n",
      "      down   : 0.6600\n",
      "      left   : 0.6664\n",
      "    MAE per class:\n",
      "      squares: 0.3848\n",
      "      circles: 0.3723\n",
      "      up     : 0.5237\n",
      "      right  : 0.3649\n",
      "      down   : 0.3618\n",
      "      left   : 0.3629\n",
      "    RMSE overall: 0.7221\n",
      "    MAE overall: 0.3951\n",
      "\n",
      "  Losses:\n",
      "    cls=1.5017, cnt=1.2213, total=2.7230\n",
      "\n",
      "No improvement (val loss 2.7230); patience 2/10\n",
      "Train Epoch: 19 [0/8100] Loss=2.0331\n",
      "Train Epoch: 19 [1280/8100] Loss=2.0592\n",
      "Train Epoch: 19 [0/8100] Loss=2.0331\n",
      "Train Epoch: 19 [1280/8100] Loss=2.0592\n",
      "Train Epoch: 19 [2560/8100] Loss=1.9542\n",
      "Train Epoch: 19 [2560/8100] Loss=1.9542\n",
      "Train Epoch: 19 [3840/8100] Loss=2.0414\n",
      "Train Epoch: 19 [5120/8100] Loss=2.0394\n",
      "Train Epoch: 19 [3840/8100] Loss=2.0414\n",
      "Train Epoch: 19 [5120/8100] Loss=2.0394\n",
      "Train Epoch: 19 [6400/8100] Loss=1.8889\n",
      "Train Epoch: 19 [6400/8100] Loss=1.8889\n",
      "Train Epoch: 19 [7680/8100] Loss=1.6664\n",
      "Train Epoch: 19 [7680/8100] Loss=1.6664\n",
      "\n",
      "Test set (epoch 19):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 46.22%\n",
      "    Macro F1-score: 0.3043\n",
      "    Per-pair accuracy (unordered pair): 93.33%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5758\n",
      "      circles: 0.5459\n",
      "      up     : 0.6902\n",
      "      right  : 0.6370\n",
      "      down   : 0.6912\n",
      "      left   : 0.6419\n",
      "    MAE per class:\n",
      "      squares: 0.3219\n",
      "      circles: 0.3225\n",
      "      up     : 0.3576\n",
      "      right  : 0.3271\n",
      "      down   : 0.3819\n",
      "      left   : 0.3543\n",
      "    RMSE overall: 0.6327\n",
      "    MAE overall: 0.3442\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3773, cnt=0.9808, total=2.3581\n",
      "\n",
      "Improved val loss to 2.3581 at epoch 19\n",
      "\n",
      "Test set (epoch 19):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 46.22%\n",
      "    Macro F1-score: 0.3043\n",
      "    Per-pair accuracy (unordered pair): 93.33%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5758\n",
      "      circles: 0.5459\n",
      "      up     : 0.6902\n",
      "      right  : 0.6370\n",
      "      down   : 0.6912\n",
      "      left   : 0.6419\n",
      "    MAE per class:\n",
      "      squares: 0.3219\n",
      "      circles: 0.3225\n",
      "      up     : 0.3576\n",
      "      right  : 0.3271\n",
      "      down   : 0.3819\n",
      "      left   : 0.3543\n",
      "    RMSE overall: 0.6327\n",
      "    MAE overall: 0.3442\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3773, cnt=0.9808, total=2.3581\n",
      "\n",
      "Improved val loss to 2.3581 at epoch 19\n",
      "Train Epoch: 20 [0/8100] Loss=2.0382\n",
      "Train Epoch: 20 [1280/8100] Loss=1.8643\n",
      "Train Epoch: 20 [0/8100] Loss=2.0382\n",
      "Train Epoch: 20 [1280/8100] Loss=1.8643\n",
      "Train Epoch: 20 [2560/8100] Loss=2.0177\n",
      "Train Epoch: 20 [2560/8100] Loss=2.0177\n",
      "Train Epoch: 20 [3840/8100] Loss=2.0087\n",
      "Train Epoch: 20 [5120/8100] Loss=2.1373\n",
      "Train Epoch: 20 [3840/8100] Loss=2.0087\n",
      "Train Epoch: 20 [5120/8100] Loss=2.1373\n",
      "Train Epoch: 20 [6400/8100] Loss=2.1065\n",
      "Train Epoch: 20 [6400/8100] Loss=2.1065\n",
      "Train Epoch: 20 [7680/8100] Loss=1.8741\n",
      "Train Epoch: 20 [7680/8100] Loss=1.8741\n",
      "\n",
      "Test set (epoch 20):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 41.67%\n",
      "    Macro F1-score: 0.2848\n",
      "    Per-pair accuracy (unordered pair): 92.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6208\n",
      "      circles: 0.6143\n",
      "      up     : 0.7919\n",
      "      right  : 0.6108\n",
      "      down   : 0.6885\n",
      "      left   : 0.6187\n",
      "    MAE per class:\n",
      "      squares: 0.3670\n",
      "      circles: 0.3302\n",
      "      up     : 0.4111\n",
      "      right  : 0.3510\n",
      "      down   : 0.3737\n",
      "      left   : 0.3628\n",
      "    RMSE overall: 0.6608\n",
      "    MAE overall: 0.3660\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4053, cnt=1.0712, total=2.4765\n",
      "\n",
      "No improvement (val loss 2.4765); patience 1/10\n",
      "\n",
      "Test set (epoch 20):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 41.67%\n",
      "    Macro F1-score: 0.2848\n",
      "    Per-pair accuracy (unordered pair): 92.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6208\n",
      "      circles: 0.6143\n",
      "      up     : 0.7919\n",
      "      right  : 0.6108\n",
      "      down   : 0.6885\n",
      "      left   : 0.6187\n",
      "    MAE per class:\n",
      "      squares: 0.3670\n",
      "      circles: 0.3302\n",
      "      up     : 0.4111\n",
      "      right  : 0.3510\n",
      "      down   : 0.3737\n",
      "      left   : 0.3628\n",
      "    RMSE overall: 0.6608\n",
      "    MAE overall: 0.3660\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4053, cnt=1.0712, total=2.4765\n",
      "\n",
      "No improvement (val loss 2.4765); patience 1/10\n",
      "Train Epoch: 21 [0/8100] Loss=1.9598\n",
      "Train Epoch: 21 [1280/8100] Loss=1.8781\n",
      "Train Epoch: 21 [0/8100] Loss=1.9598\n",
      "Train Epoch: 21 [1280/8100] Loss=1.8781\n",
      "Train Epoch: 21 [2560/8100] Loss=1.8717\n",
      "Train Epoch: 21 [2560/8100] Loss=1.8717\n",
      "Train Epoch: 21 [3840/8100] Loss=1.9068\n",
      "Train Epoch: 21 [5120/8100] Loss=1.9009\n",
      "Train Epoch: 21 [3840/8100] Loss=1.9068\n",
      "Train Epoch: 21 [5120/8100] Loss=1.9009\n",
      "Train Epoch: 21 [6400/8100] Loss=1.8105\n",
      "Train Epoch: 21 [6400/8100] Loss=1.8105\n",
      "Train Epoch: 21 [7680/8100] Loss=1.8580\n",
      "Train Epoch: 21 [7680/8100] Loss=1.8580\n",
      "\n",
      "Test set (epoch 21):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 47.33%\n",
      "    Macro F1-score: 0.3334\n",
      "    Per-pair accuracy (unordered pair): 93.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5699\n",
      "      circles: 0.5545\n",
      "      up     : 0.7973\n",
      "      right  : 0.6093\n",
      "      down   : 0.6961\n",
      "      left   : 0.6113\n",
      "    MAE per class:\n",
      "      squares: 0.3234\n",
      "      circles: 0.3475\n",
      "      up     : 0.4221\n",
      "      right  : 0.3204\n",
      "      down   : 0.3923\n",
      "      left   : 0.3344\n",
      "    RMSE overall: 0.6452\n",
      "    MAE overall: 0.3567\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3453, cnt=1.0199, total=2.3653\n",
      "\n",
      "No improvement (val loss 2.3653); patience 2/10\n",
      "\n",
      "Test set (epoch 21):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 47.33%\n",
      "    Macro F1-score: 0.3334\n",
      "    Per-pair accuracy (unordered pair): 93.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5699\n",
      "      circles: 0.5545\n",
      "      up     : 0.7973\n",
      "      right  : 0.6093\n",
      "      down   : 0.6961\n",
      "      left   : 0.6113\n",
      "    MAE per class:\n",
      "      squares: 0.3234\n",
      "      circles: 0.3475\n",
      "      up     : 0.4221\n",
      "      right  : 0.3204\n",
      "      down   : 0.3923\n",
      "      left   : 0.3344\n",
      "    RMSE overall: 0.6452\n",
      "    MAE overall: 0.3567\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3453, cnt=1.0199, total=2.3653\n",
      "\n",
      "No improvement (val loss 2.3653); patience 2/10\n",
      "Train Epoch: 22 [0/8100] Loss=1.7442\n",
      "Train Epoch: 22 [1280/8100] Loss=1.9023\n",
      "Train Epoch: 22 [0/8100] Loss=1.7442\n",
      "Train Epoch: 22 [1280/8100] Loss=1.9023\n",
      "Train Epoch: 22 [2560/8100] Loss=1.9675\n",
      "Train Epoch: 22 [2560/8100] Loss=1.9675\n",
      "Train Epoch: 22 [3840/8100] Loss=1.8355\n",
      "Train Epoch: 22 [5120/8100] Loss=1.9595\n",
      "Train Epoch: 22 [3840/8100] Loss=1.8355\n",
      "Train Epoch: 22 [5120/8100] Loss=1.9595\n",
      "Train Epoch: 22 [6400/8100] Loss=1.9225\n",
      "Train Epoch: 22 [6400/8100] Loss=1.9225\n",
      "Train Epoch: 22 [7680/8100] Loss=1.8118\n",
      "Train Epoch: 22 [7680/8100] Loss=1.8118\n",
      "\n",
      "Test set (epoch 22):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 46.11%\n",
      "    Macro F1-score: 0.3184\n",
      "    Per-pair accuracy (unordered pair): 92.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5904\n",
      "      circles: 0.5538\n",
      "      up     : 0.5793\n",
      "      right  : 0.7453\n",
      "      down   : 0.6963\n",
      "      left   : 0.6179\n",
      "    MAE per class:\n",
      "      squares: 0.3468\n",
      "      circles: 0.3340\n",
      "      up     : 0.3075\n",
      "      right  : 0.3845\n",
      "      down   : 0.3896\n",
      "      left   : 0.3184\n",
      "    RMSE overall: 0.6342\n",
      "    MAE overall: 0.3468\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3337, cnt=0.9986, total=2.3324\n",
      "\n",
      "Improved val loss to 2.3324 at epoch 22\n",
      "\n",
      "Test set (epoch 22):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 46.11%\n",
      "    Macro F1-score: 0.3184\n",
      "    Per-pair accuracy (unordered pair): 92.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5904\n",
      "      circles: 0.5538\n",
      "      up     : 0.5793\n",
      "      right  : 0.7453\n",
      "      down   : 0.6963\n",
      "      left   : 0.6179\n",
      "    MAE per class:\n",
      "      squares: 0.3468\n",
      "      circles: 0.3340\n",
      "      up     : 0.3075\n",
      "      right  : 0.3845\n",
      "      down   : 0.3896\n",
      "      left   : 0.3184\n",
      "    RMSE overall: 0.6342\n",
      "    MAE overall: 0.3468\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3337, cnt=0.9986, total=2.3324\n",
      "\n",
      "Improved val loss to 2.3324 at epoch 22\n",
      "Train Epoch: 23 [0/8100] Loss=1.9121\n",
      "Train Epoch: 23 [1280/8100] Loss=1.7465\n",
      "Train Epoch: 23 [0/8100] Loss=1.9121\n",
      "Train Epoch: 23 [1280/8100] Loss=1.7465\n",
      "Train Epoch: 23 [2560/8100] Loss=1.9865\n",
      "Train Epoch: 23 [2560/8100] Loss=1.9865\n",
      "Train Epoch: 23 [3840/8100] Loss=1.8829\n",
      "Train Epoch: 23 [5120/8100] Loss=2.0302\n",
      "Train Epoch: 23 [3840/8100] Loss=1.8829\n",
      "Train Epoch: 23 [5120/8100] Loss=2.0302\n",
      "Train Epoch: 23 [6400/8100] Loss=1.9494\n",
      "Train Epoch: 23 [6400/8100] Loss=1.9494\n",
      "Train Epoch: 23 [7680/8100] Loss=1.7615\n",
      "Train Epoch: 23 [7680/8100] Loss=1.7615\n",
      "\n",
      "Test set (epoch 23):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 43.00%\n",
      "    Macro F1-score: 0.3018\n",
      "    Per-pair accuracy (unordered pair): 92.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5872\n",
      "      circles: 0.5602\n",
      "      up     : 0.8161\n",
      "      right  : 0.6769\n",
      "      down   : 0.7396\n",
      "      left   : 0.5741\n",
      "    MAE per class:\n",
      "      squares: 0.3420\n",
      "      circles: 0.3295\n",
      "      up     : 0.4438\n",
      "      right  : 0.4077\n",
      "      down   : 0.3809\n",
      "      left   : 0.3034\n",
      "    RMSE overall: 0.6658\n",
      "    MAE overall: 0.3679\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4130, cnt=1.0926, total=2.5056\n",
      "\n",
      "No improvement (val loss 2.5056); patience 1/10\n",
      "\n",
      "Test set (epoch 23):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 43.00%\n",
      "    Macro F1-score: 0.3018\n",
      "    Per-pair accuracy (unordered pair): 92.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5872\n",
      "      circles: 0.5602\n",
      "      up     : 0.8161\n",
      "      right  : 0.6769\n",
      "      down   : 0.7396\n",
      "      left   : 0.5741\n",
      "    MAE per class:\n",
      "      squares: 0.3420\n",
      "      circles: 0.3295\n",
      "      up     : 0.4438\n",
      "      right  : 0.4077\n",
      "      down   : 0.3809\n",
      "      left   : 0.3034\n",
      "    RMSE overall: 0.6658\n",
      "    MAE overall: 0.3679\n",
      "\n",
      "  Losses:\n",
      "    cls=1.4130, cnt=1.0926, total=2.5056\n",
      "\n",
      "No improvement (val loss 2.5056); patience 1/10\n",
      "Train Epoch: 24 [0/8100] Loss=1.8518\n",
      "Train Epoch: 24 [1280/8100] Loss=1.7761\n",
      "Train Epoch: 24 [0/8100] Loss=1.8518\n",
      "Train Epoch: 24 [1280/8100] Loss=1.7761\n",
      "Train Epoch: 24 [2560/8100] Loss=1.8420\n",
      "Train Epoch: 24 [2560/8100] Loss=1.8420\n",
      "Train Epoch: 24 [3840/8100] Loss=1.6693\n",
      "Train Epoch: 24 [5120/8100] Loss=2.0338\n",
      "Train Epoch: 24 [3840/8100] Loss=1.6693\n",
      "Train Epoch: 24 [5120/8100] Loss=2.0338\n",
      "Train Epoch: 24 [6400/8100] Loss=1.8558\n",
      "Train Epoch: 24 [6400/8100] Loss=1.8558\n",
      "Train Epoch: 24 [7680/8100] Loss=1.9579\n",
      "Train Epoch: 24 [7680/8100] Loss=1.9579\n",
      "\n",
      "Test set (epoch 24):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.44%\n",
      "    Macro F1-score: 0.3428\n",
      "    Per-pair accuracy (unordered pair): 94.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5789\n",
      "      circles: 0.5481\n",
      "      up     : 0.6668\n",
      "      right  : 0.6230\n",
      "      down   : 0.6916\n",
      "      left   : 0.5911\n",
      "    MAE per class:\n",
      "      squares: 0.3286\n",
      "      circles: 0.3007\n",
      "      up     : 0.3549\n",
      "      right  : 0.3305\n",
      "      down   : 0.3721\n",
      "      left   : 0.3274\n",
      "    RMSE overall: 0.6186\n",
      "    MAE overall: 0.3357\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2985, cnt=0.9508, total=2.2493\n",
      "\n",
      "Improved val loss to 2.2493 at epoch 24\n",
      "\n",
      "Test set (epoch 24):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.44%\n",
      "    Macro F1-score: 0.3428\n",
      "    Per-pair accuracy (unordered pair): 94.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5789\n",
      "      circles: 0.5481\n",
      "      up     : 0.6668\n",
      "      right  : 0.6230\n",
      "      down   : 0.6916\n",
      "      left   : 0.5911\n",
      "    MAE per class:\n",
      "      squares: 0.3286\n",
      "      circles: 0.3007\n",
      "      up     : 0.3549\n",
      "      right  : 0.3305\n",
      "      down   : 0.3721\n",
      "      left   : 0.3274\n",
      "    RMSE overall: 0.6186\n",
      "    MAE overall: 0.3357\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2985, cnt=0.9508, total=2.2493\n",
      "\n",
      "Improved val loss to 2.2493 at epoch 24\n",
      "Train Epoch: 25 [0/8100] Loss=1.6788\n",
      "Train Epoch: 25 [1280/8100] Loss=1.8555\n",
      "Train Epoch: 25 [0/8100] Loss=1.6788\n",
      "Train Epoch: 25 [1280/8100] Loss=1.8555\n",
      "Train Epoch: 25 [2560/8100] Loss=1.7703\n",
      "Train Epoch: 25 [2560/8100] Loss=1.7703\n",
      "Train Epoch: 25 [3840/8100] Loss=1.8201\n",
      "Train Epoch: 25 [5120/8100] Loss=1.6750\n",
      "Train Epoch: 25 [3840/8100] Loss=1.8201\n",
      "Train Epoch: 25 [5120/8100] Loss=1.6750\n",
      "Train Epoch: 25 [6400/8100] Loss=1.9610\n",
      "Train Epoch: 25 [6400/8100] Loss=1.9610\n",
      "Train Epoch: 25 [7680/8100] Loss=1.6166\n",
      "Train Epoch: 25 [7680/8100] Loss=1.6166\n",
      "\n",
      "Test set (epoch 25):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.33%\n",
      "    Macro F1-score: 0.3584\n",
      "    Per-pair accuracy (unordered pair): 94.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.7424\n",
      "      circles: 0.5859\n",
      "      up     : 0.6123\n",
      "      right  : 0.6301\n",
      "      down   : 0.6194\n",
      "      left   : 0.6798\n",
      "    MAE per class:\n",
      "      squares: 0.4156\n",
      "      circles: 0.3127\n",
      "      up     : 0.3471\n",
      "      right  : 0.3253\n",
      "      down   : 0.3353\n",
      "      left   : 0.4114\n",
      "    RMSE overall: 0.6471\n",
      "    MAE overall: 0.3579\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2935, cnt=1.0292, total=2.3227\n",
      "\n",
      "No improvement (val loss 2.3227); patience 1/10\n",
      "\n",
      "Test set (epoch 25):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.33%\n",
      "    Macro F1-score: 0.3584\n",
      "    Per-pair accuracy (unordered pair): 94.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.7424\n",
      "      circles: 0.5859\n",
      "      up     : 0.6123\n",
      "      right  : 0.6301\n",
      "      down   : 0.6194\n",
      "      left   : 0.6798\n",
      "    MAE per class:\n",
      "      squares: 0.4156\n",
      "      circles: 0.3127\n",
      "      up     : 0.3471\n",
      "      right  : 0.3253\n",
      "      down   : 0.3353\n",
      "      left   : 0.4114\n",
      "    RMSE overall: 0.6471\n",
      "    MAE overall: 0.3579\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2935, cnt=1.0292, total=2.3227\n",
      "\n",
      "No improvement (val loss 2.3227); patience 1/10\n",
      "Train Epoch: 26 [0/8100] Loss=1.7966\n",
      "Train Epoch: 26 [1280/8100] Loss=1.8515\n",
      "Train Epoch: 26 [0/8100] Loss=1.7966\n",
      "Train Epoch: 26 [1280/8100] Loss=1.8515\n",
      "Train Epoch: 26 [2560/8100] Loss=1.8555\n",
      "Train Epoch: 26 [2560/8100] Loss=1.8555\n",
      "Train Epoch: 26 [3840/8100] Loss=1.7859\n",
      "Train Epoch: 26 [5120/8100] Loss=1.7343\n",
      "Train Epoch: 26 [3840/8100] Loss=1.7859\n",
      "Train Epoch: 26 [5120/8100] Loss=1.7343\n",
      "Train Epoch: 26 [6400/8100] Loss=1.8056\n",
      "Train Epoch: 26 [6400/8100] Loss=1.8056\n",
      "Train Epoch: 26 [7680/8100] Loss=1.7483\n",
      "Train Epoch: 26 [7680/8100] Loss=1.7483\n",
      "\n",
      "Test set (epoch 26):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 45.44%\n",
      "    Macro F1-score: 0.3170\n",
      "    Per-pair accuracy (unordered pair): 94.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5730\n",
      "      circles: 0.6273\n",
      "      up     : 0.6184\n",
      "      right  : 0.6255\n",
      "      down   : 0.6539\n",
      "      left   : 0.6883\n",
      "    MAE per class:\n",
      "      squares: 0.3514\n",
      "      circles: 0.3262\n",
      "      up     : 0.3497\n",
      "      right  : 0.3539\n",
      "      down   : 0.3496\n",
      "      left   : 0.3853\n",
      "    RMSE overall: 0.6320\n",
      "    MAE overall: 0.3527\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3353, cnt=0.9897, total=2.3249\n",
      "\n",
      "No improvement (val loss 2.3249); patience 2/10\n",
      "\n",
      "Test set (epoch 26):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 45.44%\n",
      "    Macro F1-score: 0.3170\n",
      "    Per-pair accuracy (unordered pair): 94.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5730\n",
      "      circles: 0.6273\n",
      "      up     : 0.6184\n",
      "      right  : 0.6255\n",
      "      down   : 0.6539\n",
      "      left   : 0.6883\n",
      "    MAE per class:\n",
      "      squares: 0.3514\n",
      "      circles: 0.3262\n",
      "      up     : 0.3497\n",
      "      right  : 0.3539\n",
      "      down   : 0.3496\n",
      "      left   : 0.3853\n",
      "    RMSE overall: 0.6320\n",
      "    MAE overall: 0.3527\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3353, cnt=0.9897, total=2.3249\n",
      "\n",
      "No improvement (val loss 2.3249); patience 2/10\n",
      "Train Epoch: 27 [0/8100] Loss=1.8762\n",
      "Train Epoch: 27 [1280/8100] Loss=1.7204\n",
      "Train Epoch: 27 [0/8100] Loss=1.8762\n",
      "Train Epoch: 27 [1280/8100] Loss=1.7204\n",
      "Train Epoch: 27 [2560/8100] Loss=1.7900\n",
      "Train Epoch: 27 [2560/8100] Loss=1.7900\n",
      "Train Epoch: 27 [3840/8100] Loss=1.7111\n",
      "Train Epoch: 27 [5120/8100] Loss=1.7680\n",
      "Train Epoch: 27 [3840/8100] Loss=1.7111\n",
      "Train Epoch: 27 [5120/8100] Loss=1.7680\n",
      "Train Epoch: 27 [6400/8100] Loss=1.7073\n",
      "Train Epoch: 27 [6400/8100] Loss=1.7073\n",
      "Train Epoch: 27 [7680/8100] Loss=1.8168\n",
      "Train Epoch: 27 [7680/8100] Loss=1.8168\n",
      "\n",
      "Test set (epoch 27):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 45.56%\n",
      "    Macro F1-score: 0.3347\n",
      "    Per-pair accuracy (unordered pair): 93.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5942\n",
      "      circles: 0.5251\n",
      "      up     : 0.6683\n",
      "      right  : 0.6881\n",
      "      down   : 0.6301\n",
      "      left   : 0.6942\n",
      "    MAE per class:\n",
      "      squares: 0.3367\n",
      "      circles: 0.3192\n",
      "      up     : 0.3818\n",
      "      right  : 0.3653\n",
      "      down   : 0.3324\n",
      "      left   : 0.3753\n",
      "    RMSE overall: 0.6361\n",
      "    MAE overall: 0.3518\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3247, cnt=1.0073, total=2.3320\n",
      "\n",
      "No improvement (val loss 2.3320); patience 3/10\n",
      "\n",
      "Test set (epoch 27):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 45.56%\n",
      "    Macro F1-score: 0.3347\n",
      "    Per-pair accuracy (unordered pair): 93.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5942\n",
      "      circles: 0.5251\n",
      "      up     : 0.6683\n",
      "      right  : 0.6881\n",
      "      down   : 0.6301\n",
      "      left   : 0.6942\n",
      "    MAE per class:\n",
      "      squares: 0.3367\n",
      "      circles: 0.3192\n",
      "      up     : 0.3818\n",
      "      right  : 0.3653\n",
      "      down   : 0.3324\n",
      "      left   : 0.3753\n",
      "    RMSE overall: 0.6361\n",
      "    MAE overall: 0.3518\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3247, cnt=1.0073, total=2.3320\n",
      "\n",
      "No improvement (val loss 2.3320); patience 3/10\n",
      "Train Epoch: 28 [0/8100] Loss=1.8401\n",
      "Train Epoch: 28 [1280/8100] Loss=1.7836\n",
      "Train Epoch: 28 [0/8100] Loss=1.8401\n",
      "Train Epoch: 28 [1280/8100] Loss=1.7836\n",
      "Train Epoch: 28 [2560/8100] Loss=1.7013\n",
      "Train Epoch: 28 [2560/8100] Loss=1.7013\n",
      "Train Epoch: 28 [3840/8100] Loss=1.7955\n",
      "Train Epoch: 28 [5120/8100] Loss=1.9283\n",
      "Train Epoch: 28 [3840/8100] Loss=1.7955\n",
      "Train Epoch: 28 [5120/8100] Loss=1.9283\n",
      "Train Epoch: 28 [6400/8100] Loss=1.9269\n",
      "Train Epoch: 28 [6400/8100] Loss=1.9269\n",
      "Train Epoch: 28 [7680/8100] Loss=1.9681\n",
      "Train Epoch: 28 [7680/8100] Loss=1.9681\n",
      "\n",
      "Test set (epoch 28):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 44.33%\n",
      "    Macro F1-score: 0.3180\n",
      "    Per-pair accuracy (unordered pair): 93.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5949\n",
      "      circles: 0.5484\n",
      "      up     : 0.6338\n",
      "      right  : 0.7433\n",
      "      down   : 0.6386\n",
      "      left   : 0.6490\n",
      "    MAE per class:\n",
      "      squares: 0.3327\n",
      "      circles: 0.3386\n",
      "      up     : 0.3325\n",
      "      right  : 0.3888\n",
      "      down   : 0.3760\n",
      "      left   : 0.3436\n",
      "    RMSE overall: 0.6374\n",
      "    MAE overall: 0.3520\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3414, cnt=1.0028, total=2.3442\n",
      "\n",
      "No improvement (val loss 2.3442); patience 4/10\n",
      "\n",
      "Test set (epoch 28):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 44.33%\n",
      "    Macro F1-score: 0.3180\n",
      "    Per-pair accuracy (unordered pair): 93.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5949\n",
      "      circles: 0.5484\n",
      "      up     : 0.6338\n",
      "      right  : 0.7433\n",
      "      down   : 0.6386\n",
      "      left   : 0.6490\n",
      "    MAE per class:\n",
      "      squares: 0.3327\n",
      "      circles: 0.3386\n",
      "      up     : 0.3325\n",
      "      right  : 0.3888\n",
      "      down   : 0.3760\n",
      "      left   : 0.3436\n",
      "    RMSE overall: 0.6374\n",
      "    MAE overall: 0.3520\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3414, cnt=1.0028, total=2.3442\n",
      "\n",
      "No improvement (val loss 2.3442); patience 4/10\n",
      "Train Epoch: 29 [0/8100] Loss=1.6536\n",
      "Train Epoch: 29 [1280/8100] Loss=2.0066\n",
      "Train Epoch: 29 [0/8100] Loss=1.6536\n",
      "Train Epoch: 29 [1280/8100] Loss=2.0066\n",
      "Train Epoch: 29 [2560/8100] Loss=1.6930\n",
      "Train Epoch: 29 [2560/8100] Loss=1.6930\n",
      "Train Epoch: 29 [3840/8100] Loss=1.7263\n",
      "Train Epoch: 29 [5120/8100] Loss=1.8608\n",
      "Train Epoch: 29 [3840/8100] Loss=1.7263\n",
      "Train Epoch: 29 [5120/8100] Loss=1.8608\n",
      "Train Epoch: 29 [6400/8100] Loss=1.6720\n",
      "Train Epoch: 29 [6400/8100] Loss=1.6720\n",
      "Train Epoch: 29 [7680/8100] Loss=1.6655\n",
      "Train Epoch: 29 [7680/8100] Loss=1.6655\n",
      "\n",
      "Test set (epoch 29):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.67%\n",
      "    Macro F1-score: 0.3610\n",
      "    Per-pair accuracy (unordered pair): 93.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5607\n",
      "      circles: 0.4950\n",
      "      up     : 0.6919\n",
      "      right  : 0.6073\n",
      "      down   : 0.6544\n",
      "      left   : 0.6633\n",
      "    MAE per class:\n",
      "      squares: 0.3284\n",
      "      circles: 0.2709\n",
      "      up     : 0.3810\n",
      "      right  : 0.3323\n",
      "      down   : 0.3659\n",
      "      left   : 0.3528\n",
      "    RMSE overall: 0.6158\n",
      "    MAE overall: 0.3385\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2720, cnt=0.9480, total=2.2199\n",
      "\n",
      "Improved val loss to 2.2199 at epoch 29\n",
      "\n",
      "Test set (epoch 29):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.67%\n",
      "    Macro F1-score: 0.3610\n",
      "    Per-pair accuracy (unordered pair): 93.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5607\n",
      "      circles: 0.4950\n",
      "      up     : 0.6919\n",
      "      right  : 0.6073\n",
      "      down   : 0.6544\n",
      "      left   : 0.6633\n",
      "    MAE per class:\n",
      "      squares: 0.3284\n",
      "      circles: 0.2709\n",
      "      up     : 0.3810\n",
      "      right  : 0.3323\n",
      "      down   : 0.3659\n",
      "      left   : 0.3528\n",
      "    RMSE overall: 0.6158\n",
      "    MAE overall: 0.3385\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2720, cnt=0.9480, total=2.2199\n",
      "\n",
      "Improved val loss to 2.2199 at epoch 29\n",
      "Train Epoch: 30 [0/8100] Loss=1.5701\n",
      "Train Epoch: 30 [1280/8100] Loss=1.6028\n",
      "Train Epoch: 30 [0/8100] Loss=1.5701\n",
      "Train Epoch: 30 [1280/8100] Loss=1.6028\n",
      "Train Epoch: 30 [2560/8100] Loss=1.6277\n",
      "Train Epoch: 30 [2560/8100] Loss=1.6277\n",
      "Train Epoch: 30 [3840/8100] Loss=1.7137\n",
      "Train Epoch: 30 [5120/8100] Loss=1.9458\n",
      "Train Epoch: 30 [3840/8100] Loss=1.7137\n",
      "Train Epoch: 30 [5120/8100] Loss=1.9458\n",
      "Train Epoch: 30 [6400/8100] Loss=1.8496\n",
      "Train Epoch: 30 [6400/8100] Loss=1.8496\n",
      "Train Epoch: 30 [7680/8100] Loss=1.7603\n",
      "Train Epoch: 30 [7680/8100] Loss=1.7603\n",
      "\n",
      "Test set (epoch 30):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 48.89%\n",
      "    Macro F1-score: 0.3533\n",
      "    Per-pair accuracy (unordered pair): 94.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6103\n",
      "      circles: 0.4860\n",
      "      up     : 0.5971\n",
      "      right  : 0.6282\n",
      "      down   : 0.6855\n",
      "      left   : 0.6380\n",
      "    MAE per class:\n",
      "      squares: 0.3775\n",
      "      circles: 0.2920\n",
      "      up     : 0.3214\n",
      "      right  : 0.3385\n",
      "      down   : 0.3701\n",
      "      left   : 0.3406\n",
      "    RMSE overall: 0.6105\n",
      "    MAE overall: 0.3400\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2682, cnt=0.9371, total=2.2052\n",
      "\n",
      "Improved val loss to 2.2052 at epoch 30\n",
      "\n",
      "Test set (epoch 30):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 48.89%\n",
      "    Macro F1-score: 0.3533\n",
      "    Per-pair accuracy (unordered pair): 94.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6103\n",
      "      circles: 0.4860\n",
      "      up     : 0.5971\n",
      "      right  : 0.6282\n",
      "      down   : 0.6855\n",
      "      left   : 0.6380\n",
      "    MAE per class:\n",
      "      squares: 0.3775\n",
      "      circles: 0.2920\n",
      "      up     : 0.3214\n",
      "      right  : 0.3385\n",
      "      down   : 0.3701\n",
      "      left   : 0.3406\n",
      "    RMSE overall: 0.6105\n",
      "    MAE overall: 0.3400\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2682, cnt=0.9371, total=2.2052\n",
      "\n",
      "Improved val loss to 2.2052 at epoch 30\n",
      "Train Epoch: 31 [0/8100] Loss=1.7524\n",
      "Train Epoch: 31 [1280/8100] Loss=1.7979\n",
      "Train Epoch: 31 [0/8100] Loss=1.7524\n",
      "Train Epoch: 31 [1280/8100] Loss=1.7979\n",
      "Train Epoch: 31 [2560/8100] Loss=1.5210\n",
      "Train Epoch: 31 [2560/8100] Loss=1.5210\n",
      "Train Epoch: 31 [3840/8100] Loss=1.7528\n",
      "Train Epoch: 31 [5120/8100] Loss=1.7900\n",
      "Train Epoch: 31 [3840/8100] Loss=1.7528\n",
      "Train Epoch: 31 [5120/8100] Loss=1.7900\n",
      "Train Epoch: 31 [6400/8100] Loss=1.7583\n",
      "Train Epoch: 31 [6400/8100] Loss=1.7583\n",
      "Train Epoch: 31 [7680/8100] Loss=1.4692\n",
      "Train Epoch: 31 [7680/8100] Loss=1.4692\n",
      "\n",
      "Test set (epoch 31):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.00%\n",
      "    Macro F1-score: 0.3571\n",
      "    Per-pair accuracy (unordered pair): 94.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5525\n",
      "      circles: 0.4989\n",
      "      up     : 0.7188\n",
      "      right  : 0.6519\n",
      "      down   : 0.6488\n",
      "      left   : 0.6168\n",
      "    MAE per class:\n",
      "      squares: 0.3125\n",
      "      circles: 0.3113\n",
      "      up     : 0.3808\n",
      "      right  : 0.3544\n",
      "      down   : 0.3692\n",
      "      left   : 0.3118\n",
      "    RMSE overall: 0.6188\n",
      "    MAE overall: 0.3400\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2721, cnt=0.9502, total=2.2223\n",
      "\n",
      "No improvement (val loss 2.2223); patience 1/10\n",
      "\n",
      "Test set (epoch 31):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.00%\n",
      "    Macro F1-score: 0.3571\n",
      "    Per-pair accuracy (unordered pair): 94.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5525\n",
      "      circles: 0.4989\n",
      "      up     : 0.7188\n",
      "      right  : 0.6519\n",
      "      down   : 0.6488\n",
      "      left   : 0.6168\n",
      "    MAE per class:\n",
      "      squares: 0.3125\n",
      "      circles: 0.3113\n",
      "      up     : 0.3808\n",
      "      right  : 0.3544\n",
      "      down   : 0.3692\n",
      "      left   : 0.3118\n",
      "    RMSE overall: 0.6188\n",
      "    MAE overall: 0.3400\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2721, cnt=0.9502, total=2.2223\n",
      "\n",
      "No improvement (val loss 2.2223); patience 1/10\n",
      "Train Epoch: 32 [0/8100] Loss=1.7365\n",
      "Train Epoch: 32 [1280/8100] Loss=1.7455\n",
      "Train Epoch: 32 [0/8100] Loss=1.7365\n",
      "Train Epoch: 32 [1280/8100] Loss=1.7455\n",
      "Train Epoch: 32 [2560/8100] Loss=1.6270\n",
      "Train Epoch: 32 [2560/8100] Loss=1.6270\n",
      "Train Epoch: 32 [3840/8100] Loss=1.5526\n",
      "Train Epoch: 32 [5120/8100] Loss=1.9620\n",
      "Train Epoch: 32 [3840/8100] Loss=1.5526\n",
      "Train Epoch: 32 [5120/8100] Loss=1.9620\n",
      "Train Epoch: 32 [6400/8100] Loss=1.7334\n",
      "Train Epoch: 32 [6400/8100] Loss=1.7334\n",
      "Train Epoch: 32 [7680/8100] Loss=1.8468\n",
      "Train Epoch: 32 [7680/8100] Loss=1.8468\n",
      "\n",
      "Test set (epoch 32):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.22%\n",
      "    Macro F1-score: 0.3571\n",
      "    Per-pair accuracy (unordered pair): 94.33%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5479\n",
      "      circles: 0.6240\n",
      "      up     : 0.6396\n",
      "      right  : 0.6265\n",
      "      down   : 0.6026\n",
      "      left   : 0.5891\n",
      "    MAE per class:\n",
      "      squares: 0.2841\n",
      "      circles: 0.3207\n",
      "      up     : 0.3456\n",
      "      right  : 0.3865\n",
      "      down   : 0.3237\n",
      "      left   : 0.3399\n",
      "    RMSE overall: 0.6057\n",
      "    MAE overall: 0.3334\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2681, cnt=0.9252, total=2.1932\n",
      "\n",
      "Improved val loss to 2.1932 at epoch 32\n",
      "\n",
      "Test set (epoch 32):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.22%\n",
      "    Macro F1-score: 0.3571\n",
      "    Per-pair accuracy (unordered pair): 94.33%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5479\n",
      "      circles: 0.6240\n",
      "      up     : 0.6396\n",
      "      right  : 0.6265\n",
      "      down   : 0.6026\n",
      "      left   : 0.5891\n",
      "    MAE per class:\n",
      "      squares: 0.2841\n",
      "      circles: 0.3207\n",
      "      up     : 0.3456\n",
      "      right  : 0.3865\n",
      "      down   : 0.3237\n",
      "      left   : 0.3399\n",
      "    RMSE overall: 0.6057\n",
      "    MAE overall: 0.3334\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2681, cnt=0.9252, total=2.1932\n",
      "\n",
      "Improved val loss to 2.1932 at epoch 32\n",
      "Train Epoch: 33 [0/8100] Loss=1.6884\n",
      "Train Epoch: 33 [1280/8100] Loss=1.8523\n",
      "Train Epoch: 33 [0/8100] Loss=1.6884\n",
      "Train Epoch: 33 [1280/8100] Loss=1.8523\n",
      "Train Epoch: 33 [2560/8100] Loss=1.6889\n",
      "Train Epoch: 33 [2560/8100] Loss=1.6889\n",
      "Train Epoch: 33 [3840/8100] Loss=1.6891\n",
      "Train Epoch: 33 [5120/8100] Loss=1.5758\n",
      "Train Epoch: 33 [3840/8100] Loss=1.6891\n",
      "Train Epoch: 33 [5120/8100] Loss=1.5758\n",
      "Train Epoch: 33 [6400/8100] Loss=1.7145\n",
      "Train Epoch: 33 [6400/8100] Loss=1.7145\n",
      "Train Epoch: 33 [7680/8100] Loss=1.7285\n",
      "Train Epoch: 33 [7680/8100] Loss=1.7285\n",
      "\n",
      "Test set (epoch 33):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 47.33%\n",
      "    Macro F1-score: 0.3490\n",
      "    Per-pair accuracy (unordered pair): 93.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5617\n",
      "      circles: 0.5052\n",
      "      up     : 0.7338\n",
      "      right  : 0.5928\n",
      "      down   : 0.5938\n",
      "      left   : 0.6045\n",
      "    MAE per class:\n",
      "      squares: 0.3446\n",
      "      circles: 0.2875\n",
      "      up     : 0.3935\n",
      "      right  : 0.3210\n",
      "      down   : 0.3158\n",
      "      left   : 0.3610\n",
      "    RMSE overall: 0.6026\n",
      "    MAE overall: 0.3372\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2988, cnt=0.9121, total=2.2110\n",
      "\n",
      "No improvement (val loss 2.2110); patience 1/10\n",
      "\n",
      "Test set (epoch 33):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 47.33%\n",
      "    Macro F1-score: 0.3490\n",
      "    Per-pair accuracy (unordered pair): 93.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5617\n",
      "      circles: 0.5052\n",
      "      up     : 0.7338\n",
      "      right  : 0.5928\n",
      "      down   : 0.5938\n",
      "      left   : 0.6045\n",
      "    MAE per class:\n",
      "      squares: 0.3446\n",
      "      circles: 0.2875\n",
      "      up     : 0.3935\n",
      "      right  : 0.3210\n",
      "      down   : 0.3158\n",
      "      left   : 0.3610\n",
      "    RMSE overall: 0.6026\n",
      "    MAE overall: 0.3372\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2988, cnt=0.9121, total=2.2110\n",
      "\n",
      "No improvement (val loss 2.2110); patience 1/10\n",
      "Train Epoch: 34 [0/8100] Loss=1.7644\n",
      "Train Epoch: 34 [1280/8100] Loss=1.5005\n",
      "Train Epoch: 34 [0/8100] Loss=1.7644\n",
      "Train Epoch: 34 [1280/8100] Loss=1.5005\n",
      "Train Epoch: 34 [2560/8100] Loss=1.8153\n",
      "Train Epoch: 34 [2560/8100] Loss=1.8153\n",
      "Train Epoch: 34 [3840/8100] Loss=1.6312\n",
      "Train Epoch: 34 [5120/8100] Loss=1.7266\n",
      "Train Epoch: 34 [3840/8100] Loss=1.6312\n",
      "Train Epoch: 34 [5120/8100] Loss=1.7266\n",
      "Train Epoch: 34 [6400/8100] Loss=1.5846\n",
      "Train Epoch: 34 [6400/8100] Loss=1.5846\n",
      "Train Epoch: 34 [7680/8100] Loss=1.8295\n",
      "Train Epoch: 34 [7680/8100] Loss=1.8295\n",
      "\n",
      "Test set (epoch 34):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 46.44%\n",
      "    Macro F1-score: 0.3296\n",
      "    Per-pair accuracy (unordered pair): 94.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5952\n",
      "      circles: 0.5288\n",
      "      up     : 0.6474\n",
      "      right  : 0.5848\n",
      "      down   : 0.7491\n",
      "      left   : 0.5861\n",
      "    MAE per class:\n",
      "      squares: 0.3320\n",
      "      circles: 0.3314\n",
      "      up     : 0.3356\n",
      "      right  : 0.3267\n",
      "      down   : 0.4037\n",
      "      left   : 0.3549\n",
      "    RMSE overall: 0.6191\n",
      "    MAE overall: 0.3474\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2991, cnt=0.9632, total=2.2623\n",
      "\n",
      "No improvement (val loss 2.2623); patience 2/10\n",
      "\n",
      "Test set (epoch 34):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 46.44%\n",
      "    Macro F1-score: 0.3296\n",
      "    Per-pair accuracy (unordered pair): 94.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5952\n",
      "      circles: 0.5288\n",
      "      up     : 0.6474\n",
      "      right  : 0.5848\n",
      "      down   : 0.7491\n",
      "      left   : 0.5861\n",
      "    MAE per class:\n",
      "      squares: 0.3320\n",
      "      circles: 0.3314\n",
      "      up     : 0.3356\n",
      "      right  : 0.3267\n",
      "      down   : 0.4037\n",
      "      left   : 0.3549\n",
      "    RMSE overall: 0.6191\n",
      "    MAE overall: 0.3474\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2991, cnt=0.9632, total=2.2623\n",
      "\n",
      "No improvement (val loss 2.2623); patience 2/10\n",
      "Train Epoch: 35 [0/8100] Loss=1.6735\n",
      "Train Epoch: 35 [1280/8100] Loss=1.8129\n",
      "Train Epoch: 35 [0/8100] Loss=1.6735\n",
      "Train Epoch: 35 [1280/8100] Loss=1.8129\n",
      "Train Epoch: 35 [2560/8100] Loss=1.5303\n",
      "Train Epoch: 35 [2560/8100] Loss=1.5303\n",
      "Train Epoch: 35 [3840/8100] Loss=1.5200\n",
      "Train Epoch: 35 [5120/8100] Loss=1.7460\n",
      "Train Epoch: 35 [3840/8100] Loss=1.5200\n",
      "Train Epoch: 35 [5120/8100] Loss=1.7460\n",
      "Train Epoch: 35 [6400/8100] Loss=1.6316\n",
      "Train Epoch: 35 [6400/8100] Loss=1.6316\n",
      "Train Epoch: 35 [7680/8100] Loss=1.5871\n",
      "Train Epoch: 35 [7680/8100] Loss=1.5871\n",
      "\n",
      "Test set (epoch 35):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.44%\n",
      "    Macro F1-score: 0.3642\n",
      "    Per-pair accuracy (unordered pair): 95.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5356\n",
      "      circles: 0.6383\n",
      "      up     : 0.6193\n",
      "      right  : 0.6320\n",
      "      down   : 0.5940\n",
      "      left   : 0.6435\n",
      "    MAE per class:\n",
      "      squares: 0.3149\n",
      "      circles: 0.3523\n",
      "      up     : 0.3418\n",
      "      right  : 0.3442\n",
      "      down   : 0.3029\n",
      "      left   : 0.3406\n",
      "    RMSE overall: 0.6116\n",
      "    MAE overall: 0.3328\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2350, cnt=0.9292, total=2.1642\n",
      "\n",
      "Improved val loss to 2.1642 at epoch 35\n",
      "\n",
      "Test set (epoch 35):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.44%\n",
      "    Macro F1-score: 0.3642\n",
      "    Per-pair accuracy (unordered pair): 95.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5356\n",
      "      circles: 0.6383\n",
      "      up     : 0.6193\n",
      "      right  : 0.6320\n",
      "      down   : 0.5940\n",
      "      left   : 0.6435\n",
      "    MAE per class:\n",
      "      squares: 0.3149\n",
      "      circles: 0.3523\n",
      "      up     : 0.3418\n",
      "      right  : 0.3442\n",
      "      down   : 0.3029\n",
      "      left   : 0.3406\n",
      "    RMSE overall: 0.6116\n",
      "    MAE overall: 0.3328\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2350, cnt=0.9292, total=2.1642\n",
      "\n",
      "Improved val loss to 2.1642 at epoch 35\n",
      "Train Epoch: 36 [0/8100] Loss=1.4999\n",
      "Train Epoch: 36 [1280/8100] Loss=1.6521\n",
      "Train Epoch: 36 [0/8100] Loss=1.4999\n",
      "Train Epoch: 36 [1280/8100] Loss=1.6521\n",
      "Train Epoch: 36 [2560/8100] Loss=1.6331\n",
      "Train Epoch: 36 [2560/8100] Loss=1.6331\n",
      "Train Epoch: 36 [3840/8100] Loss=1.6935\n",
      "Train Epoch: 36 [5120/8100] Loss=1.5450\n",
      "Train Epoch: 36 [3840/8100] Loss=1.6935\n",
      "Train Epoch: 36 [5120/8100] Loss=1.5450\n",
      "Train Epoch: 36 [6400/8100] Loss=1.5580\n",
      "Train Epoch: 36 [6400/8100] Loss=1.5580\n",
      "Train Epoch: 36 [7680/8100] Loss=1.7601\n",
      "Train Epoch: 36 [7680/8100] Loss=1.7601\n",
      "\n",
      "Test set (epoch 36):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.78%\n",
      "    Macro F1-score: 0.3780\n",
      "    Per-pair accuracy (unordered pair): 94.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5713\n",
      "      circles: 0.4980\n",
      "      up     : 0.5587\n",
      "      right  : 0.5716\n",
      "      down   : 0.6668\n",
      "      left   : 0.6408\n",
      "    MAE per class:\n",
      "      squares: 0.3057\n",
      "      circles: 0.3026\n",
      "      up     : 0.3021\n",
      "      right  : 0.3069\n",
      "      down   : 0.3663\n",
      "      left   : 0.3516\n",
      "    RMSE overall: 0.5871\n",
      "    MAE overall: 0.3225\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2201, cnt=0.8739, total=2.0940\n",
      "\n",
      "Improved val loss to 2.0940 at epoch 36\n",
      "\n",
      "Test set (epoch 36):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.78%\n",
      "    Macro F1-score: 0.3780\n",
      "    Per-pair accuracy (unordered pair): 94.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5713\n",
      "      circles: 0.4980\n",
      "      up     : 0.5587\n",
      "      right  : 0.5716\n",
      "      down   : 0.6668\n",
      "      left   : 0.6408\n",
      "    MAE per class:\n",
      "      squares: 0.3057\n",
      "      circles: 0.3026\n",
      "      up     : 0.3021\n",
      "      right  : 0.3069\n",
      "      down   : 0.3663\n",
      "      left   : 0.3516\n",
      "    RMSE overall: 0.5871\n",
      "    MAE overall: 0.3225\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2201, cnt=0.8739, total=2.0940\n",
      "\n",
      "Improved val loss to 2.0940 at epoch 36\n",
      "Train Epoch: 37 [0/8100] Loss=1.5717\n",
      "Train Epoch: 37 [1280/8100] Loss=1.7806\n",
      "Train Epoch: 37 [0/8100] Loss=1.5717\n",
      "Train Epoch: 37 [1280/8100] Loss=1.7806\n",
      "Train Epoch: 37 [2560/8100] Loss=1.5145\n",
      "Train Epoch: 37 [2560/8100] Loss=1.5145\n",
      "Train Epoch: 37 [3840/8100] Loss=1.5316\n",
      "Train Epoch: 37 [5120/8100] Loss=1.5156\n",
      "Train Epoch: 37 [3840/8100] Loss=1.5316\n",
      "Train Epoch: 37 [5120/8100] Loss=1.5156\n",
      "Train Epoch: 37 [6400/8100] Loss=1.6856\n",
      "Train Epoch: 37 [6400/8100] Loss=1.6856\n",
      "Train Epoch: 37 [7680/8100] Loss=1.6310\n",
      "Train Epoch: 37 [7680/8100] Loss=1.6310\n",
      "\n",
      "Test set (epoch 37):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 52.22%\n",
      "    Macro F1-score: 0.3794\n",
      "    Per-pair accuracy (unordered pair): 94.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5693\n",
      "      circles: 0.4846\n",
      "      up     : 0.6124\n",
      "      right  : 0.6630\n",
      "      down   : 0.6291\n",
      "      left   : 0.5900\n",
      "    MAE per class:\n",
      "      squares: 0.3181\n",
      "      circles: 0.2829\n",
      "      up     : 0.3437\n",
      "      right  : 0.3432\n",
      "      down   : 0.3636\n",
      "      left   : 0.3358\n",
      "    RMSE overall: 0.5940\n",
      "    MAE overall: 0.3312\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2289, cnt=0.8919, total=2.1208\n",
      "\n",
      "No improvement (val loss 2.1208); patience 1/10\n",
      "\n",
      "Test set (epoch 37):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 52.22%\n",
      "    Macro F1-score: 0.3794\n",
      "    Per-pair accuracy (unordered pair): 94.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5693\n",
      "      circles: 0.4846\n",
      "      up     : 0.6124\n",
      "      right  : 0.6630\n",
      "      down   : 0.6291\n",
      "      left   : 0.5900\n",
      "    MAE per class:\n",
      "      squares: 0.3181\n",
      "      circles: 0.2829\n",
      "      up     : 0.3437\n",
      "      right  : 0.3432\n",
      "      down   : 0.3636\n",
      "      left   : 0.3358\n",
      "    RMSE overall: 0.5940\n",
      "    MAE overall: 0.3312\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2289, cnt=0.8919, total=2.1208\n",
      "\n",
      "No improvement (val loss 2.1208); patience 1/10\n",
      "Train Epoch: 38 [0/8100] Loss=1.5106\n",
      "Train Epoch: 38 [1280/8100] Loss=1.7600\n",
      "Train Epoch: 38 [0/8100] Loss=1.5106\n",
      "Train Epoch: 38 [1280/8100] Loss=1.7600\n",
      "Train Epoch: 38 [2560/8100] Loss=1.6898\n",
      "Train Epoch: 38 [2560/8100] Loss=1.6898\n",
      "Train Epoch: 38 [3840/8100] Loss=1.6176\n",
      "Train Epoch: 38 [5120/8100] Loss=1.5835\n",
      "Train Epoch: 38 [3840/8100] Loss=1.6176\n",
      "Train Epoch: 38 [5120/8100] Loss=1.5835\n",
      "Train Epoch: 38 [6400/8100] Loss=1.4710\n",
      "Train Epoch: 38 [6400/8100] Loss=1.4710\n",
      "Train Epoch: 38 [7680/8100] Loss=1.5464\n",
      "Train Epoch: 38 [7680/8100] Loss=1.5464\n",
      "\n",
      "Test set (epoch 38):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 47.44%\n",
      "    Macro F1-score: 0.3440\n",
      "    Per-pair accuracy (unordered pair): 93.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5490\n",
      "      circles: 0.5881\n",
      "      up     : 0.6828\n",
      "      right  : 0.6712\n",
      "      down   : 0.7679\n",
      "      left   : 0.6298\n",
      "    MAE per class:\n",
      "      squares: 0.3153\n",
      "      circles: 0.3735\n",
      "      up     : 0.3948\n",
      "      right  : 0.3605\n",
      "      down   : 0.4237\n",
      "      left   : 0.3290\n",
      "    RMSE overall: 0.6520\n",
      "    MAE overall: 0.3661\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3006, cnt=1.0630, total=2.3637\n",
      "\n",
      "No improvement (val loss 2.3637); patience 2/10\n",
      "\n",
      "Test set (epoch 38):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 47.44%\n",
      "    Macro F1-score: 0.3440\n",
      "    Per-pair accuracy (unordered pair): 93.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5490\n",
      "      circles: 0.5881\n",
      "      up     : 0.6828\n",
      "      right  : 0.6712\n",
      "      down   : 0.7679\n",
      "      left   : 0.6298\n",
      "    MAE per class:\n",
      "      squares: 0.3153\n",
      "      circles: 0.3735\n",
      "      up     : 0.3948\n",
      "      right  : 0.3605\n",
      "      down   : 0.4237\n",
      "      left   : 0.3290\n",
      "    RMSE overall: 0.6520\n",
      "    MAE overall: 0.3661\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3006, cnt=1.0630, total=2.3637\n",
      "\n",
      "No improvement (val loss 2.3637); patience 2/10\n",
      "Train Epoch: 39 [0/8100] Loss=1.5733\n",
      "Train Epoch: 39 [1280/8100] Loss=1.5266\n",
      "Train Epoch: 39 [0/8100] Loss=1.5733\n",
      "Train Epoch: 39 [1280/8100] Loss=1.5266\n",
      "Train Epoch: 39 [2560/8100] Loss=1.6598\n",
      "Train Epoch: 39 [2560/8100] Loss=1.6598\n",
      "Train Epoch: 39 [3840/8100] Loss=1.6181\n",
      "Train Epoch: 39 [5120/8100] Loss=1.5028\n",
      "Train Epoch: 39 [3840/8100] Loss=1.6181\n",
      "Train Epoch: 39 [5120/8100] Loss=1.5028\n",
      "Train Epoch: 39 [6400/8100] Loss=1.5298\n",
      "Train Epoch: 39 [6400/8100] Loss=1.5298\n",
      "Train Epoch: 39 [7680/8100] Loss=1.5445\n",
      "Train Epoch: 39 [7680/8100] Loss=1.5445\n",
      "\n",
      "Test set (epoch 39):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.44%\n",
      "    Macro F1-score: 0.3792\n",
      "    Per-pair accuracy (unordered pair): 94.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5656\n",
      "      circles: 0.4813\n",
      "      up     : 0.6804\n",
      "      right  : 0.6143\n",
      "      down   : 0.5841\n",
      "      left   : 0.5913\n",
      "    MAE per class:\n",
      "      squares: 0.3264\n",
      "      circles: 0.2752\n",
      "      up     : 0.3760\n",
      "      right  : 0.3241\n",
      "      down   : 0.3062\n",
      "      left   : 0.3252\n",
      "    RMSE overall: 0.5892\n",
      "    MAE overall: 0.3222\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2359, cnt=0.8670, total=2.1029\n",
      "\n",
      "No improvement (val loss 2.1029); patience 3/10\n",
      "\n",
      "Test set (epoch 39):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.44%\n",
      "    Macro F1-score: 0.3792\n",
      "    Per-pair accuracy (unordered pair): 94.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5656\n",
      "      circles: 0.4813\n",
      "      up     : 0.6804\n",
      "      right  : 0.6143\n",
      "      down   : 0.5841\n",
      "      left   : 0.5913\n",
      "    MAE per class:\n",
      "      squares: 0.3264\n",
      "      circles: 0.2752\n",
      "      up     : 0.3760\n",
      "      right  : 0.3241\n",
      "      down   : 0.3062\n",
      "      left   : 0.3252\n",
      "    RMSE overall: 0.5892\n",
      "    MAE overall: 0.3222\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2359, cnt=0.8670, total=2.1029\n",
      "\n",
      "No improvement (val loss 2.1029); patience 3/10\n",
      "Train Epoch: 40 [0/8100] Loss=1.4731\n",
      "Train Epoch: 40 [1280/8100] Loss=1.4924\n",
      "Train Epoch: 40 [0/8100] Loss=1.4731\n",
      "Train Epoch: 40 [1280/8100] Loss=1.4924\n",
      "Train Epoch: 40 [2560/8100] Loss=1.6145\n",
      "Train Epoch: 40 [2560/8100] Loss=1.6145\n",
      "Train Epoch: 40 [3840/8100] Loss=1.5833\n",
      "Train Epoch: 40 [5120/8100] Loss=1.6372\n",
      "Train Epoch: 40 [3840/8100] Loss=1.5833\n",
      "Train Epoch: 40 [5120/8100] Loss=1.6372\n",
      "Train Epoch: 40 [6400/8100] Loss=1.4029\n",
      "Train Epoch: 40 [6400/8100] Loss=1.4029\n",
      "Train Epoch: 40 [7680/8100] Loss=1.4053\n",
      "Train Epoch: 40 [7680/8100] Loss=1.4053\n",
      "\n",
      "Test set (epoch 40):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.89%\n",
      "    Macro F1-score: 0.3711\n",
      "    Per-pair accuracy (unordered pair): 95.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5738\n",
      "      circles: 0.4699\n",
      "      up     : 0.6188\n",
      "      right  : 0.6892\n",
      "      down   : 0.6148\n",
      "      left   : 0.6057\n",
      "    MAE per class:\n",
      "      squares: 0.3088\n",
      "      circles: 0.2662\n",
      "      up     : 0.3597\n",
      "      right  : 0.3718\n",
      "      down   : 0.3424\n",
      "      left   : 0.3387\n",
      "    RMSE overall: 0.5990\n",
      "    MAE overall: 0.3313\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2067, cnt=0.9133, total=2.1199\n",
      "\n",
      "No improvement (val loss 2.1199); patience 4/10\n",
      "\n",
      "Test set (epoch 40):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.89%\n",
      "    Macro F1-score: 0.3711\n",
      "    Per-pair accuracy (unordered pair): 95.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5738\n",
      "      circles: 0.4699\n",
      "      up     : 0.6188\n",
      "      right  : 0.6892\n",
      "      down   : 0.6148\n",
      "      left   : 0.6057\n",
      "    MAE per class:\n",
      "      squares: 0.3088\n",
      "      circles: 0.2662\n",
      "      up     : 0.3597\n",
      "      right  : 0.3718\n",
      "      down   : 0.3424\n",
      "      left   : 0.3387\n",
      "    RMSE overall: 0.5990\n",
      "    MAE overall: 0.3313\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2067, cnt=0.9133, total=2.1199\n",
      "\n",
      "No improvement (val loss 2.1199); patience 4/10\n",
      "Train Epoch: 41 [0/8100] Loss=1.4968\n",
      "Train Epoch: 41 [1280/8100] Loss=1.5747\n",
      "Train Epoch: 41 [0/8100] Loss=1.4968\n",
      "Train Epoch: 41 [1280/8100] Loss=1.5747\n",
      "Train Epoch: 41 [2560/8100] Loss=1.5350\n",
      "Train Epoch: 41 [2560/8100] Loss=1.5350\n",
      "Train Epoch: 41 [3840/8100] Loss=1.4880\n",
      "Train Epoch: 41 [5120/8100] Loss=1.3954\n",
      "Train Epoch: 41 [3840/8100] Loss=1.4880\n",
      "Train Epoch: 41 [5120/8100] Loss=1.3954\n",
      "Train Epoch: 41 [6400/8100] Loss=1.4976\n",
      "Train Epoch: 41 [6400/8100] Loss=1.4976\n",
      "Train Epoch: 41 [7680/8100] Loss=1.4284\n",
      "Train Epoch: 41 [7680/8100] Loss=1.4284\n",
      "\n",
      "Test set (epoch 41):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.56%\n",
      "    Macro F1-score: 0.3701\n",
      "    Per-pair accuracy (unordered pair): 95.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5546\n",
      "      circles: 0.5825\n",
      "      up     : 0.6236\n",
      "      right  : 0.6150\n",
      "      down   : 0.6525\n",
      "      left   : 0.5849\n",
      "    MAE per class:\n",
      "      squares: 0.3093\n",
      "      circles: 0.3127\n",
      "      up     : 0.3585\n",
      "      right  : 0.3294\n",
      "      down   : 0.3661\n",
      "      left   : 0.3343\n",
      "    RMSE overall: 0.6030\n",
      "    MAE overall: 0.3351\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2292, cnt=0.9178, total=2.1470\n",
      "\n",
      "No improvement (val loss 2.1470); patience 5/10\n",
      "\n",
      "Test set (epoch 41):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.56%\n",
      "    Macro F1-score: 0.3701\n",
      "    Per-pair accuracy (unordered pair): 95.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5546\n",
      "      circles: 0.5825\n",
      "      up     : 0.6236\n",
      "      right  : 0.6150\n",
      "      down   : 0.6525\n",
      "      left   : 0.5849\n",
      "    MAE per class:\n",
      "      squares: 0.3093\n",
      "      circles: 0.3127\n",
      "      up     : 0.3585\n",
      "      right  : 0.3294\n",
      "      down   : 0.3661\n",
      "      left   : 0.3343\n",
      "    RMSE overall: 0.6030\n",
      "    MAE overall: 0.3351\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2292, cnt=0.9178, total=2.1470\n",
      "\n",
      "No improvement (val loss 2.1470); patience 5/10\n",
      "Train Epoch: 42 [0/8100] Loss=1.4851\n",
      "Train Epoch: 42 [1280/8100] Loss=1.5716\n",
      "Train Epoch: 42 [0/8100] Loss=1.4851\n",
      "Train Epoch: 42 [1280/8100] Loss=1.5716\n",
      "Train Epoch: 42 [2560/8100] Loss=1.4675\n",
      "Train Epoch: 42 [2560/8100] Loss=1.4675\n",
      "Train Epoch: 42 [3840/8100] Loss=1.4379\n",
      "Train Epoch: 42 [5120/8100] Loss=1.6195\n",
      "Train Epoch: 42 [3840/8100] Loss=1.4379\n",
      "Train Epoch: 42 [5120/8100] Loss=1.6195\n",
      "Train Epoch: 42 [6400/8100] Loss=1.5198\n",
      "Train Epoch: 42 [6400/8100] Loss=1.5198\n",
      "Train Epoch: 42 [7680/8100] Loss=1.4208\n",
      "Train Epoch: 42 [7680/8100] Loss=1.4208\n",
      "\n",
      "Test set (epoch 42):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.56%\n",
      "    Macro F1-score: 0.3610\n",
      "    Per-pair accuracy (unordered pair): 93.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5638\n",
      "      circles: 0.5600\n",
      "      up     : 0.7252\n",
      "      right  : 0.5608\n",
      "      down   : 0.6342\n",
      "      left   : 0.5898\n",
      "    MAE per class:\n",
      "      squares: 0.3072\n",
      "      circles: 0.3015\n",
      "      up     : 0.3748\n",
      "      right  : 0.3152\n",
      "      down   : 0.3884\n",
      "      left   : 0.3435\n",
      "    RMSE overall: 0.6086\n",
      "    MAE overall: 0.3384\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2738, cnt=0.9205, total=2.1942\n",
      "\n",
      "No improvement (val loss 2.1942); patience 6/10\n",
      "\n",
      "Test set (epoch 42):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.56%\n",
      "    Macro F1-score: 0.3610\n",
      "    Per-pair accuracy (unordered pair): 93.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5638\n",
      "      circles: 0.5600\n",
      "      up     : 0.7252\n",
      "      right  : 0.5608\n",
      "      down   : 0.6342\n",
      "      left   : 0.5898\n",
      "    MAE per class:\n",
      "      squares: 0.3072\n",
      "      circles: 0.3015\n",
      "      up     : 0.3748\n",
      "      right  : 0.3152\n",
      "      down   : 0.3884\n",
      "      left   : 0.3435\n",
      "    RMSE overall: 0.6086\n",
      "    MAE overall: 0.3384\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2738, cnt=0.9205, total=2.1942\n",
      "\n",
      "No improvement (val loss 2.1942); patience 6/10\n",
      "Train Epoch: 43 [0/8100] Loss=1.3451\n",
      "Train Epoch: 43 [1280/8100] Loss=1.4485\n",
      "Train Epoch: 43 [0/8100] Loss=1.3451\n",
      "Train Epoch: 43 [1280/8100] Loss=1.4485\n",
      "Train Epoch: 43 [2560/8100] Loss=1.6599\n",
      "Train Epoch: 43 [2560/8100] Loss=1.6599\n",
      "Train Epoch: 43 [3840/8100] Loss=1.4139\n",
      "Train Epoch: 43 [5120/8100] Loss=1.5064\n",
      "Train Epoch: 43 [3840/8100] Loss=1.4139\n",
      "Train Epoch: 43 [5120/8100] Loss=1.5064\n",
      "Train Epoch: 43 [6400/8100] Loss=1.4313\n",
      "Train Epoch: 43 [6400/8100] Loss=1.4313\n",
      "Train Epoch: 43 [7680/8100] Loss=1.5647\n",
      "Train Epoch: 43 [7680/8100] Loss=1.5647\n",
      "\n",
      "Test set (epoch 43):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 48.00%\n",
      "    Macro F1-score: 0.3464\n",
      "    Per-pair accuracy (unordered pair): 94.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5455\n",
      "      circles: 0.4988\n",
      "      up     : 0.5793\n",
      "      right  : 0.6106\n",
      "      down   : 0.5767\n",
      "      left   : 0.7398\n",
      "    MAE per class:\n",
      "      squares: 0.3203\n",
      "      circles: 0.2954\n",
      "      up     : 0.3262\n",
      "      right  : 0.3361\n",
      "      down   : 0.3258\n",
      "      left   : 0.3937\n",
      "    RMSE overall: 0.5965\n",
      "    MAE overall: 0.3329\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2807, cnt=0.8957, total=2.1763\n",
      "\n",
      "No improvement (val loss 2.1763); patience 7/10\n",
      "\n",
      "Test set (epoch 43):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 48.00%\n",
      "    Macro F1-score: 0.3464\n",
      "    Per-pair accuracy (unordered pair): 94.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5455\n",
      "      circles: 0.4988\n",
      "      up     : 0.5793\n",
      "      right  : 0.6106\n",
      "      down   : 0.5767\n",
      "      left   : 0.7398\n",
      "    MAE per class:\n",
      "      squares: 0.3203\n",
      "      circles: 0.2954\n",
      "      up     : 0.3262\n",
      "      right  : 0.3361\n",
      "      down   : 0.3258\n",
      "      left   : 0.3937\n",
      "    RMSE overall: 0.5965\n",
      "    MAE overall: 0.3329\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2807, cnt=0.8957, total=2.1763\n",
      "\n",
      "No improvement (val loss 2.1763); patience 7/10\n",
      "Train Epoch: 44 [0/8100] Loss=1.4260\n",
      "Train Epoch: 44 [1280/8100] Loss=1.4234\n",
      "Train Epoch: 44 [0/8100] Loss=1.4260\n",
      "Train Epoch: 44 [1280/8100] Loss=1.4234\n",
      "Train Epoch: 44 [2560/8100] Loss=1.6055\n",
      "Train Epoch: 44 [2560/8100] Loss=1.6055\n",
      "Train Epoch: 44 [3840/8100] Loss=1.3808\n",
      "Train Epoch: 44 [5120/8100] Loss=1.5205\n",
      "Train Epoch: 44 [3840/8100] Loss=1.3808\n",
      "Train Epoch: 44 [5120/8100] Loss=1.5205\n",
      "Train Epoch: 44 [6400/8100] Loss=1.3838\n",
      "Train Epoch: 44 [6400/8100] Loss=1.3838\n",
      "Train Epoch: 44 [7680/8100] Loss=1.5096\n",
      "Train Epoch: 44 [7680/8100] Loss=1.5096\n",
      "\n",
      "Test set (epoch 44):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 53.44%\n",
      "    Macro F1-score: 0.3938\n",
      "    Per-pair accuracy (unordered pair): 94.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5301\n",
      "      circles: 0.4649\n",
      "      up     : 0.6616\n",
      "      right  : 0.5766\n",
      "      down   : 0.5838\n",
      "      left   : 0.6284\n",
      "    MAE per class:\n",
      "      squares: 0.2986\n",
      "      circles: 0.2643\n",
      "      up     : 0.3510\n",
      "      right  : 0.3200\n",
      "      down   : 0.3251\n",
      "      left   : 0.3654\n",
      "    RMSE overall: 0.5778\n",
      "    MAE overall: 0.3207\n",
      "\n",
      "  Losses:\n",
      "    cls=1.1785, cnt=0.8392, total=2.0177\n",
      "\n",
      "Improved val loss to 2.0177 at epoch 44\n",
      "\n",
      "Test set (epoch 44):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 53.44%\n",
      "    Macro F1-score: 0.3938\n",
      "    Per-pair accuracy (unordered pair): 94.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5301\n",
      "      circles: 0.4649\n",
      "      up     : 0.6616\n",
      "      right  : 0.5766\n",
      "      down   : 0.5838\n",
      "      left   : 0.6284\n",
      "    MAE per class:\n",
      "      squares: 0.2986\n",
      "      circles: 0.2643\n",
      "      up     : 0.3510\n",
      "      right  : 0.3200\n",
      "      down   : 0.3251\n",
      "      left   : 0.3654\n",
      "    RMSE overall: 0.5778\n",
      "    MAE overall: 0.3207\n",
      "\n",
      "  Losses:\n",
      "    cls=1.1785, cnt=0.8392, total=2.0177\n",
      "\n",
      "Improved val loss to 2.0177 at epoch 44\n",
      "Train Epoch: 45 [0/8100] Loss=1.3557\n",
      "Train Epoch: 45 [1280/8100] Loss=1.4208\n",
      "Train Epoch: 45 [0/8100] Loss=1.3557\n",
      "Train Epoch: 45 [1280/8100] Loss=1.4208\n",
      "Train Epoch: 45 [2560/8100] Loss=1.6421\n",
      "Train Epoch: 45 [2560/8100] Loss=1.6421\n",
      "Train Epoch: 45 [3840/8100] Loss=1.5273\n",
      "Train Epoch: 45 [5120/8100] Loss=1.6123\n",
      "Train Epoch: 45 [3840/8100] Loss=1.5273\n",
      "Train Epoch: 45 [5120/8100] Loss=1.6123\n",
      "Train Epoch: 45 [6400/8100] Loss=1.3791\n",
      "Train Epoch: 45 [6400/8100] Loss=1.3791\n",
      "Train Epoch: 45 [7680/8100] Loss=1.5977\n",
      "Train Epoch: 45 [7680/8100] Loss=1.5977\n",
      "\n",
      "Test set (epoch 45):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 54.33%\n",
      "    Macro F1-score: 0.4042\n",
      "    Per-pair accuracy (unordered pair): 95.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5689\n",
      "      circles: 0.4659\n",
      "      up     : 0.5858\n",
      "      right  : 0.5749\n",
      "      down   : 0.6074\n",
      "      left   : 0.5572\n",
      "    MAE per class:\n",
      "      squares: 0.3140\n",
      "      circles: 0.2645\n",
      "      up     : 0.3213\n",
      "      right  : 0.3239\n",
      "      down   : 0.3364\n",
      "      left   : 0.3095\n",
      "    RMSE overall: 0.5618\n",
      "    MAE overall: 0.3116\n",
      "\n",
      "  Losses:\n",
      "    cls=1.1806, cnt=0.8099, total=1.9905\n",
      "\n",
      "Improved val loss to 1.9905 at epoch 45\n",
      "\n",
      "Test set (epoch 45):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 54.33%\n",
      "    Macro F1-score: 0.4042\n",
      "    Per-pair accuracy (unordered pair): 95.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5689\n",
      "      circles: 0.4659\n",
      "      up     : 0.5858\n",
      "      right  : 0.5749\n",
      "      down   : 0.6074\n",
      "      left   : 0.5572\n",
      "    MAE per class:\n",
      "      squares: 0.3140\n",
      "      circles: 0.2645\n",
      "      up     : 0.3213\n",
      "      right  : 0.3239\n",
      "      down   : 0.3364\n",
      "      left   : 0.3095\n",
      "    RMSE overall: 0.5618\n",
      "    MAE overall: 0.3116\n",
      "\n",
      "  Losses:\n",
      "    cls=1.1806, cnt=0.8099, total=1.9905\n",
      "\n",
      "Improved val loss to 1.9905 at epoch 45\n",
      "Train Epoch: 46 [0/8100] Loss=1.3223\n",
      "Train Epoch: 46 [1280/8100] Loss=1.5243\n",
      "Train Epoch: 46 [0/8100] Loss=1.3223\n",
      "Train Epoch: 46 [1280/8100] Loss=1.5243\n",
      "Train Epoch: 46 [2560/8100] Loss=1.4051\n",
      "Train Epoch: 46 [2560/8100] Loss=1.4051\n",
      "Train Epoch: 46 [3840/8100] Loss=1.4719\n",
      "Train Epoch: 46 [5120/8100] Loss=1.5420\n",
      "Train Epoch: 46 [3840/8100] Loss=1.4719\n",
      "Train Epoch: 46 [5120/8100] Loss=1.5420\n",
      "Train Epoch: 46 [6400/8100] Loss=1.3796\n",
      "Train Epoch: 46 [6400/8100] Loss=1.3796\n",
      "Train Epoch: 46 [7680/8100] Loss=1.5416\n",
      "Train Epoch: 46 [7680/8100] Loss=1.5416\n",
      "\n",
      "Test set (epoch 46):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.56%\n",
      "    Macro F1-score: 0.3673\n",
      "    Per-pair accuracy (unordered pair): 94.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6106\n",
      "      circles: 0.4811\n",
      "      up     : 0.6269\n",
      "      right  : 0.5887\n",
      "      down   : 0.5515\n",
      "      left   : 0.5907\n",
      "    MAE per class:\n",
      "      squares: 0.3380\n",
      "      circles: 0.2701\n",
      "      up     : 0.3492\n",
      "      right  : 0.3151\n",
      "      down   : 0.3288\n",
      "      left   : 0.3442\n",
      "    RMSE overall: 0.5769\n",
      "    MAE overall: 0.3242\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2325, cnt=0.8583, total=2.0907\n",
      "\n",
      "No improvement (val loss 2.0907); patience 1/10\n",
      "\n",
      "Test set (epoch 46):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.56%\n",
      "    Macro F1-score: 0.3673\n",
      "    Per-pair accuracy (unordered pair): 94.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6106\n",
      "      circles: 0.4811\n",
      "      up     : 0.6269\n",
      "      right  : 0.5887\n",
      "      down   : 0.5515\n",
      "      left   : 0.5907\n",
      "    MAE per class:\n",
      "      squares: 0.3380\n",
      "      circles: 0.2701\n",
      "      up     : 0.3492\n",
      "      right  : 0.3151\n",
      "      down   : 0.3288\n",
      "      left   : 0.3442\n",
      "    RMSE overall: 0.5769\n",
      "    MAE overall: 0.3242\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2325, cnt=0.8583, total=2.0907\n",
      "\n",
      "No improvement (val loss 2.0907); patience 1/10\n",
      "Train Epoch: 47 [0/8100] Loss=1.4346\n",
      "Train Epoch: 47 [1280/8100] Loss=1.4747\n",
      "Train Epoch: 47 [0/8100] Loss=1.4346\n",
      "Train Epoch: 47 [1280/8100] Loss=1.4747\n",
      "Train Epoch: 47 [2560/8100] Loss=1.5173\n",
      "Train Epoch: 47 [2560/8100] Loss=1.5173\n",
      "Train Epoch: 47 [3840/8100] Loss=1.3745\n",
      "Train Epoch: 47 [5120/8100] Loss=1.3310\n",
      "Train Epoch: 47 [3840/8100] Loss=1.3745\n",
      "Train Epoch: 47 [5120/8100] Loss=1.3310\n",
      "Train Epoch: 47 [6400/8100] Loss=1.5307\n",
      "Train Epoch: 47 [6400/8100] Loss=1.5307\n",
      "Train Epoch: 47 [7680/8100] Loss=1.4187\n",
      "Train Epoch: 47 [7680/8100] Loss=1.4187\n",
      "\n",
      "Test set (epoch 47):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.56%\n",
      "    Macro F1-score: 0.3663\n",
      "    Per-pair accuracy (unordered pair): 94.67%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5371\n",
      "      circles: 0.4867\n",
      "      up     : 0.6344\n",
      "      right  : 0.5952\n",
      "      down   : 0.6425\n",
      "      left   : 0.5760\n",
      "    MAE per class:\n",
      "      squares: 0.2852\n",
      "      circles: 0.2776\n",
      "      up     : 0.3640\n",
      "      right  : 0.2995\n",
      "      down   : 0.3674\n",
      "      left   : 0.3086\n",
      "    RMSE overall: 0.5812\n",
      "    MAE overall: 0.3170\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2564, cnt=0.8469, total=2.1033\n",
      "\n",
      "No improvement (val loss 2.1033); patience 2/10\n",
      "\n",
      "Test set (epoch 47):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.56%\n",
      "    Macro F1-score: 0.3663\n",
      "    Per-pair accuracy (unordered pair): 94.67%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5371\n",
      "      circles: 0.4867\n",
      "      up     : 0.6344\n",
      "      right  : 0.5952\n",
      "      down   : 0.6425\n",
      "      left   : 0.5760\n",
      "    MAE per class:\n",
      "      squares: 0.2852\n",
      "      circles: 0.2776\n",
      "      up     : 0.3640\n",
      "      right  : 0.2995\n",
      "      down   : 0.3674\n",
      "      left   : 0.3086\n",
      "    RMSE overall: 0.5812\n",
      "    MAE overall: 0.3170\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2564, cnt=0.8469, total=2.1033\n",
      "\n",
      "No improvement (val loss 2.1033); patience 2/10\n",
      "Train Epoch: 48 [0/8100] Loss=1.3901\n",
      "Train Epoch: 48 [1280/8100] Loss=1.5562\n",
      "Train Epoch: 48 [0/8100] Loss=1.3901\n",
      "Train Epoch: 48 [1280/8100] Loss=1.5562\n",
      "Train Epoch: 48 [2560/8100] Loss=1.4261\n",
      "Train Epoch: 48 [2560/8100] Loss=1.4261\n",
      "Train Epoch: 48 [3840/8100] Loss=1.7093\n",
      "Train Epoch: 48 [5120/8100] Loss=1.3536\n",
      "Train Epoch: 48 [3840/8100] Loss=1.7093\n",
      "Train Epoch: 48 [5120/8100] Loss=1.3536\n",
      "Train Epoch: 48 [6400/8100] Loss=1.5622\n",
      "Train Epoch: 48 [6400/8100] Loss=1.5622\n",
      "Train Epoch: 48 [7680/8100] Loss=1.4167\n",
      "Train Epoch: 48 [7680/8100] Loss=1.4167\n",
      "\n",
      "Test set (epoch 48):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.33%\n",
      "    Macro F1-score: 0.3600\n",
      "    Per-pair accuracy (unordered pair): 93.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6136\n",
      "      circles: 0.4674\n",
      "      up     : 0.6517\n",
      "      right  : 0.5990\n",
      "      down   : 0.6178\n",
      "      left   : 0.5656\n",
      "    MAE per class:\n",
      "      squares: 0.3289\n",
      "      circles: 0.2831\n",
      "      up     : 0.3438\n",
      "      right  : 0.3196\n",
      "      down   : 0.3640\n",
      "      left   : 0.3030\n",
      "    RMSE overall: 0.5888\n",
      "    MAE overall: 0.3237\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2917, cnt=0.8739, total=2.1656\n",
      "\n",
      "No improvement (val loss 2.1656); patience 3/10\n",
      "\n",
      "Test set (epoch 48):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.33%\n",
      "    Macro F1-score: 0.3600\n",
      "    Per-pair accuracy (unordered pair): 93.89%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.6136\n",
      "      circles: 0.4674\n",
      "      up     : 0.6517\n",
      "      right  : 0.5990\n",
      "      down   : 0.6178\n",
      "      left   : 0.5656\n",
      "    MAE per class:\n",
      "      squares: 0.3289\n",
      "      circles: 0.2831\n",
      "      up     : 0.3438\n",
      "      right  : 0.3196\n",
      "      down   : 0.3640\n",
      "      left   : 0.3030\n",
      "    RMSE overall: 0.5888\n",
      "    MAE overall: 0.3237\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2917, cnt=0.8739, total=2.1656\n",
      "\n",
      "No improvement (val loss 2.1656); patience 3/10\n",
      "Train Epoch: 49 [0/8100] Loss=1.3166\n",
      "Train Epoch: 49 [1280/8100] Loss=1.4419\n",
      "Train Epoch: 49 [0/8100] Loss=1.3166\n",
      "Train Epoch: 49 [1280/8100] Loss=1.4419\n",
      "Train Epoch: 49 [2560/8100] Loss=1.4446\n",
      "Train Epoch: 49 [2560/8100] Loss=1.4446\n",
      "Train Epoch: 49 [3840/8100] Loss=1.3780\n",
      "Train Epoch: 49 [5120/8100] Loss=1.7168\n",
      "Train Epoch: 49 [3840/8100] Loss=1.3780\n",
      "Train Epoch: 49 [5120/8100] Loss=1.7168\n",
      "Train Epoch: 49 [6400/8100] Loss=1.4616\n",
      "Train Epoch: 49 [6400/8100] Loss=1.4616\n",
      "Train Epoch: 49 [7680/8100] Loss=1.4561\n",
      "Train Epoch: 49 [7680/8100] Loss=1.4561\n",
      "\n",
      "Test set (epoch 49):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 52.00%\n",
      "    Macro F1-score: 0.3824\n",
      "    Per-pair accuracy (unordered pair): 94.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5535\n",
      "      circles: 0.5148\n",
      "      up     : 0.6169\n",
      "      right  : 0.5965\n",
      "      down   : 0.6346\n",
      "      left   : 0.5815\n",
      "    MAE per class:\n",
      "      squares: 0.3055\n",
      "      circles: 0.2935\n",
      "      up     : 0.3466\n",
      "      right  : 0.3411\n",
      "      down   : 0.3632\n",
      "      left   : 0.3005\n",
      "    RMSE overall: 0.5843\n",
      "    MAE overall: 0.3251\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2644, cnt=0.8643, total=2.1287\n",
      "\n",
      "No improvement (val loss 2.1287); patience 4/10\n",
      "\n",
      "Test set (epoch 49):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 52.00%\n",
      "    Macro F1-score: 0.3824\n",
      "    Per-pair accuracy (unordered pair): 94.44%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5535\n",
      "      circles: 0.5148\n",
      "      up     : 0.6169\n",
      "      right  : 0.5965\n",
      "      down   : 0.6346\n",
      "      left   : 0.5815\n",
      "    MAE per class:\n",
      "      squares: 0.3055\n",
      "      circles: 0.2935\n",
      "      up     : 0.3466\n",
      "      right  : 0.3411\n",
      "      down   : 0.3632\n",
      "      left   : 0.3005\n",
      "    RMSE overall: 0.5843\n",
      "    MAE overall: 0.3251\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2644, cnt=0.8643, total=2.1287\n",
      "\n",
      "No improvement (val loss 2.1287); patience 4/10\n",
      "Train Epoch: 50 [0/8100] Loss=1.4235\n",
      "Train Epoch: 50 [1280/8100] Loss=1.3880\n",
      "Train Epoch: 50 [0/8100] Loss=1.4235\n",
      "Train Epoch: 50 [1280/8100] Loss=1.3880\n",
      "Train Epoch: 50 [2560/8100] Loss=1.3441\n",
      "Train Epoch: 50 [2560/8100] Loss=1.3441\n",
      "Train Epoch: 50 [3840/8100] Loss=1.3275\n",
      "Train Epoch: 50 [5120/8100] Loss=1.6236\n",
      "Train Epoch: 50 [3840/8100] Loss=1.3275\n",
      "Train Epoch: 50 [5120/8100] Loss=1.6236\n",
      "Train Epoch: 50 [6400/8100] Loss=1.5248\n",
      "Train Epoch: 50 [6400/8100] Loss=1.5248\n",
      "Train Epoch: 50 [7680/8100] Loss=1.3167\n",
      "Train Epoch: 50 [7680/8100] Loss=1.3167\n",
      "\n",
      "Test set (epoch 50):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 52.67%\n",
      "    Macro F1-score: 0.3841\n",
      "    Per-pair accuracy (unordered pair): 94.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5351\n",
      "      circles: 0.4805\n",
      "      up     : 0.5963\n",
      "      right  : 0.5885\n",
      "      down   : 0.6049\n",
      "      left   : 0.5476\n",
      "    MAE per class:\n",
      "      squares: 0.2969\n",
      "      circles: 0.2712\n",
      "      up     : 0.3173\n",
      "      right  : 0.2992\n",
      "      down   : 0.3483\n",
      "      left   : 0.3051\n",
      "    RMSE overall: 0.5605\n",
      "    MAE overall: 0.3063\n",
      "\n",
      "  Losses:\n",
      "    cls=1.1903, cnt=0.8045, total=1.9948\n",
      "\n",
      "No improvement (val loss 1.9948); patience 5/10\n",
      "\n",
      "Test set (epoch 50):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 52.67%\n",
      "    Macro F1-score: 0.3841\n",
      "    Per-pair accuracy (unordered pair): 94.78%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5351\n",
      "      circles: 0.4805\n",
      "      up     : 0.5963\n",
      "      right  : 0.5885\n",
      "      down   : 0.6049\n",
      "      left   : 0.5476\n",
      "    MAE per class:\n",
      "      squares: 0.2969\n",
      "      circles: 0.2712\n",
      "      up     : 0.3173\n",
      "      right  : 0.2992\n",
      "      down   : 0.3483\n",
      "      left   : 0.3051\n",
      "    RMSE overall: 0.5605\n",
      "    MAE overall: 0.3063\n",
      "\n",
      "  Losses:\n",
      "    cls=1.1903, cnt=0.8045, total=1.9948\n",
      "\n",
      "No improvement (val loss 1.9948); patience 5/10\n",
      "Train Epoch: 51 [0/8100] Loss=1.2130\n",
      "Train Epoch: 51 [1280/8100] Loss=1.3345\n",
      "Train Epoch: 51 [0/8100] Loss=1.2130\n",
      "Train Epoch: 51 [1280/8100] Loss=1.3345\n",
      "Train Epoch: 51 [2560/8100] Loss=1.2516\n",
      "Train Epoch: 51 [2560/8100] Loss=1.2516\n",
      "Train Epoch: 51 [3840/8100] Loss=1.3471\n",
      "Train Epoch: 51 [5120/8100] Loss=1.5150\n",
      "Train Epoch: 51 [3840/8100] Loss=1.3471\n",
      "Train Epoch: 51 [5120/8100] Loss=1.5150\n",
      "Train Epoch: 51 [6400/8100] Loss=1.4670\n",
      "Train Epoch: 51 [6400/8100] Loss=1.4670\n",
      "Train Epoch: 51 [7680/8100] Loss=1.3772\n",
      "Train Epoch: 51 [7680/8100] Loss=1.3772\n",
      "\n",
      "Test set (epoch 51):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.33%\n",
      "    Macro F1-score: 0.3772\n",
      "    Per-pair accuracy (unordered pair): 94.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5204\n",
      "      circles: 0.5112\n",
      "      up     : 0.6806\n",
      "      right  : 0.5473\n",
      "      down   : 0.6599\n",
      "      left   : 0.6168\n",
      "    MAE per class:\n",
      "      squares: 0.2976\n",
      "      circles: 0.3019\n",
      "      up     : 0.4070\n",
      "      right  : 0.2977\n",
      "      down   : 0.3963\n",
      "      left   : 0.3129\n",
      "    RMSE overall: 0.5931\n",
      "    MAE overall: 0.3356\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2693, cnt=0.8967, total=2.1660\n",
      "\n",
      "No improvement (val loss 2.1660); patience 6/10\n",
      "\n",
      "Test set (epoch 51):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 51.33%\n",
      "    Macro F1-score: 0.3772\n",
      "    Per-pair accuracy (unordered pair): 94.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5204\n",
      "      circles: 0.5112\n",
      "      up     : 0.6806\n",
      "      right  : 0.5473\n",
      "      down   : 0.6599\n",
      "      left   : 0.6168\n",
      "    MAE per class:\n",
      "      squares: 0.2976\n",
      "      circles: 0.3019\n",
      "      up     : 0.4070\n",
      "      right  : 0.2977\n",
      "      down   : 0.3963\n",
      "      left   : 0.3129\n",
      "    RMSE overall: 0.5931\n",
      "    MAE overall: 0.3356\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2693, cnt=0.8967, total=2.1660\n",
      "\n",
      "No improvement (val loss 2.1660); patience 6/10\n",
      "Train Epoch: 52 [0/8100] Loss=1.3216\n",
      "Train Epoch: 52 [1280/8100] Loss=1.2638\n",
      "Train Epoch: 52 [0/8100] Loss=1.3216\n",
      "Train Epoch: 52 [1280/8100] Loss=1.2638\n",
      "Train Epoch: 52 [2560/8100] Loss=1.2728\n",
      "Train Epoch: 52 [2560/8100] Loss=1.2728\n",
      "Train Epoch: 52 [3840/8100] Loss=1.4993\n",
      "Train Epoch: 52 [5120/8100] Loss=1.4024\n",
      "Train Epoch: 52 [3840/8100] Loss=1.4993\n",
      "Train Epoch: 52 [5120/8100] Loss=1.4024\n",
      "Train Epoch: 52 [6400/8100] Loss=1.4910\n",
      "Train Epoch: 52 [6400/8100] Loss=1.4910\n",
      "Train Epoch: 52 [7680/8100] Loss=1.3520\n",
      "Train Epoch: 52 [7680/8100] Loss=1.3520\n",
      "\n",
      "Test set (epoch 52):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.44%\n",
      "    Macro F1-score: 0.3719\n",
      "    Per-pair accuracy (unordered pair): 95.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5670\n",
      "      circles: 0.6206\n",
      "      up     : 0.6406\n",
      "      right  : 0.6474\n",
      "      down   : 0.6739\n",
      "      left   : 0.5441\n",
      "    MAE per class:\n",
      "      squares: 0.3245\n",
      "      circles: 0.3400\n",
      "      up     : 0.3943\n",
      "      right  : 0.3660\n",
      "      down   : 0.3693\n",
      "      left   : 0.3152\n",
      "    RMSE overall: 0.6173\n",
      "    MAE overall: 0.3515\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2737, cnt=0.9627, total=2.2363\n",
      "\n",
      "No improvement (val loss 2.2363); patience 7/10\n",
      "\n",
      "Test set (epoch 52):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 50.44%\n",
      "    Macro F1-score: 0.3719\n",
      "    Per-pair accuracy (unordered pair): 95.22%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5670\n",
      "      circles: 0.6206\n",
      "      up     : 0.6406\n",
      "      right  : 0.6474\n",
      "      down   : 0.6739\n",
      "      left   : 0.5441\n",
      "    MAE per class:\n",
      "      squares: 0.3245\n",
      "      circles: 0.3400\n",
      "      up     : 0.3943\n",
      "      right  : 0.3660\n",
      "      down   : 0.3693\n",
      "      left   : 0.3152\n",
      "    RMSE overall: 0.6173\n",
      "    MAE overall: 0.3515\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2737, cnt=0.9627, total=2.2363\n",
      "\n",
      "No improvement (val loss 2.2363); patience 7/10\n",
      "Train Epoch: 53 [0/8100] Loss=1.3789\n",
      "Train Epoch: 53 [1280/8100] Loss=1.4376\n",
      "Train Epoch: 53 [0/8100] Loss=1.3789\n",
      "Train Epoch: 53 [1280/8100] Loss=1.4376\n",
      "Train Epoch: 53 [2560/8100] Loss=1.3196\n",
      "Train Epoch: 53 [2560/8100] Loss=1.3196\n",
      "Train Epoch: 53 [3840/8100] Loss=1.5309\n",
      "Train Epoch: 53 [5120/8100] Loss=1.4603\n",
      "Train Epoch: 53 [3840/8100] Loss=1.5309\n",
      "Train Epoch: 53 [5120/8100] Loss=1.4603\n",
      "Train Epoch: 53 [6400/8100] Loss=1.4079\n",
      "Train Epoch: 53 [6400/8100] Loss=1.4079\n",
      "Train Epoch: 53 [7680/8100] Loss=1.3731\n",
      "Train Epoch: 53 [7680/8100] Loss=1.3731\n",
      "\n",
      "Test set (epoch 53):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.33%\n",
      "    Macro F1-score: 0.3600\n",
      "    Per-pair accuracy (unordered pair): 94.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5582\n",
      "      circles: 0.4957\n",
      "      up     : 0.5912\n",
      "      right  : 0.6731\n",
      "      down   : 0.5787\n",
      "      left   : 0.5885\n",
      "    MAE per class:\n",
      "      squares: 0.3175\n",
      "      circles: 0.3129\n",
      "      up     : 0.3312\n",
      "      right  : 0.3602\n",
      "      down   : 0.3095\n",
      "      left   : 0.3225\n",
      "    RMSE overall: 0.5832\n",
      "    MAE overall: 0.3256\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2845, cnt=0.8624, total=2.1469\n",
      "\n",
      "No improvement (val loss 2.1469); patience 8/10\n",
      "\n",
      "Test set (epoch 53):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.33%\n",
      "    Macro F1-score: 0.3600\n",
      "    Per-pair accuracy (unordered pair): 94.00%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5582\n",
      "      circles: 0.4957\n",
      "      up     : 0.5912\n",
      "      right  : 0.6731\n",
      "      down   : 0.5787\n",
      "      left   : 0.5885\n",
      "    MAE per class:\n",
      "      squares: 0.3175\n",
      "      circles: 0.3129\n",
      "      up     : 0.3312\n",
      "      right  : 0.3602\n",
      "      down   : 0.3095\n",
      "      left   : 0.3225\n",
      "    RMSE overall: 0.5832\n",
      "    MAE overall: 0.3256\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2845, cnt=0.8624, total=2.1469\n",
      "\n",
      "No improvement (val loss 2.1469); patience 8/10\n",
      "Train Epoch: 54 [0/8100] Loss=1.2741\n",
      "Train Epoch: 54 [1280/8100] Loss=1.3134\n",
      "Train Epoch: 54 [0/8100] Loss=1.2741\n",
      "Train Epoch: 54 [1280/8100] Loss=1.3134\n",
      "Train Epoch: 54 [2560/8100] Loss=1.3345\n",
      "Train Epoch: 54 [2560/8100] Loss=1.3345\n",
      "Train Epoch: 54 [3840/8100] Loss=1.2943\n",
      "Train Epoch: 54 [5120/8100] Loss=1.2150\n",
      "Train Epoch: 54 [3840/8100] Loss=1.2943\n",
      "Train Epoch: 54 [5120/8100] Loss=1.2150\n",
      "Train Epoch: 54 [6400/8100] Loss=1.3390\n",
      "Train Epoch: 54 [6400/8100] Loss=1.3390\n",
      "Train Epoch: 54 [7680/8100] Loss=1.2116\n",
      "Train Epoch: 54 [7680/8100] Loss=1.2116\n",
      "\n",
      "Test set (epoch 54):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 52.56%\n",
      "    Macro F1-score: 0.3888\n",
      "    Per-pair accuracy (unordered pair): 95.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5760\n",
      "      circles: 0.4772\n",
      "      up     : 0.6063\n",
      "      right  : 0.6052\n",
      "      down   : 0.5663\n",
      "      left   : 0.5577\n",
      "    MAE per class:\n",
      "      squares: 0.3490\n",
      "      circles: 0.2676\n",
      "      up     : 0.3314\n",
      "      right  : 0.3375\n",
      "      down   : 0.3038\n",
      "      left   : 0.2980\n",
      "    RMSE overall: 0.5664\n",
      "    MAE overall: 0.3146\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2954, cnt=0.8215, total=2.1169\n",
      "\n",
      "No improvement (val loss 2.1169); patience 9/10\n",
      "\n",
      "Test set (epoch 54):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 52.56%\n",
      "    Macro F1-score: 0.3888\n",
      "    Per-pair accuracy (unordered pair): 95.11%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5760\n",
      "      circles: 0.4772\n",
      "      up     : 0.6063\n",
      "      right  : 0.6052\n",
      "      down   : 0.5663\n",
      "      left   : 0.5577\n",
      "    MAE per class:\n",
      "      squares: 0.3490\n",
      "      circles: 0.2676\n",
      "      up     : 0.3314\n",
      "      right  : 0.3375\n",
      "      down   : 0.3038\n",
      "      left   : 0.2980\n",
      "    RMSE overall: 0.5664\n",
      "    MAE overall: 0.3146\n",
      "\n",
      "  Losses:\n",
      "    cls=1.2954, cnt=0.8215, total=2.1169\n",
      "\n",
      "No improvement (val loss 2.1169); patience 9/10\n",
      "Train Epoch: 55 [0/8100] Loss=1.5174\n",
      "Train Epoch: 55 [1280/8100] Loss=1.4562\n",
      "Train Epoch: 55 [0/8100] Loss=1.5174\n",
      "Train Epoch: 55 [1280/8100] Loss=1.4562\n",
      "Train Epoch: 55 [2560/8100] Loss=1.2157\n",
      "Train Epoch: 55 [2560/8100] Loss=1.2157\n",
      "Train Epoch: 55 [3840/8100] Loss=1.4814\n",
      "Train Epoch: 55 [5120/8100] Loss=1.3101\n",
      "Train Epoch: 55 [3840/8100] Loss=1.4814\n",
      "Train Epoch: 55 [5120/8100] Loss=1.3101\n",
      "Train Epoch: 55 [6400/8100] Loss=1.1941\n",
      "Train Epoch: 55 [6400/8100] Loss=1.1941\n",
      "Train Epoch: 55 [7680/8100] Loss=1.3340\n",
      "Train Epoch: 55 [7680/8100] Loss=1.3340\n",
      "\n",
      "Test set (epoch 55):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.56%\n",
      "    Macro F1-score: 0.3675\n",
      "    Per-pair accuracy (unordered pair): 94.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5729\n",
      "      circles: 0.4939\n",
      "      up     : 0.6236\n",
      "      right  : 0.5797\n",
      "      down   : 0.5586\n",
      "      left   : 0.5800\n",
      "    MAE per class:\n",
      "      squares: 0.3101\n",
      "      circles: 0.3010\n",
      "      up     : 0.3396\n",
      "      right  : 0.3284\n",
      "      down   : 0.2986\n",
      "      left   : 0.3119\n",
      "    RMSE overall: 0.5694\n",
      "    MAE overall: 0.3149\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3014, cnt=0.8255, total=2.1269\n",
      "\n",
      "No improvement (val loss 2.1269); patience 10/10\n",
      "Early stopping triggered at epoch 55. Best val loss: 1.9905 (epoch 45)\n",
      "Restored best model from epoch 45 with val loss 1.9905\n",
      "\n",
      "Test set (epoch 55):\n",
      "  Classification (135-way):\n",
      "    Top-1 accuracy: 49.56%\n",
      "    Macro F1-score: 0.3675\n",
      "    Per-pair accuracy (unordered pair): 94.56%\n",
      "\n",
      "  Regression (6-D counts):\n",
      "    RMSE per class:\n",
      "      squares: 0.5729\n",
      "      circles: 0.4939\n",
      "      up     : 0.6236\n",
      "      right  : 0.5797\n",
      "      down   : 0.5586\n",
      "      left   : 0.5800\n",
      "    MAE per class:\n",
      "      squares: 0.3101\n",
      "      circles: 0.3010\n",
      "      up     : 0.3396\n",
      "      right  : 0.3284\n",
      "      down   : 0.2986\n",
      "      left   : 0.3119\n",
      "    RMSE overall: 0.5694\n",
      "    MAE overall: 0.3149\n",
      "\n",
      "  Losses:\n",
      "    cls=1.3014, cnt=0.8255, total=2.1269\n",
      "\n",
      "No improvement (val loss 2.1269); patience 10/10\n",
      "Early stopping triggered at epoch 55. Best val loss: 1.9905 (epoch 45)\n",
      "Restored best model from epoch 45 with val loss 1.9905\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiTaskNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "best_val_loss = float('inf')  # track best validation loss\n",
    "patience_counter = 0          # epochs since last improvement\n",
    "best_epoch = None\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    tr_metrics = train_epoch(\n",
    "        model, device, train_loader, optimizer, epoch, log_interval,\n",
    "        verbose=True, lambda_cnt=lambda_cnt, label_smoothing=label_smoothing\n",
    "    )\n",
    "    # use validation loader (subset of training data) instead of test set\n",
    "    val_metrics = test(\n",
    "        model, device, val_loader, epoch, lambda_cnt=lambda_cnt, verbose=True\n",
    "    )\n",
    "\n",
    "    train_losses.append(tr_metrics[\"loss\"])\n",
    "    train_top1.append(tr_metrics[\"top1\"])\n",
    "    train_pair_acc.append(tr_metrics[\"pair_acc\"])\n",
    "    val_losses.append(val_metrics[\"loss_total\"])\n",
    "    val_top1.append(val_metrics[\"top1\"])\n",
    "    val_pair_acc.append(val_metrics[\"pair_acc\"])\n",
    "    val_rmse_overall.append(val_metrics[\"rmse_overall\"])  # overall RMSE of counts\n",
    "\n",
    "    current_val_loss = val_metrics[\"loss_total\"]\n",
    "    if current_val_loss < best_val_loss - early_stopping_min_delta:\n",
    "        best_val_loss = current_val_loss\n",
    "        patience_counter = 0\n",
    "        best_epoch = epoch\n",
    "        best_model_state = model.state_dict()\n",
    "        print(f\"Improved val loss to {best_val_loss:.4f} at epoch {epoch}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement (val loss {current_val_loss:.4f}); patience {patience_counter}/{early_stopping_patience}\")\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}. Best val loss: {best_val_loss:.4f} (epoch {best_epoch})\")\n",
    "            break\n",
    "\n",
    "# (Optional) restore best model state after stopping\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Restored best model from epoch {best_epoch} with val loss {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "V-Fs58-x7wzr",
    "outputId": "8446140a-ce3a-49fd-8544-fe5c5bebd530"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "# 1) Loss curves\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs_range, train_losses, label='Train loss')\n",
    "plt.plot(epochs_range, val_losses, label='Val loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss Curves')\n",
    "plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "# 2) Accuracy & RMSE\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs_range, [100*a for a in val_top1], label='Val top-1 %')\n",
    "plt.plot(epochs_range, val_rmse_overall, label='Val RMSE overall')\n",
    "plt.xlabel('Epoch'); plt.title('Accuracy & RMSE');\n",
    "plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "# 3) Pair accuracy\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs_range, [100*a for a in train_pair_acc], label='Train pair %')\n",
    "plt.plot(epochs_range, [100*a for a in val_pair_acc], label='Val pair %')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Pair accuracy %'); plt.title('Pair Accuracy');\n",
    "plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "knr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
