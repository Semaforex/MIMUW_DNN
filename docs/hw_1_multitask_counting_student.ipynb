{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project: Multitask Learning for Geometric Shape Classification and Counting**\n",
        "\n",
        "## 1. Overview\n",
        "\n",
        "In this project, you will design, implement, and evaluate a **multitask neural network** that performs **two tasks simultaneously**:\n",
        "\n",
        "1. **Classification** – identify which pair of geometric shape types appears in a 28×28 binary image (135 possible configurations).\n",
        "2. **Regression** – predict how many shapes of each type are present (6 regression targets).\n",
        "\n",
        "This project focuses on **multi-task learning**, i.e., using one shared model to learn several related tasks at once. You will compare how adding an auxiliary task affects performance and training dynamics.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Dataset\n",
        "\n",
        "You will use the **Geometric Shape Numbers (GSN)** dataset:\n",
        "\n",
        "```bash\n",
        "!wget https://github.com/marcin119a/data/raw/refs/heads/main/data_gsn.zip\n",
        "!unzip data_gsn.zip &> /dev/null\n",
        "!rm data_gsn.zip\n",
        "```\n",
        "\n",
        "This will create a directory `data/` containing:\n",
        "\n",
        "* **10,000 images** (28×28x1, grayscale)\n",
        "* **labels.csv** – counts of each of six shape types per image\n",
        "\n",
        "Each image contains exactly **two types** of geometric figures (out of six) and **10 shapes total**.\n",
        "\n",
        "**Shape classes:**\n",
        "\n",
        "| Index | Shape type     |\n",
        "| ----: | -------------- |\n",
        "|     0 | square         |\n",
        "|     1 | circle         |\n",
        "|     2 | triangle up    |\n",
        "|     3 | triangle right |\n",
        "|     4 | triangle down  |\n",
        "|     5 | triangle left  |\n",
        "\n",
        "Example row from `labels.csv`:\n",
        "\n",
        "```\n",
        "name,squares,circles,up,right,down,left\n",
        "img_00000.png,0,0,0,4,0,6\n",
        "```\n",
        "\n",
        "Here, the image contains **4 right-pointing triangles** and **6 left-pointing triangles**.\n",
        "\n",
        "**Split:**\n",
        "\n",
        "* Training: first 9,000 samples\n",
        "* Validation: last 1,000 samples\n",
        "\n",
        "Examples:\n",
        "![example.png](data:image/png;base64,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)\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Tasks and objectives\n",
        "\n",
        "You must design a **multitask deep learning system** that:\n",
        "\n",
        "1. **Classifies** each image into one of **135 possible configurations**, representing:\n",
        "\n",
        "   * which **two shape classes** appear, and\n",
        "   * how their counts (1–9) sum to 10.\n",
        "\n",
        "   → Example: \"3 circles + 7 squares\" is one configuration class.\n",
        "\n",
        "2. **Regresses** the number of shapes of each type (a 6-dimensional real-valued output).\n",
        "\n",
        "3. Combines both objectives in a **joint loss** function (Hint: losses are implemented in PyTorch):\n",
        "\n",
        "\n",
        "$$ Loss = \\text{NLLLoss(classification)} + \\lambda_{\\text{cnt}} \\cdot \\text{SmoothL1Loss(regression)}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Model requirements\n",
        "\n",
        "### Architecture constraints\n",
        "\n",
        "You must use **exactly this feature extractor (backbone)**:\n",
        "\n",
        "```python\n",
        "nn.Sequential(\n",
        "    nn.Conv2d(1, 8, 3, stride=1, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(8, 16, 3, stride=1, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(),\n",
        "    nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(),\n",
        "    nn.Flatten(start_dim=1),\n",
        "    nn.Linear(64 * 28 * 28, 256), nn.ReLU()\n",
        ")\n",
        "```\n",
        "\n",
        "Then add **two separate heads**:\n",
        "\n",
        "* `head_cls`: outputs log-probabilities for 135 classes\n",
        "* `head_cnt`: outputs 6 regression values (counts)\n",
        "\n",
        "The model must return two outputs: `(log_probs, counts)`.\n",
        "\n",
        "You may add dropout or batch normalization inside the heads, **but you must not modify the backbone**.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Training setup\n",
        "\n",
        "* Optimizer: **Adam**, learning rate = 1e-3\n",
        "* Epochs: up to **100** (use **early stopping**)\n",
        "* Batch sizes: **64** (train), **1000** (validation)\n",
        "* Device: GPU allowed for Notebook, but your **final code must run on GPU within ~30 minutes**\n",
        "* Random seed: set `torch.manual_seed(1)` for reproducibility\n",
        "* Split: **exactly 9,000 train / 1,000 validation**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Data preprocessing and augmentation\n",
        "\n",
        "You must implement a **PyTorch `Dataset` class** that:\n",
        "\n",
        "* Reads `labels.csv`\n",
        "* Loads the corresponding image (from `data/`)\n",
        "* Returns both:\n",
        "  * the image (as a tensor)\n",
        "  * the labels (counts for 6 shapes)\n",
        "* Optionally applies transformations\n",
        "\n",
        "### Required augmentations\n",
        "\n",
        "You must implement **at least three** of the following:\n",
        "\n",
        "1. Random horizontal flip\n",
        "2. Random vertical flip\n",
        "3. Random 90° rotation (must correctly rotate orientation labels: up → right → down → left)\n",
        "4. Random brightness/contrast (mild)\n",
        "5. Gaussian noise\n",
        "6. Random erasing (small areas only)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Evaluation metrics\n",
        "\n",
        "Implement and report the following metrics on the validation set:\n",
        "\n",
        "### (a) **Classification (135-way)**\n",
        "\n",
        "* Top-1 accuracy\n",
        "* Macro F1-score\n",
        "* Per-pair accuracy (aggregate by unordered shape pair, e.g. {circle, up})\n",
        "\n",
        "### (b) **Regression (6-D counts)**\n",
        "\n",
        "* RMSE per class and overall\n",
        "* MAE per class and overall\n",
        "\n",
        "Also plot:\n",
        "\n",
        "* Training and validation losses\n",
        "* Validation accuracy and RMSE over epochs\n",
        "\n",
        "**Important**: This task is not about finding the best architecture; we expect at least 50% accuracy, but achieving results higher than that will not affect the grade for the assignment**.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Experiments and analysis\n",
        "\n",
        "You must train and compare **three model settings**:\n",
        "\n",
        "| Setting | Description                                      |\n",
        "| :------ | :----------------------------------------------- |\n",
        "| 1       | **Classification-only:** λ_cnt = 0               |\n",
        "| 2       | **Regression-only:** classification loss ignored |\n",
        "| 3       | **Multitask:** λ_cnt = with your choose          |\n",
        "\n",
        "For each experiment:\n",
        "\n",
        "* Train until early stopping\n",
        "* Record loss, accuracy, RMSE, and runtime\n",
        "* Compare results and explain how λ influences learning\n",
        "* Discuss whether multitask learning improves the main tasks\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Final deliverables\n",
        "\n",
        "You must submit .zip project with:\n",
        "\n",
        "1. **Code** (`.ipynb` or `.py`) that:\n",
        "\n",
        "   * Downloads and extracts the dataset\n",
        "   * Defines dataset, dataloaders, model, loss, training loop, evaluation, and plotting\n",
        "   * Can run start-to-end without interaction, and finishes within 30 minutes on Colab T4 GPUs\n",
        "   * Includes three experiment configurations\n",
        "\n",
        "2. **Report (2–4 pages, PDF)** including:\n",
        "   * Section on (EDA) Exploratory Data Analysis in your report: no more than 3 graphs or tables describing the data set.\n",
        "   * Model architecture\n",
        "   * Description and justification of augmentations\n",
        "   * Results table (loss, accuracy, RMSE for all runs)\n",
        "   * Learning curves\n",
        "   * Discussion on multitask effects\n",
        "\n",
        "3. **README.md**:\n",
        "\n",
        "   * Link to Colab version of task for fast replication.\n",
        "   * Approximate runtime and resource requirements\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Grading rubric\n",
        "\n",
        "Component\tDescription\tPoints\n",
        "1. Implementation correctness\tCorrect use of the fixed backbone, two-headed model, and proper training loop (classification + regression).\t30%\n",
        "2. Data & augmentations\tProper dataset loading, preprocessing, and at least three augmentations with brief justification.\t20%\n",
        "3. Evaluation & experiments\tCorrect computation of metrics (accuracy, F1, RMSE) and completion of all three λ configurations (λ=0, regression-only, your choice λ).\t30%\n",
        "4. Report & analysis\n",
        "A clear separation of concerns (e.g. headers in notebooks, modules in code) and concise 2–4 page report with results tables, learning curves, confusion matrix, and short discussion on multitask effects and error examples.\n",
        "20%\n",
        "\n",
        "###### Readability and modularity will be considered within each grading component. Clear structure (headers in notebooks, docstrings, modular code) significantly improves evaluation speed. Emphasize using clear headers to help reviewers navigate efficiently.\n",
        "---"
      ],
      "metadata": {
        "id": "_NvRrg8YvTPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://github.com/marcin119a/data/raw/refs/heads/main/data_gsn.zip\n",
        "!unzip data_gsn.zip &> /dev/null\n",
        "!rm data_gsn.zip"
      ],
      "metadata": {
        "id": "yUmggC-uvcGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating labels for classification problem\n",
        "\n",
        "There are 135 combinations. This comes from:\n",
        "$$\\binom{6}{2}\\cdot 9 = 15\\cdot9 = 135$$\n",
        "\n",
        "We propose the following labeling: <br>\n",
        "For counting label $$[a_0, a_1, a_2, a_3, a_4, a_5]$$ with the only non-zero elements $a_i$ and $a_j$, where $i<j$ we will use a label equal to:\n",
        "$$ f(i, j)\\cdot9+a_i-1$$\n",
        "Where $f(g, h)$, where $g<h$, is a simple indexing function: <br>\n",
        "$$f(g,h) = \\binom{h}{2}+g$$ where $0\\leq g<h\\leq5$. This provides us with unique labels from $0$ to $134$"
      ],
      "metadata": {
        "id": "clsXRR2XUjf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math as mth\n",
        "\n",
        "def cnt_to_cls_idx(cnt_label):\n",
        "  a_1, i_1, i_2 = 0, 0, 0\n",
        "  for i, cnt in enumerate(cnt_label):\n",
        "    if cnt > 0:\n",
        "      if not a_1:\n",
        "        a_1 = cnt\n",
        "        i_1 = i\n",
        "      else:\n",
        "        i_2 = i\n",
        "        break\n",
        "  cls_idx = (mth.comb(i_2, 2)+i_1)*9+a_1-1\n",
        "  return cls_idx\n",
        "\n",
        "def cls_idx_to_cnt(cls_idx):\n",
        "    if not (0 <= cls_idx <= 134):\n",
        "        raise ValueError(\"cls_idx must be in [0, 134] for 6 labels and counts 1..9\")\n",
        "\n",
        "    a_1 = (cls_idx % 9) + 1\n",
        "    pair_idx = cls_idx // 9\n",
        "    i_2 = 1\n",
        "    while mth.comb(i_2 + 1, 2) <= pair_idx:\n",
        "        i_2 += 1\n",
        "    i_1 = pair_idx - mth.comb(i_2, 2)\n",
        "\n",
        "    cnt_label = [0]*6\n",
        "    cnt_label[i_1] = a_1\n",
        "    cnt_label[i_2] = 10 - a_1\n",
        "    return cnt_label\n",
        "\n",
        "\n",
        "# Test the labeling and create O(1) mapping\n",
        "labels = set()\n",
        "for a1 in range(1, 10):\n",
        "  for idx1 in range(6):\n",
        "    for idx2 in range(idx1+1, 6):\n",
        "      label_cnt = [0]*6\n",
        "      label_cnt[idx1] = a1\n",
        "      label_cnt[idx2] = 10-a1\n",
        "      label = cnt_to_cls_idx(label_cnt)\n",
        "      if label in labels:\n",
        "        print(f\"Not ok {label}\")\n",
        "      if cls_idx_to_cnt(label) != label_cnt:\n",
        "        print(\"Not ok\")\n",
        "      labels.add(label)\n",
        "\n",
        "if len(labels) == 135:\n",
        "  print(\"Ok\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BSqeLuQ1Uqpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding new labels"
      ],
      "metadata": {
        "id": "xs6a3_uSYYNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "CSV_PATH = \"./data/labels.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "label_cols = df.columns[1:]\n",
        "n_images = len(df)\n",
        "\n",
        "class_indices = []\n",
        "for i in range(n_images):\n",
        "    cnt_label = df[label_cols].iloc[i].values\n",
        "    class_idx = cnt_to_cls_idx(cnt_label)\n",
        "    class_indices.append(class_idx)\n",
        "\n",
        "df[\"class_idx\"] = class_indices\n"
      ],
      "metadata": {
        "id": "eAGB4xBvYcg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Data\n"
      ],
      "metadata": {
        "id": "rhOb2Wyoyfer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cnt_label_cols = df.columns[1:7]\n",
        "n_images = len(df)\n",
        "\n",
        "\n",
        "# --- COUNT LABELS ANALYSIS ---\n",
        "total_shapes     = df[cnt_label_cols].sum().sum()\n",
        "shape_totals     = df[cnt_label_cols].sum()\n",
        "shape_percentage = 100 * shape_totals / total_shapes\n",
        "\n",
        "corr = df[cnt_label_cols].corr(numeric_only=True)\n",
        "nonzero_means = df[cnt_label_cols].replace(0, np.nan).mean()\n",
        "presence_percentage = 100 * (df[cnt_label_cols] > 0).sum() / n_images\n",
        "\n",
        "# Per-image constraints\n",
        "nonzero_per_image = (df[cnt_label_cols] > 0).sum(axis=1)\n",
        "sum_per_image     = df[cnt_label_cols].sum(axis=1)\n",
        "\n",
        "prop_exact_two_nonzero = (nonzero_per_image == 2).mean() * 100\n",
        "prop_sum_eq_10         = (sum_per_image == 10).mean() * 100\n",
        "prop_both_constraints  = ((nonzero_per_image == 2) & (sum_per_image == 10)).mean() * 100\n",
        "\n",
        "# --- CLASS INDEX ANALYSIS (robust) ---\n",
        "n_classes = 135\n",
        "\n",
        "# counts for all classes [0..n_classes-1], missing -> 0\n",
        "class_counts_raw = df[\"class_idx\"].value_counts()          # counts only for seen classes\n",
        "class_counts_full = class_counts_raw.reindex(range(n_classes), fill_value=0)\n",
        "\n",
        "# summary table: count + % of images containing that class\n",
        "class_presence_pct = 100 * class_counts_full / n_images\n",
        "class_summary = pd.DataFrame({\n",
        "    \"class_id\": range(n_classes),\n",
        "    \"count\": class_counts_full.values,\n",
        "    \"pct_of_images\": class_presence_pct.values\n",
        "})\n",
        "\n",
        "# stats\n",
        "num_used_classes = int((class_counts_full > 0).sum())\n",
        "pct_classes_used = 100 * num_used_classes / n_classes\n",
        "unused_classes = class_summary.loc[class_summary[\"count\"] == 0, \"class_id\"].tolist()\n",
        "\n",
        "# top / bottom 10 (including unseen)\n",
        "top10_classes = class_summary.sort_values(\"count\", ascending=False).head(10)\n",
        "least10_present = (\n",
        "    class_summary[class_summary[\"count\"] > 0]\n",
        "    .sort_values([\"count\", \"class_id\"], ascending=[True, True])\n",
        "    .head(10)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "# --- PRINT SUMMARY ---\n",
        "print(\"=== DATA OVERVIEW ===\")\n",
        "print(f\"Images: {n_images}\")\n",
        "print(f\"Count label columns: {list(label_cols)}\")\n",
        "print(f\"Number of classes: {n_classes}\")\n",
        "\n",
        "print(\"\\n=== COUNT LABELS SUMMARY ===\")\n",
        "print(f\"Total sum of all counts: {int(total_shapes)}\")\n",
        "print(\"\\nPer-label totals:\")\n",
        "print(shape_totals)\n",
        "print(\"\\nPer-label percentage of total (%):\")\n",
        "print(shape_percentage.round(2))\n",
        "print(\"\\nPresence percentage per label (%% of images with >0):\")\n",
        "print(presence_percentage.round(2))\n",
        "print(\"\\nMean of non-zero values per label:\")\n",
        "print(nonzero_means.round(3))\n",
        "\n",
        "print(\"\\n=== CONSTRAINT CHECKS ===\")\n",
        "print(f\"Images with exactly 2 non-zero count labels: {prop_exact_two_nonzero:.2f}%\")\n",
        "print(f\"Images with sum(counts) == 10: {prop_sum_eq_10:.2f}%\")\n",
        "print(f\"Images satisfying both: {prop_both_constraints:.2f}%\")\n",
        "\n",
        "print(\"\\nCorrelation matrix between count labels:\")\n",
        "print(corr.round(3))\n",
        "\n",
        "print(f\"Classes used: {num_used_classes}/{n_classes} ({pct_classes_used:.2f}%)\")\n",
        "print(\"Top 10 classes (id, count, % of images):\")\n",
        "print(top10_classes[[\"class_id\", \"count\", \"pct_of_images\"]].to_string(index=False))\n",
        "\n",
        "print(\"\\nLeast 10 classes (id, count, % of images):\")\n",
        "print(least10_present[[\"class_id\", \"count\", \"pct_of_images\"]].to_string(index=False))\n",
        "print(\"Unused common classes:\")\n",
        "print(unused_classes)\n"
      ],
      "metadata": {
        "id": "KbjAlQiVyjY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "The dataset is well balanced: all shapes appear with similar frequency, there are no strong correlations between shape types, and whenever a shape is present its average count is close to 5 out of 10. Based on this, not much data augmentation is needed."
      ],
      "metadata": {
        "id": "eVQLy-7S7_WW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Class\n",
        "Each transform is applied independently with a fixed probability."
      ],
      "metadata": {
        "id": "L4QwKRS1uwnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3ake3FpnUpxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "\n",
        "class MultitaskDataset(Dataset):\n",
        "\n",
        "  def __init__(self, root: str, transforms = None, transform_prob: float = 0.3):\n",
        "    self.root = Path(root)\n",
        "    self.df = pd.read_csv(root)\n",
        "    if transforms is None:\n",
        "      transforms = []\n",
        "    self.transforms = transforms\n",
        "    self.transform_prob = transform_prob\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.root.parent / self.df.iloc[idx, 0]\n",
        "    image = Image.open(img_path).convert('L')\n",
        "    label_cnt = self.df.iloc[idx, 1:].tolist()\n",
        "\n",
        "\n",
        "\n",
        "    for transform in self.transforms:\n",
        "      if torch.rand(1) < self.transform_prob:\n",
        "        image, label_cnt = transform(image, label_cnt)\n",
        "\n",
        "\n",
        "    cls_idx = cnt_to_cls_idx(label_cnt)\n",
        "    image = TF.to_tensor(image)\n",
        "    return image, torch.tensor(label_cnt, dtype=torch.float32), cls_idx\n",
        "\n",
        "\n",
        "def horizontal_flip(image, labels_cnt):\n",
        "  labels_cnt[3], labels_cnt[5] = labels_cnt[5], labels_cnt[3]\n",
        "  return image.transpose(Image.FLIP_LEFT_RIGHT), labels_cnt\n",
        "\n",
        "\n",
        "def vertical_flip(image, labels_cnt):\n",
        "  labels_cnt[2], labels_cnt[4] = labels_cnt[4], labels_cnt[2]\n",
        "  return image.transpose(Image.FLIP_TOP_BOTTOM), labels_cnt\n",
        "\n",
        "def rotation(image, labels_cnt):\n",
        "  labels_cnt = [labels_cnt[0], labels_cnt[1], labels_cnt[3], labels_cnt[4], labels_cnt[5], labels_cnt[2]]\n",
        "  return image.rotate(90), labels_cnt\n",
        "\n"
      ],
      "metadata": {
        "id": "Noooak7Y18Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data"
      ],
      "metadata": {
        "id": "vE1fwqZovBc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "g = torch.Generator().manual_seed(1)\n",
        "\n",
        "train_base = MultitaskDataset(\n",
        "    root=\"./data/labels.csv\",\n",
        "    transforms=[horizontal_flip, vertical_flip, rotation],\n",
        "    transform_prob=0.3\n",
        ")\n",
        "\n",
        "test_base = MultitaskDataset(\n",
        "    root=\"./data/labels.csv\",\n",
        "    transforms=[],\n",
        ")\n",
        "\n",
        "n = len(train_base)\n",
        "split = int(0.9 * n)\n",
        "\n",
        "train_idx = [i for i in range(split)]\n",
        "test_idx  = [i for i in range(split,n)]\n",
        "\n",
        "assert (len(train_idx), len(test_idx)) == (9000, 1000)\n",
        "\n",
        "train_ds = Subset(train_base, train_idx)\n",
        "test_ds  = Subset(test_base,  test_idx)\n",
        "\n",
        "num_workers = min(4, os.cpu_count() // 2)\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=1000, shuffle=False, num_workers=num_workers, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "uDskVAXfvkFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network structure\n"
      ],
      "metadata": {
        "id": "_ObxxKDb9YDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class MultiTaskNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Linear(64 * 28 * 28, 256), nn.ReLU()\n",
        "        )\n",
        "        self.head_cls = nn.Sequential(\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 135)\n",
        "        )\n",
        "        self.head_cnt = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 6)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone(x)\n",
        "        logits = self.head_cls(feat)\n",
        "        log_probs = F.log_softmax(logits, dim=1)\n",
        "        counts = self.head_cnt(feat)\n",
        "        return log_probs, counts\n"
      ],
      "metadata": {
        "id": "Ps2PbavO95CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n"
      ],
      "metadata": {
        "id": "D32dQyZbHAhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualiser"
      ],
      "metadata": {
        "id": "y8mlBVi99dzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# class TrainingVisualizer:\n",
        "#     def __init__(self, lr):\n",
        "#         self.lr = lr\n",
        "#         self.first_linear_layer = None\n",
        "\n",
        "#     def attach(self, model: nn.Module):\n",
        "#         \"\"\"Znajdź pierwszą warstwę liniową w modelu i zapamiętaj referencję.\"\"\"\n",
        "#         self.first_linear_layer = None\n",
        "#         for m in model.modules():\n",
        "#             if isinstance(m, nn.Linear):\n",
        "#                 self.first_linear_layer = m\n",
        "#                 break\n",
        "\n",
        "#     def plot_gradients_and_loss(self, batch_idx: int, loss: float):\n",
        "#         layer = self.first_linear_layer\n",
        "#         # Jeśli nie znaleziono warstwy lub brak gradientu – po prostu pomiń\n",
        "#         if layer is None or layer.weight is None or layer.weight.grad is None:\n",
        "#             return\n",
        "\n",
        "#         # Zabezpieczenia przed dzieleniem przez zero / NaN\n",
        "#         w_std = layer.weight.detach().std()\n",
        "#         g_std = layer.weight.grad.detach().std()\n",
        "#         if w_std == 0 or torch.isnan(w_std) or torch.isnan(g_std):\n",
        "#             return\n",
        "\n",
        "#         grad_to_weight_ratio = (self.lr * g_std / w_std).item()\n",
        "\n",
        "#         # ...tu Twoje rysowanie / logowanie:\n",
        "#         # self.writer.add_scalar(\"train/loss\", loss, batch_idx)\n",
        "#         # self.writer.add_scalar(\"train/grad_to_weight_ratio\", grad_to_weight_ratio, batch_idx)\n"
      ],
      "metadata": {
        "id": "ria9VZF0G6k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "MnAgvVKy9i7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "    model: torch.nn.Module,\n",
        "    device: torch.device,\n",
        "    train_loader: torch.utils.data.DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epoch: int,\n",
        "    log_interval: int,\n",
        "    # visualizer: TrainingVisualizer,\n",
        "    verbose: bool = False,\n",
        "    lambda_cnt: float = 0.5\n",
        ") -> float:\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    n_total = 0\n",
        "\n",
        "    for batch_idx, (data, target_cnt, target_cls) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        target_cls = target_cls.to(device).long()\n",
        "        target_cnt = target_cnt.to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        log_probs, counts = model(data)\n",
        "\n",
        "        loss_cls = F.nll_loss(log_probs, target_cls)\n",
        "        loss_cnt = F.smooth_l1_loss(counts, target_cnt)\n",
        "\n",
        "        loss = loss_cls + lambda_cnt * loss_cnt\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = data.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        n_total += batch_size\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            if verbose:\n",
        "                done, total = batch_idx * batch_size, len(train_loader.dataset)\n",
        "                print(\n",
        "                    f\"Train Epoch: {epoch} [{done}/{total} images ({done / total:.0%})]\\t\"\n",
        "                    + f\"Loss: {loss.item():.6f}\"\n",
        "                )\n",
        "\n",
        "    avg_loss = total_loss / n_total\n",
        "    return avg_loss\n"
      ],
      "metadata": {
        "id": "nM1ILMQ07fTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(\n",
        "    model: torch.nn.Module,\n",
        "    device: torch.device,\n",
        "    test_loader: torch.utils.data.DataLoader,\n",
        "    epoch: int,\n",
        "    lambda_cnt: float = 0.5,\n",
        "    verbose: bool = False,\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    n_classes = 135\n",
        "    n_reg_targets = 6\n",
        "\n",
        "    total_loss_cls = 0.0\n",
        "    total_loss_cnt = 0.0\n",
        "    n_total = 0\n",
        "\n",
        "    # classification metrics\n",
        "    n_correct_cls = 0\n",
        "    n_correct_pair = 0  # per-pair accuracy\n",
        "    conf_mat = torch.zeros(n_classes, n_classes, dtype=torch.long)\n",
        "\n",
        "    # regression metrics\n",
        "    sum_sq_err_per_class = torch.zeros(n_reg_targets)\n",
        "    sum_abs_err_per_class = torch.zeros(n_reg_targets)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target_cnt, target_cls in test_loader:\n",
        "            data = data.to(device)\n",
        "            target_cls = target_cls.to(device).long()\n",
        "            target_cnt = target_cnt.to(device).float()\n",
        "\n",
        "            log_probs, counts = model(data)\n",
        "\n",
        "            loss_cls = F.nll_loss(log_probs, target_cls, reduction=\"sum\")\n",
        "            loss_cnt = F.smooth_l1_loss(counts, target_cnt, reduction=\"sum\")\n",
        "\n",
        "            batch_size = data.size(0)\n",
        "            total_loss_cls += loss_cls.item()\n",
        "            total_loss_cnt += loss_cnt.item()\n",
        "            n_total += batch_size\n",
        "\n",
        "            pred_cls = log_probs.argmax(dim=1)\n",
        "\n",
        "            n_correct_cls += (pred_cls == target_cls).sum().item()\n",
        "\n",
        "            true_pair_idx = target_cls // 9\n",
        "            pred_pair_idx = pred_cls // 9\n",
        "            n_correct_pair += (true_pair_idx == pred_pair_idx).sum().item()\n",
        "\n",
        "            for t, p in zip(target_cls.view(-1), pred_cls.view(-1)):\n",
        "                conf_mat[t.item(), p.item()] += 1\n",
        "\n",
        "            diff = counts - target_cnt          # (B, 6)\n",
        "            sq_err = diff ** 2\n",
        "            abs_err = diff.abs()\n",
        "\n",
        "            sum_sq_err_per_class += sq_err.sum(dim=0).cpu()\n",
        "            sum_abs_err_per_class += abs_err.sum(dim=0).cpu()\n",
        "\n",
        "    # average losses\n",
        "    avg_loss_cls = total_loss_cls / n_total\n",
        "    avg_loss_cnt = total_loss_cnt / n_total\n",
        "    avg_loss_total = avg_loss_cls + lambda_cnt * avg_loss_cnt\n",
        "\n",
        "    # --- classification: top-1 & per-pair ---\n",
        "    top1_acc = n_correct_cls / n_total\n",
        "    pair_acc = n_correct_pair / n_total\n",
        "\n",
        "    # --- macro F1 over 135 classes ---\n",
        "    f1_per_class = []\n",
        "    for c in range(n_classes):\n",
        "        tp = conf_mat[c, c].item()\n",
        "        fp = conf_mat[:, c].sum().item() - tp\n",
        "        fn = conf_mat[c, :].sum().item() - tp\n",
        "\n",
        "        if tp == 0 and fp == 0 and fn == 0:\n",
        "            f1 = 0.0  # class never appears\n",
        "        else:\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "            if precision + recall == 0:\n",
        "                f1 = 0.0\n",
        "            else:\n",
        "                f1 = 2 * precision * recall / (precision + recall)\n",
        "        f1_per_class.append(f1)\n",
        "\n",
        "    macro_f1 = sum(f1_per_class) / n_classes\n",
        "\n",
        "    # --- regression: RMSE / MAE per class + overall ---\n",
        "    num_samples = n_total\n",
        "    rmse_per_class = (sum_sq_err_per_class / num_samples).sqrt()\n",
        "    mae_per_class = sum_abs_err_per_class / num_samples\n",
        "\n",
        "    num_elements = n_total * n_reg_targets\n",
        "    rmse_overall = (sum_sq_err_per_class.sum() / num_elements) ** 0.5\n",
        "    mae_overall = sum_abs_err_per_class.sum() / num_elements\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nTest set (epoch {epoch}):\")\n",
        "        print(f\"  Classification (135-way):\")\n",
        "        print(f\"    Top-1 accuracy: {100.0 * top1_acc:.2f}%\")\n",
        "        print(f\"    Macro F1-score: {macro_f1:.4f}\")\n",
        "        print(f\"    Per-pair accuracy (unordered pair): {100.0 * pair_acc:.2f}%\")\n",
        "\n",
        "        print(f\"\\n  Regression (6-D counts):\")\n",
        "        class_names = [\"squares\", \"circles\", \"up\", \"right\", \"down\", \"left\"]\n",
        "        print(\"    RMSE per class:\")\n",
        "        for name, v in zip(class_names, rmse_per_class):\n",
        "            print(f\"      {name:7s}: {v:.4f}\")\n",
        "        print(\"    MAE per class:\")\n",
        "        for name, v in zip(class_names, mae_per_class):\n",
        "            print(f\"      {name:7s}: {v:.4f}\")\n",
        "        print(f\"    RMSE overall: {rmse_overall:.4f}\")\n",
        "        print(f\"    MAE overall: {mae_overall:.4f}\")\n",
        "\n",
        "        print(f\"\\n  Losses:\")\n",
        "        print(f\"    cls={avg_loss_cls:.4f}, cnt={avg_loss_cnt:.4f}, total={avg_loss_total:.4f}\\n\")\n",
        "\n",
        "    # return everything so we can log/plot\n",
        "    return {\n",
        "        \"loss_cls\": avg_loss_cls,\n",
        "        \"loss_cnt\": avg_loss_cnt,\n",
        "        \"loss_total\": avg_loss_total,\n",
        "        \"top1\": top1_acc,\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"pair_acc\": pair_acc,\n",
        "        \"rmse_per_class\": rmse_per_class,\n",
        "        \"mae_per_class\": mae_per_class,\n",
        "        \"rmse_overall\": rmse_overall.item(),\n",
        "        \"mae_overall\": mae_overall.item(),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "FwU7CYdY1h4C"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "Kg_dRGdo3D44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "lambda_cnt = 1\n",
        "lr = 0.001\n",
        "\n",
        "log_interval = 10\n"
      ],
      "metadata": {
        "id": "kYxMHoc43HRA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "yFr2cj6W5M74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "model = MultiTaskNet().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# visualizer = TrainingVisualizer(lr=optimizer.param_groups[0][\"lr\"])\n",
        "# visualizer.attach(model)\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_epoch(\n",
        "        model,\n",
        "        device,\n",
        "        train_loader,\n",
        "        optimizer,\n",
        "        epoch,\n",
        "        log_interval,\n",
        "        # visualizer,\n",
        "        verbose=True,\n",
        "        lambda_cnt=lambda_cnt\n",
        "    )\n",
        "    test(model, device, test_loader, epoch, verbose = True) #visualizer, verbose=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "GnzDL1pSAot5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbdb9c6b-3950-436a-9cae-05d04644e690"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/9000 images (0%)]\tLoss: 6.400849\n",
            "Train Epoch: 1 [640/9000 images (7%)]\tLoss: 6.217244\n",
            "Train Epoch: 1 [1280/9000 images (14%)]\tLoss: 6.221544\n",
            "Train Epoch: 1 [1920/9000 images (21%)]\tLoss: 6.186970\n",
            "Train Epoch: 1 [2560/9000 images (28%)]\tLoss: 6.094488\n",
            "Train Epoch: 1 [3200/9000 images (36%)]\tLoss: 6.089694\n",
            "Train Epoch: 1 [3840/9000 images (43%)]\tLoss: 6.120149\n",
            "Train Epoch: 1 [4480/9000 images (50%)]\tLoss: 6.110209\n",
            "Train Epoch: 1 [5120/9000 images (57%)]\tLoss: 6.141380\n",
            "Train Epoch: 1 [5760/9000 images (64%)]\tLoss: 6.119569\n",
            "Train Epoch: 1 [6400/9000 images (71%)]\tLoss: 6.109132\n",
            "Train Epoch: 1 [7040/9000 images (78%)]\tLoss: 6.115865\n",
            "Train Epoch: 1 [7680/9000 images (85%)]\tLoss: 6.125960\n",
            "Train Epoch: 1 [8320/9000 images (92%)]\tLoss: 6.091089\n",
            "Train Epoch: 1 [5600/9000 images (62%)]\tLoss: 6.058277\n",
            "\n",
            "Test set (epoch 1):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 1.20%\n",
            "    Macro F1-score: 0.0005\n",
            "    Per-pair accuracy (unordered pair): 8.30%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 2.8452\n",
            "      circles: 2.8002\n",
            "      up     : 2.9579\n",
            "      right  : 2.9591\n",
            "      down   : 2.8606\n",
            "      left   : 2.7887\n",
            "    MAE per class:\n",
            "      squares: 1.8060\n",
            "      circles: 1.8682\n",
            "      up     : 1.8205\n",
            "      right  : 1.8685\n",
            "      down   : 1.7725\n",
            "      left   : 1.7765\n",
            "    RMSE overall: 2.8694\n",
            "    MAE overall: 1.8187\n",
            "\n",
            "  Losses:\n",
            "    cls=4.6739, cnt=8.4744, total=8.9111\n",
            "\n",
            "Train Epoch: 2 [0/9000 images (0%)]\tLoss: 6.069962\n",
            "Train Epoch: 2 [640/9000 images (7%)]\tLoss: 6.134440\n",
            "Train Epoch: 2 [1280/9000 images (14%)]\tLoss: 6.101567\n",
            "Train Epoch: 2 [1920/9000 images (21%)]\tLoss: 5.867496\n",
            "Train Epoch: 2 [2560/9000 images (28%)]\tLoss: 5.856515\n",
            "Train Epoch: 2 [3200/9000 images (36%)]\tLoss: 5.491814\n",
            "Train Epoch: 2 [3840/9000 images (43%)]\tLoss: 5.710882\n",
            "Train Epoch: 2 [4480/9000 images (50%)]\tLoss: 5.545031\n",
            "Train Epoch: 2 [5120/9000 images (57%)]\tLoss: 5.431169\n",
            "Train Epoch: 2 [5760/9000 images (64%)]\tLoss: 5.137099\n",
            "Train Epoch: 2 [6400/9000 images (71%)]\tLoss: 5.329782\n",
            "Train Epoch: 2 [7040/9000 images (78%)]\tLoss: 5.279714\n",
            "Train Epoch: 2 [7680/9000 images (85%)]\tLoss: 5.249753\n",
            "Train Epoch: 2 [8320/9000 images (92%)]\tLoss: 5.029112\n",
            "Train Epoch: 2 [5600/9000 images (62%)]\tLoss: 5.104548\n",
            "\n",
            "Test set (epoch 2):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 3.60%\n",
            "    Macro F1-score: 0.0060\n",
            "    Per-pair accuracy (unordered pair): 24.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 2.5015\n",
            "      circles: 2.7754\n",
            "      up     : 2.3788\n",
            "      right  : 2.9546\n",
            "      down   : 2.4956\n",
            "      left   : 1.7835\n",
            "    MAE per class:\n",
            "      squares: 1.6945\n",
            "      circles: 1.7164\n",
            "      up     : 1.5070\n",
            "      right  : 1.8547\n",
            "      down   : 1.5702\n",
            "      left   : 1.0880\n",
            "    RMSE overall: 2.5086\n",
            "    MAE overall: 1.5718\n",
            "\n",
            "  Losses:\n",
            "    cls=3.8829, cnt=7.3838, total=7.5748\n",
            "\n",
            "Train Epoch: 3 [0/9000 images (0%)]\tLoss: 5.115052\n",
            "Train Epoch: 3 [640/9000 images (7%)]\tLoss: 5.003801\n",
            "Train Epoch: 3 [1280/9000 images (14%)]\tLoss: 5.102077\n",
            "Train Epoch: 3 [1920/9000 images (21%)]\tLoss: 5.006168\n",
            "Train Epoch: 3 [2560/9000 images (28%)]\tLoss: 4.848704\n",
            "Train Epoch: 3 [3200/9000 images (36%)]\tLoss: 4.732475\n",
            "Train Epoch: 3 [3840/9000 images (43%)]\tLoss: 4.558147\n",
            "Train Epoch: 3 [4480/9000 images (50%)]\tLoss: 4.732911\n",
            "Train Epoch: 3 [5120/9000 images (57%)]\tLoss: 4.471457\n",
            "Train Epoch: 3 [5760/9000 images (64%)]\tLoss: 4.368061\n",
            "Train Epoch: 3 [6400/9000 images (71%)]\tLoss: 4.673670\n",
            "Train Epoch: 3 [7040/9000 images (78%)]\tLoss: 4.182598\n",
            "Train Epoch: 3 [7680/9000 images (85%)]\tLoss: 4.126039\n",
            "Train Epoch: 3 [8320/9000 images (92%)]\tLoss: 4.102285\n",
            "Train Epoch: 3 [5600/9000 images (62%)]\tLoss: 3.928406\n",
            "\n",
            "Test set (epoch 3):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 12.00%\n",
            "    Macro F1-score: 0.0447\n",
            "    Per-pair accuracy (unordered pair): 46.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 1.3269\n",
            "      circles: 2.6006\n",
            "      up     : 1.3214\n",
            "      right  : 2.1590\n",
            "      down   : 2.2027\n",
            "      left   : 1.1817\n",
            "    MAE per class:\n",
            "      squares: 0.7699\n",
            "      circles: 1.7007\n",
            "      up     : 0.9173\n",
            "      right  : 1.3502\n",
            "      down   : 1.5223\n",
            "      left   : 0.7074\n",
            "    RMSE overall: 1.8788\n",
            "    MAE overall: 1.1613\n",
            "\n",
            "  Losses:\n",
            "    cls=3.0481, cnt=5.0620, total=5.5791\n",
            "\n",
            "Train Epoch: 4 [0/9000 images (0%)]\tLoss: 4.205868\n",
            "Train Epoch: 4 [640/9000 images (7%)]\tLoss: 3.836902\n",
            "Train Epoch: 4 [1280/9000 images (14%)]\tLoss: 3.593803\n",
            "Train Epoch: 4 [1920/9000 images (21%)]\tLoss: 3.585287\n",
            "Train Epoch: 4 [2560/9000 images (28%)]\tLoss: 3.643233\n",
            "Train Epoch: 4 [3200/9000 images (36%)]\tLoss: 3.527216\n",
            "Train Epoch: 4 [3840/9000 images (43%)]\tLoss: 3.618731\n",
            "Train Epoch: 4 [4480/9000 images (50%)]\tLoss: 3.154340\n",
            "Train Epoch: 4 [5120/9000 images (57%)]\tLoss: 3.336102\n",
            "Train Epoch: 4 [5760/9000 images (64%)]\tLoss: 3.198939\n",
            "Train Epoch: 4 [6400/9000 images (71%)]\tLoss: 3.369658\n",
            "Train Epoch: 4 [7040/9000 images (78%)]\tLoss: 3.396615\n",
            "Train Epoch: 4 [7680/9000 images (85%)]\tLoss: 3.211173\n",
            "Train Epoch: 4 [8320/9000 images (92%)]\tLoss: 3.291127\n",
            "Train Epoch: 4 [5600/9000 images (62%)]\tLoss: 2.895823\n",
            "\n",
            "Test set (epoch 4):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 21.90%\n",
            "    Macro F1-score: 0.1124\n",
            "    Per-pair accuracy (unordered pair): 65.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 1.1143\n",
            "      circles: 2.0377\n",
            "      up     : 1.0654\n",
            "      right  : 1.4701\n",
            "      down   : 1.4725\n",
            "      left   : 1.0745\n",
            "    MAE per class:\n",
            "      squares: 0.6802\n",
            "      circles: 1.3552\n",
            "      up     : 0.6290\n",
            "      right  : 0.8348\n",
            "      down   : 0.9973\n",
            "      left   : 0.6673\n",
            "    RMSE overall: 1.4150\n",
            "    MAE overall: 0.8607\n",
            "\n",
            "  Losses:\n",
            "    cls=2.3398, cnt=3.3845, total=4.0321\n",
            "\n",
            "Train Epoch: 5 [0/9000 images (0%)]\tLoss: 2.942021\n",
            "Train Epoch: 5 [640/9000 images (7%)]\tLoss: 2.754010\n",
            "Train Epoch: 5 [1280/9000 images (14%)]\tLoss: 3.043558\n",
            "Train Epoch: 5 [1920/9000 images (21%)]\tLoss: 2.965683\n",
            "Train Epoch: 5 [2560/9000 images (28%)]\tLoss: 3.182672\n",
            "Train Epoch: 5 [3200/9000 images (36%)]\tLoss: 2.757786\n",
            "Train Epoch: 5 [3840/9000 images (43%)]\tLoss: 2.692985\n",
            "Train Epoch: 5 [4480/9000 images (50%)]\tLoss: 2.813732\n",
            "Train Epoch: 5 [5120/9000 images (57%)]\tLoss: 2.652583\n",
            "Train Epoch: 5 [5760/9000 images (64%)]\tLoss: 2.491720\n",
            "Train Epoch: 5 [6400/9000 images (71%)]\tLoss: 2.586032\n",
            "Train Epoch: 5 [7040/9000 images (78%)]\tLoss: 2.782963\n",
            "Train Epoch: 5 [7680/9000 images (85%)]\tLoss: 2.464843\n",
            "Train Epoch: 5 [8320/9000 images (92%)]\tLoss: 2.657480\n",
            "Train Epoch: 5 [5600/9000 images (62%)]\tLoss: 2.521872\n",
            "\n",
            "Test set (epoch 5):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 30.80%\n",
            "    Macro F1-score: 0.1848\n",
            "    Per-pair accuracy (unordered pair): 81.60%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 1.0741\n",
            "      circles: 1.0310\n",
            "      up     : 0.9264\n",
            "      right  : 1.1233\n",
            "      down   : 1.0015\n",
            "      left   : 0.9531\n",
            "    MAE per class:\n",
            "      squares: 0.6232\n",
            "      circles: 0.7215\n",
            "      up     : 0.5771\n",
            "      right  : 0.6519\n",
            "      down   : 0.6326\n",
            "      left   : 0.5650\n",
            "    RMSE overall: 1.0205\n",
            "    MAE overall: 0.6285\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9475, cnt=2.1655, total=3.0302\n",
            "\n",
            "Train Epoch: 6 [0/9000 images (0%)]\tLoss: 2.415948\n",
            "Train Epoch: 6 [640/9000 images (7%)]\tLoss: 2.405269\n",
            "Train Epoch: 6 [1280/9000 images (14%)]\tLoss: 2.325206\n",
            "Train Epoch: 6 [1920/9000 images (21%)]\tLoss: 2.503123\n",
            "Train Epoch: 6 [2560/9000 images (28%)]\tLoss: 2.044840\n",
            "Train Epoch: 6 [3200/9000 images (36%)]\tLoss: 2.459894\n",
            "Train Epoch: 6 [3840/9000 images (43%)]\tLoss: 2.236940\n",
            "Train Epoch: 6 [4480/9000 images (50%)]\tLoss: 2.326640\n",
            "Train Epoch: 6 [5120/9000 images (57%)]\tLoss: 2.227578\n",
            "Train Epoch: 6 [5760/9000 images (64%)]\tLoss: 2.656218\n",
            "Train Epoch: 6 [6400/9000 images (71%)]\tLoss: 2.214819\n",
            "Train Epoch: 6 [7040/9000 images (78%)]\tLoss: 1.942849\n",
            "Train Epoch: 6 [7680/9000 images (85%)]\tLoss: 2.269653\n",
            "Train Epoch: 6 [8320/9000 images (92%)]\tLoss: 2.283831\n",
            "Train Epoch: 6 [5600/9000 images (62%)]\tLoss: 2.194159\n",
            "\n",
            "Test set (epoch 6):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 30.00%\n",
            "    Macro F1-score: 0.1786\n",
            "    Per-pair accuracy (unordered pair): 83.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.8049\n",
            "      circles: 1.0926\n",
            "      up     : 1.0728\n",
            "      right  : 0.9809\n",
            "      down   : 0.8839\n",
            "      left   : 0.9494\n",
            "    MAE per class:\n",
            "      squares: 0.4757\n",
            "      circles: 0.8077\n",
            "      up     : 0.6003\n",
            "      right  : 0.5552\n",
            "      down   : 0.5749\n",
            "      left   : 0.5346\n",
            "    RMSE overall: 0.9693\n",
            "    MAE overall: 0.5914\n",
            "\n",
            "  Losses:\n",
            "    cls=1.8528, cnt=2.0033, total=2.8545\n",
            "\n",
            "Train Epoch: 7 [0/9000 images (0%)]\tLoss: 2.237283\n",
            "Train Epoch: 7 [640/9000 images (7%)]\tLoss: 1.985774\n",
            "Train Epoch: 7 [1280/9000 images (14%)]\tLoss: 2.138602\n",
            "Train Epoch: 7 [1920/9000 images (21%)]\tLoss: 2.088722\n",
            "Train Epoch: 7 [2560/9000 images (28%)]\tLoss: 1.992343\n",
            "Train Epoch: 7 [3200/9000 images (36%)]\tLoss: 1.832387\n",
            "Train Epoch: 7 [3840/9000 images (43%)]\tLoss: 2.132288\n",
            "Train Epoch: 7 [4480/9000 images (50%)]\tLoss: 1.939202\n",
            "Train Epoch: 7 [5120/9000 images (57%)]\tLoss: 1.948739\n",
            "Train Epoch: 7 [5760/9000 images (64%)]\tLoss: 1.984891\n",
            "Train Epoch: 7 [6400/9000 images (71%)]\tLoss: 1.905638\n",
            "Train Epoch: 7 [7040/9000 images (78%)]\tLoss: 1.954043\n",
            "Train Epoch: 7 [7680/9000 images (85%)]\tLoss: 2.015100\n",
            "Train Epoch: 7 [8320/9000 images (92%)]\tLoss: 2.244891\n",
            "Train Epoch: 7 [5600/9000 images (62%)]\tLoss: 2.198518\n",
            "\n",
            "Test set (epoch 7):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 33.50%\n",
            "    Macro F1-score: 0.2049\n",
            "    Per-pair accuracy (unordered pair): 86.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.7637\n",
            "      circles: 0.9819\n",
            "      up     : 0.9773\n",
            "      right  : 0.9042\n",
            "      down   : 0.9190\n",
            "      left   : 0.9358\n",
            "    MAE per class:\n",
            "      squares: 0.4449\n",
            "      circles: 0.5584\n",
            "      up     : 0.6757\n",
            "      right  : 0.5351\n",
            "      down   : 0.5053\n",
            "      left   : 0.5180\n",
            "    RMSE overall: 0.9165\n",
            "    MAE overall: 0.5396\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7140, cnt=1.8221, total=2.6250\n",
            "\n",
            "Train Epoch: 8 [0/9000 images (0%)]\tLoss: 2.001996\n",
            "Train Epoch: 8 [640/9000 images (7%)]\tLoss: 1.887814\n",
            "Train Epoch: 8 [1280/9000 images (14%)]\tLoss: 1.944125\n",
            "Train Epoch: 8 [1920/9000 images (21%)]\tLoss: 1.989854\n",
            "Train Epoch: 8 [2560/9000 images (28%)]\tLoss: 2.078171\n",
            "Train Epoch: 8 [3200/9000 images (36%)]\tLoss: 2.019862\n",
            "Train Epoch: 8 [3840/9000 images (43%)]\tLoss: 1.973682\n",
            "Train Epoch: 8 [4480/9000 images (50%)]\tLoss: 2.241350\n",
            "Train Epoch: 8 [5120/9000 images (57%)]\tLoss: 1.963476\n",
            "Train Epoch: 8 [5760/9000 images (64%)]\tLoss: 1.819728\n",
            "Train Epoch: 8 [6400/9000 images (71%)]\tLoss: 1.937908\n",
            "Train Epoch: 8 [7040/9000 images (78%)]\tLoss: 1.869242\n",
            "Train Epoch: 8 [7680/9000 images (85%)]\tLoss: 2.009599\n",
            "Train Epoch: 8 [8320/9000 images (92%)]\tLoss: 1.984873\n",
            "Train Epoch: 8 [5600/9000 images (62%)]\tLoss: 1.882810\n",
            "\n",
            "Test set (epoch 8):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 35.30%\n",
            "    Macro F1-score: 0.2353\n",
            "    Per-pair accuracy (unordered pair): 90.60%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.7475\n",
            "      circles: 0.7910\n",
            "      up     : 0.8535\n",
            "      right  : 0.8928\n",
            "      down   : 0.8525\n",
            "      left   : 0.8601\n",
            "    MAE per class:\n",
            "      squares: 0.4312\n",
            "      circles: 0.5145\n",
            "      up     : 0.4807\n",
            "      right  : 0.4950\n",
            "      down   : 0.4891\n",
            "      left   : 0.5184\n",
            "    RMSE overall: 0.8343\n",
            "    MAE overall: 0.4881\n",
            "\n",
            "  Losses:\n",
            "    cls=1.5998, cnt=1.5656, total=2.3826\n",
            "\n",
            "Train Epoch: 9 [0/9000 images (0%)]\tLoss: 1.894511\n",
            "Train Epoch: 9 [640/9000 images (7%)]\tLoss: 1.855902\n",
            "Train Epoch: 9 [1280/9000 images (14%)]\tLoss: 1.826192\n",
            "Train Epoch: 9 [1920/9000 images (21%)]\tLoss: 1.890236\n",
            "Train Epoch: 9 [2560/9000 images (28%)]\tLoss: 1.860296\n",
            "Train Epoch: 9 [3200/9000 images (36%)]\tLoss: 1.712398\n",
            "Train Epoch: 9 [3840/9000 images (43%)]\tLoss: 1.757631\n",
            "Train Epoch: 9 [4480/9000 images (50%)]\tLoss: 1.851874\n",
            "Train Epoch: 9 [5120/9000 images (57%)]\tLoss: 1.846166\n",
            "Train Epoch: 9 [5760/9000 images (64%)]\tLoss: 1.840506\n",
            "Train Epoch: 9 [6400/9000 images (71%)]\tLoss: 1.729546\n",
            "Train Epoch: 9 [7040/9000 images (78%)]\tLoss: 1.801607\n",
            "Train Epoch: 9 [7680/9000 images (85%)]\tLoss: 1.863650\n",
            "Train Epoch: 9 [8320/9000 images (92%)]\tLoss: 1.963236\n",
            "Train Epoch: 9 [5600/9000 images (62%)]\tLoss: 1.647392\n",
            "\n",
            "Test set (epoch 9):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 37.80%\n",
            "    Macro F1-score: 0.2442\n",
            "    Per-pair accuracy (unordered pair): 91.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6888\n",
            "      circles: 0.8311\n",
            "      up     : 0.8498\n",
            "      right  : 0.8227\n",
            "      down   : 0.7955\n",
            "      left   : 0.8491\n",
            "    MAE per class:\n",
            "      squares: 0.3974\n",
            "      circles: 0.4504\n",
            "      up     : 0.4611\n",
            "      right  : 0.4958\n",
            "      down   : 0.4708\n",
            "      left   : 0.4833\n",
            "    RMSE overall: 0.8081\n",
            "    MAE overall: 0.4598\n",
            "\n",
            "  Losses:\n",
            "    cls=1.5095, cnt=1.4738, total=2.2465\n",
            "\n",
            "Train Epoch: 10 [0/9000 images (0%)]\tLoss: 1.892247\n",
            "Train Epoch: 10 [640/9000 images (7%)]\tLoss: 1.976713\n",
            "Train Epoch: 10 [1280/9000 images (14%)]\tLoss: 1.841950\n",
            "Train Epoch: 10 [1920/9000 images (21%)]\tLoss: 1.621637\n",
            "Train Epoch: 10 [2560/9000 images (28%)]\tLoss: 1.687024\n",
            "Train Epoch: 10 [3200/9000 images (36%)]\tLoss: 1.985623\n",
            "Train Epoch: 10 [3840/9000 images (43%)]\tLoss: 1.756008\n",
            "Train Epoch: 10 [4480/9000 images (50%)]\tLoss: 1.691772\n",
            "Train Epoch: 10 [5120/9000 images (57%)]\tLoss: 1.810432\n",
            "Train Epoch: 10 [5760/9000 images (64%)]\tLoss: 1.795521\n",
            "Train Epoch: 10 [6400/9000 images (71%)]\tLoss: 1.751374\n",
            "Train Epoch: 10 [7040/9000 images (78%)]\tLoss: 2.068474\n",
            "Train Epoch: 10 [7680/9000 images (85%)]\tLoss: 1.790183\n",
            "Train Epoch: 10 [8320/9000 images (92%)]\tLoss: 1.725777\n",
            "Train Epoch: 10 [5600/9000 images (62%)]\tLoss: 1.639467\n",
            "\n",
            "Test set (epoch 10):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 38.90%\n",
            "    Macro F1-score: 0.2678\n",
            "    Per-pair accuracy (unordered pair): 90.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6738\n",
            "      circles: 0.7149\n",
            "      up     : 0.8210\n",
            "      right  : 0.7946\n",
            "      down   : 0.8630\n",
            "      left   : 0.8405\n",
            "    MAE per class:\n",
            "      squares: 0.3639\n",
            "      circles: 0.4288\n",
            "      up     : 0.5225\n",
            "      right  : 0.4534\n",
            "      down   : 0.4571\n",
            "      left   : 0.4634\n",
            "    RMSE overall: 0.7876\n",
            "    MAE overall: 0.4482\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4790, cnt=1.4187, total=2.1883\n",
            "\n",
            "Train Epoch: 11 [0/9000 images (0%)]\tLoss: 1.696171\n",
            "Train Epoch: 11 [640/9000 images (7%)]\tLoss: 1.765466\n",
            "Train Epoch: 11 [1280/9000 images (14%)]\tLoss: 1.343367\n",
            "Train Epoch: 11 [1920/9000 images (21%)]\tLoss: 1.808402\n",
            "Train Epoch: 11 [2560/9000 images (28%)]\tLoss: 1.864609\n",
            "Train Epoch: 11 [3200/9000 images (36%)]\tLoss: 1.768037\n",
            "Train Epoch: 11 [3840/9000 images (43%)]\tLoss: 1.704297\n",
            "Train Epoch: 11 [4480/9000 images (50%)]\tLoss: 1.476122\n",
            "Train Epoch: 11 [5120/9000 images (57%)]\tLoss: 1.808809\n",
            "Train Epoch: 11 [5760/9000 images (64%)]\tLoss: 1.610162\n",
            "Train Epoch: 11 [6400/9000 images (71%)]\tLoss: 1.623316\n",
            "Train Epoch: 11 [7040/9000 images (78%)]\tLoss: 1.511144\n",
            "Train Epoch: 11 [7680/9000 images (85%)]\tLoss: 1.530209\n",
            "Train Epoch: 11 [8320/9000 images (92%)]\tLoss: 1.746500\n",
            "Train Epoch: 11 [5600/9000 images (62%)]\tLoss: 1.497684\n",
            "\n",
            "Test set (epoch 11):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 40.50%\n",
            "    Macro F1-score: 0.2631\n",
            "    Per-pair accuracy (unordered pair): 91.80%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6405\n",
            "      circles: 0.7675\n",
            "      up     : 0.7443\n",
            "      right  : 0.7880\n",
            "      down   : 0.8336\n",
            "      left   : 0.7873\n",
            "    MAE per class:\n",
            "      squares: 0.3974\n",
            "      circles: 0.4212\n",
            "      up     : 0.4467\n",
            "      right  : 0.4688\n",
            "      down   : 0.4433\n",
            "      left   : 0.4648\n",
            "    RMSE overall: 0.7625\n",
            "    MAE overall: 0.4404\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4283, cnt=1.3596, total=2.1081\n",
            "\n",
            "Train Epoch: 12 [0/9000 images (0%)]\tLoss: 1.634966\n",
            "Train Epoch: 12 [640/9000 images (7%)]\tLoss: 1.575505\n",
            "Train Epoch: 12 [1280/9000 images (14%)]\tLoss: 1.616688\n",
            "Train Epoch: 12 [1920/9000 images (21%)]\tLoss: 1.530344\n",
            "Train Epoch: 12 [2560/9000 images (28%)]\tLoss: 1.730121\n",
            "Train Epoch: 12 [3200/9000 images (36%)]\tLoss: 1.580898\n",
            "Train Epoch: 12 [3840/9000 images (43%)]\tLoss: 1.623789\n",
            "Train Epoch: 12 [4480/9000 images (50%)]\tLoss: 1.446709\n",
            "Train Epoch: 12 [5120/9000 images (57%)]\tLoss: 1.868984\n",
            "Train Epoch: 12 [5760/9000 images (64%)]\tLoss: 1.525560\n",
            "Train Epoch: 12 [6400/9000 images (71%)]\tLoss: 1.661492\n",
            "Train Epoch: 12 [7040/9000 images (78%)]\tLoss: 1.681730\n",
            "Train Epoch: 12 [7680/9000 images (85%)]\tLoss: 1.974721\n",
            "Train Epoch: 12 [8320/9000 images (92%)]\tLoss: 1.924370\n",
            "Train Epoch: 12 [5600/9000 images (62%)]\tLoss: 1.771478\n",
            "\n",
            "Test set (epoch 12):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 41.70%\n",
            "    Macro F1-score: 0.2828\n",
            "    Per-pair accuracy (unordered pair): 92.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6352\n",
            "      circles: 0.6907\n",
            "      up     : 0.7641\n",
            "      right  : 0.7488\n",
            "      down   : 0.7443\n",
            "      left   : 0.7683\n",
            "    MAE per class:\n",
            "      squares: 0.3443\n",
            "      circles: 0.3791\n",
            "      up     : 0.4170\n",
            "      right  : 0.4297\n",
            "      down   : 0.4055\n",
            "      left   : 0.4355\n",
            "    RMSE overall: 0.7268\n",
            "    MAE overall: 0.4019\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3776, cnt=1.2437, total=1.9995\n",
            "\n",
            "Train Epoch: 13 [0/9000 images (0%)]\tLoss: 1.466870\n",
            "Train Epoch: 13 [640/9000 images (7%)]\tLoss: 1.645064\n",
            "Train Epoch: 13 [1280/9000 images (14%)]\tLoss: 1.604910\n",
            "Train Epoch: 13 [1920/9000 images (21%)]\tLoss: 1.491790\n",
            "Train Epoch: 13 [2560/9000 images (28%)]\tLoss: 1.643743\n",
            "Train Epoch: 13 [3200/9000 images (36%)]\tLoss: 1.555202\n",
            "Train Epoch: 13 [3840/9000 images (43%)]\tLoss: 1.734531\n",
            "Train Epoch: 13 [4480/9000 images (50%)]\tLoss: 1.446486\n",
            "Train Epoch: 13 [5120/9000 images (57%)]\tLoss: 1.726069\n",
            "Train Epoch: 13 [5760/9000 images (64%)]\tLoss: 1.617912\n",
            "Train Epoch: 13 [6400/9000 images (71%)]\tLoss: 1.471667\n",
            "Train Epoch: 13 [7040/9000 images (78%)]\tLoss: 1.526390\n",
            "Train Epoch: 13 [7680/9000 images (85%)]\tLoss: 1.340645\n",
            "Train Epoch: 13 [8320/9000 images (92%)]\tLoss: 1.591338\n",
            "Train Epoch: 13 [5600/9000 images (62%)]\tLoss: 1.784545\n",
            "\n",
            "Test set (epoch 13):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 41.90%\n",
            "    Macro F1-score: 0.2808\n",
            "    Per-pair accuracy (unordered pair): 91.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6963\n",
            "      circles: 0.9488\n",
            "      up     : 0.7275\n",
            "      right  : 0.7629\n",
            "      down   : 0.7107\n",
            "      left   : 0.7835\n",
            "    MAE per class:\n",
            "      squares: 0.3754\n",
            "      circles: 0.5205\n",
            "      up     : 0.4386\n",
            "      right  : 0.4495\n",
            "      down   : 0.4088\n",
            "      left   : 0.4737\n",
            "    RMSE overall: 0.7762\n",
            "    MAE overall: 0.4444\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4472, cnt=1.4033, total=2.1488\n",
            "\n",
            "Train Epoch: 14 [0/9000 images (0%)]\tLoss: 1.656437\n",
            "Train Epoch: 14 [640/9000 images (7%)]\tLoss: 1.637925\n",
            "Train Epoch: 14 [1280/9000 images (14%)]\tLoss: 1.565241\n",
            "Train Epoch: 14 [1920/9000 images (21%)]\tLoss: 1.571094\n",
            "Train Epoch: 14 [2560/9000 images (28%)]\tLoss: 1.430688\n",
            "Train Epoch: 14 [3200/9000 images (36%)]\tLoss: 1.779711\n",
            "Train Epoch: 14 [3840/9000 images (43%)]\tLoss: 1.477770\n",
            "Train Epoch: 14 [4480/9000 images (50%)]\tLoss: 1.453541\n",
            "Train Epoch: 14 [5120/9000 images (57%)]\tLoss: 1.440661\n",
            "Train Epoch: 14 [5760/9000 images (64%)]\tLoss: 1.475522\n",
            "Train Epoch: 14 [6400/9000 images (71%)]\tLoss: 1.599440\n",
            "Train Epoch: 14 [7040/9000 images (78%)]\tLoss: 1.425289\n",
            "Train Epoch: 14 [7680/9000 images (85%)]\tLoss: 1.662513\n",
            "Train Epoch: 14 [8320/9000 images (92%)]\tLoss: 1.632472\n",
            "Train Epoch: 14 [5600/9000 images (62%)]\tLoss: 1.517241\n",
            "\n",
            "Test set (epoch 14):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 40.00%\n",
            "    Macro F1-score: 0.2751\n",
            "    Per-pair accuracy (unordered pair): 92.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.7249\n",
            "      circles: 0.6632\n",
            "      up     : 0.7810\n",
            "      right  : 0.7386\n",
            "      down   : 0.7701\n",
            "      left   : 0.7527\n",
            "    MAE per class:\n",
            "      squares: 0.4009\n",
            "      circles: 0.4226\n",
            "      up     : 0.4255\n",
            "      right  : 0.4560\n",
            "      down   : 0.4038\n",
            "      left   : 0.4618\n",
            "    RMSE overall: 0.7394\n",
            "    MAE overall: 0.4284\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4117, cnt=1.3064, total=2.0649\n",
            "\n",
            "Train Epoch: 15 [0/9000 images (0%)]\tLoss: 1.409576\n",
            "Train Epoch: 15 [640/9000 images (7%)]\tLoss: 1.583304\n",
            "Train Epoch: 15 [1280/9000 images (14%)]\tLoss: 1.347091\n",
            "Train Epoch: 15 [1920/9000 images (21%)]\tLoss: 1.339494\n",
            "Train Epoch: 15 [2560/9000 images (28%)]\tLoss: 1.336538\n",
            "Train Epoch: 15 [3200/9000 images (36%)]\tLoss: 1.623846\n",
            "Train Epoch: 15 [3840/9000 images (43%)]\tLoss: 1.410993\n",
            "Train Epoch: 15 [4480/9000 images (50%)]\tLoss: 1.658718\n",
            "Train Epoch: 15 [5120/9000 images (57%)]\tLoss: 1.884430\n",
            "Train Epoch: 15 [5760/9000 images (64%)]\tLoss: 1.347218\n",
            "Train Epoch: 15 [6400/9000 images (71%)]\tLoss: 1.538082\n",
            "Train Epoch: 15 [7040/9000 images (78%)]\tLoss: 1.586318\n",
            "Train Epoch: 15 [7680/9000 images (85%)]\tLoss: 1.713167\n",
            "Train Epoch: 15 [8320/9000 images (92%)]\tLoss: 1.468199\n",
            "Train Epoch: 15 [5600/9000 images (62%)]\tLoss: 1.381236\n",
            "\n",
            "Test set (epoch 15):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 43.50%\n",
            "    Macro F1-score: 0.3023\n",
            "    Per-pair accuracy (unordered pair): 93.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5831\n",
            "      circles: 0.7883\n",
            "      up     : 0.7399\n",
            "      right  : 0.7180\n",
            "      down   : 0.6896\n",
            "      left   : 0.7577\n",
            "    MAE per class:\n",
            "      squares: 0.3326\n",
            "      circles: 0.4225\n",
            "      up     : 0.4611\n",
            "      right  : 0.4197\n",
            "      down   : 0.3852\n",
            "      left   : 0.4565\n",
            "    RMSE overall: 0.7158\n",
            "    MAE overall: 0.4129\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3441, cnt=1.2387, total=1.9634\n",
            "\n",
            "Train Epoch: 16 [0/9000 images (0%)]\tLoss: 1.558921\n",
            "Train Epoch: 16 [640/9000 images (7%)]\tLoss: 1.562521\n",
            "Train Epoch: 16 [1280/9000 images (14%)]\tLoss: 1.653480\n",
            "Train Epoch: 16 [1920/9000 images (21%)]\tLoss: 1.360080\n",
            "Train Epoch: 16 [2560/9000 images (28%)]\tLoss: 1.370098\n",
            "Train Epoch: 16 [3200/9000 images (36%)]\tLoss: 1.606146\n",
            "Train Epoch: 16 [3840/9000 images (43%)]\tLoss: 1.558140\n",
            "Train Epoch: 16 [4480/9000 images (50%)]\tLoss: 1.513630\n",
            "Train Epoch: 16 [5120/9000 images (57%)]\tLoss: 1.493075\n",
            "Train Epoch: 16 [5760/9000 images (64%)]\tLoss: 1.346535\n",
            "Train Epoch: 16 [6400/9000 images (71%)]\tLoss: 1.457916\n",
            "Train Epoch: 16 [7040/9000 images (78%)]\tLoss: 1.476325\n",
            "Train Epoch: 16 [7680/9000 images (85%)]\tLoss: 1.646212\n",
            "Train Epoch: 16 [8320/9000 images (92%)]\tLoss: 1.511998\n",
            "Train Epoch: 16 [5600/9000 images (62%)]\tLoss: 1.449848\n",
            "\n",
            "Test set (epoch 16):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 42.50%\n",
            "    Macro F1-score: 0.3078\n",
            "    Per-pair accuracy (unordered pair): 90.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6149\n",
            "      circles: 0.9281\n",
            "      up     : 0.7085\n",
            "      right  : 0.7638\n",
            "      down   : 0.7522\n",
            "      left   : 0.7369\n",
            "    MAE per class:\n",
            "      squares: 0.3434\n",
            "      circles: 0.5030\n",
            "      up     : 0.4196\n",
            "      right  : 0.4196\n",
            "      down   : 0.4824\n",
            "      left   : 0.4285\n",
            "    RMSE overall: 0.7565\n",
            "    MAE overall: 0.4328\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3845, cnt=1.3512, total=2.0601\n",
            "\n",
            "Train Epoch: 17 [0/9000 images (0%)]\tLoss: 1.488881\n",
            "Train Epoch: 17 [640/9000 images (7%)]\tLoss: 1.547628\n",
            "Train Epoch: 17 [1280/9000 images (14%)]\tLoss: 1.402653\n",
            "Train Epoch: 17 [1920/9000 images (21%)]\tLoss: 1.536514\n",
            "Train Epoch: 17 [2560/9000 images (28%)]\tLoss: 1.387861\n",
            "Train Epoch: 17 [3200/9000 images (36%)]\tLoss: 1.343011\n",
            "Train Epoch: 17 [3840/9000 images (43%)]\tLoss: 1.278392\n",
            "Train Epoch: 17 [4480/9000 images (50%)]\tLoss: 1.424425\n",
            "Train Epoch: 17 [5120/9000 images (57%)]\tLoss: 1.715331\n",
            "Train Epoch: 17 [5760/9000 images (64%)]\tLoss: 1.388332\n",
            "Train Epoch: 17 [6400/9000 images (71%)]\tLoss: 1.419447\n",
            "Train Epoch: 17 [7040/9000 images (78%)]\tLoss: 1.531468\n",
            "Train Epoch: 17 [7680/9000 images (85%)]\tLoss: 1.567269\n",
            "Train Epoch: 17 [8320/9000 images (92%)]\tLoss: 1.406681\n",
            "Train Epoch: 17 [5600/9000 images (62%)]\tLoss: 1.535908\n",
            "\n",
            "Test set (epoch 17):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 45.90%\n",
            "    Macro F1-score: 0.3200\n",
            "    Per-pair accuracy (unordered pair): 92.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5724\n",
            "      circles: 0.8061\n",
            "      up     : 0.7633\n",
            "      right  : 0.7062\n",
            "      down   : 0.6795\n",
            "      left   : 0.7710\n",
            "    MAE per class:\n",
            "      squares: 0.3377\n",
            "      circles: 0.4382\n",
            "      up     : 0.4515\n",
            "      right  : 0.4031\n",
            "      down   : 0.4130\n",
            "      left   : 0.4225\n",
            "    RMSE overall: 0.7205\n",
            "    MAE overall: 0.4110\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2828, cnt=1.2388, total=1.9021\n",
            "\n",
            "Train Epoch: 18 [0/9000 images (0%)]\tLoss: 1.456617\n",
            "Train Epoch: 18 [640/9000 images (7%)]\tLoss: 1.346303\n",
            "Train Epoch: 18 [1280/9000 images (14%)]\tLoss: 1.517476\n",
            "Train Epoch: 18 [1920/9000 images (21%)]\tLoss: 1.419040\n",
            "Train Epoch: 18 [2560/9000 images (28%)]\tLoss: 1.269314\n",
            "Train Epoch: 18 [3200/9000 images (36%)]\tLoss: 1.334679\n",
            "Train Epoch: 18 [3840/9000 images (43%)]\tLoss: 1.454995\n",
            "Train Epoch: 18 [4480/9000 images (50%)]\tLoss: 1.552695\n",
            "Train Epoch: 18 [5120/9000 images (57%)]\tLoss: 1.466367\n",
            "Train Epoch: 18 [5760/9000 images (64%)]\tLoss: 1.232910\n",
            "Train Epoch: 18 [6400/9000 images (71%)]\tLoss: 1.474853\n",
            "Train Epoch: 18 [7040/9000 images (78%)]\tLoss: 1.616232\n",
            "Train Epoch: 18 [7680/9000 images (85%)]\tLoss: 1.237557\n",
            "Train Epoch: 18 [8320/9000 images (92%)]\tLoss: 1.503486\n",
            "Train Epoch: 18 [5600/9000 images (62%)]\tLoss: 1.289990\n",
            "\n",
            "Test set (epoch 18):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.10%\n",
            "    Macro F1-score: 0.3389\n",
            "    Per-pair accuracy (unordered pair): 93.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5543\n",
            "      circles: 0.6779\n",
            "      up     : 0.6823\n",
            "      right  : 0.7227\n",
            "      down   : 0.6765\n",
            "      left   : 0.7191\n",
            "    MAE per class:\n",
            "      squares: 0.3165\n",
            "      circles: 0.3689\n",
            "      up     : 0.3914\n",
            "      right  : 0.3966\n",
            "      down   : 0.3782\n",
            "      left   : 0.4464\n",
            "    RMSE overall: 0.6745\n",
            "    MAE overall: 0.3830\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2498, cnt=1.1133, total=1.8064\n",
            "\n",
            "Train Epoch: 19 [0/9000 images (0%)]\tLoss: 1.403851\n",
            "Train Epoch: 19 [640/9000 images (7%)]\tLoss: 1.308112\n",
            "Train Epoch: 19 [1280/9000 images (14%)]\tLoss: 1.381984\n",
            "Train Epoch: 19 [1920/9000 images (21%)]\tLoss: 1.285001\n",
            "Train Epoch: 19 [2560/9000 images (28%)]\tLoss: 1.424902\n",
            "Train Epoch: 19 [3200/9000 images (36%)]\tLoss: 1.344428\n",
            "Train Epoch: 19 [3840/9000 images (43%)]\tLoss: 1.381945\n",
            "Train Epoch: 19 [4480/9000 images (50%)]\tLoss: 1.421869\n",
            "Train Epoch: 19 [5120/9000 images (57%)]\tLoss: 1.439098\n",
            "Train Epoch: 19 [5760/9000 images (64%)]\tLoss: 1.246556\n",
            "Train Epoch: 19 [6400/9000 images (71%)]\tLoss: 1.329712\n",
            "Train Epoch: 19 [7040/9000 images (78%)]\tLoss: 1.473041\n",
            "Train Epoch: 19 [7680/9000 images (85%)]\tLoss: 1.273308\n",
            "Train Epoch: 19 [8320/9000 images (92%)]\tLoss: 1.431346\n",
            "Train Epoch: 19 [5600/9000 images (62%)]\tLoss: 1.239254\n",
            "\n",
            "Test set (epoch 19):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 45.00%\n",
            "    Macro F1-score: 0.3213\n",
            "    Per-pair accuracy (unordered pair): 92.60%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5505\n",
            "      circles: 0.6027\n",
            "      up     : 0.6837\n",
            "      right  : 0.7764\n",
            "      down   : 0.6925\n",
            "      left   : 0.7330\n",
            "    MAE per class:\n",
            "      squares: 0.2942\n",
            "      circles: 0.3449\n",
            "      up     : 0.3831\n",
            "      right  : 0.4254\n",
            "      down   : 0.4150\n",
            "      left   : 0.4163\n",
            "    RMSE overall: 0.6774\n",
            "    MAE overall: 0.3798\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3135, cnt=1.1200, total=1.8735\n",
            "\n",
            "Train Epoch: 20 [0/9000 images (0%)]\tLoss: 1.147570\n",
            "Train Epoch: 20 [640/9000 images (7%)]\tLoss: 1.618139\n",
            "Train Epoch: 20 [1280/9000 images (14%)]\tLoss: 1.240665\n",
            "Train Epoch: 20 [1920/9000 images (21%)]\tLoss: 1.409327\n",
            "Train Epoch: 20 [2560/9000 images (28%)]\tLoss: 1.648070\n",
            "Train Epoch: 20 [3200/9000 images (36%)]\tLoss: 1.263483\n",
            "Train Epoch: 20 [3840/9000 images (43%)]\tLoss: 1.334743\n",
            "Train Epoch: 20 [4480/9000 images (50%)]\tLoss: 1.400263\n",
            "Train Epoch: 20 [5120/9000 images (57%)]\tLoss: 1.276443\n",
            "Train Epoch: 20 [5760/9000 images (64%)]\tLoss: 1.522830\n",
            "Train Epoch: 20 [6400/9000 images (71%)]\tLoss: 1.251007\n",
            "Train Epoch: 20 [7040/9000 images (78%)]\tLoss: 1.382563\n",
            "Train Epoch: 20 [7680/9000 images (85%)]\tLoss: 1.375759\n",
            "Train Epoch: 20 [8320/9000 images (92%)]\tLoss: 1.508850\n",
            "Train Epoch: 20 [5600/9000 images (62%)]\tLoss: 1.422230\n",
            "\n",
            "Test set (epoch 20):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.70%\n",
            "    Macro F1-score: 0.3317\n",
            "    Per-pair accuracy (unordered pair): 93.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5479\n",
            "      circles: 0.5982\n",
            "      up     : 0.7214\n",
            "      right  : 0.6937\n",
            "      down   : 0.6453\n",
            "      left   : 0.7376\n",
            "    MAE per class:\n",
            "      squares: 0.3224\n",
            "      circles: 0.3386\n",
            "      up     : 0.3917\n",
            "      right  : 0.3951\n",
            "      down   : 0.3811\n",
            "      left   : 0.4025\n",
            "    RMSE overall: 0.6608\n",
            "    MAE overall: 0.3719\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2606, cnt=1.0731, total=1.7971\n",
            "\n",
            "Train Epoch: 21 [0/9000 images (0%)]\tLoss: 1.432527\n",
            "Train Epoch: 21 [640/9000 images (7%)]\tLoss: 1.152601\n",
            "Train Epoch: 21 [1280/9000 images (14%)]\tLoss: 1.155804\n",
            "Train Epoch: 21 [1920/9000 images (21%)]\tLoss: 1.404708\n",
            "Train Epoch: 21 [2560/9000 images (28%)]\tLoss: 1.145994\n",
            "Train Epoch: 21 [3200/9000 images (36%)]\tLoss: 1.217704\n",
            "Train Epoch: 21 [3840/9000 images (43%)]\tLoss: 1.443662\n",
            "Train Epoch: 21 [4480/9000 images (50%)]\tLoss: 1.432213\n",
            "Train Epoch: 21 [5120/9000 images (57%)]\tLoss: 1.345626\n",
            "Train Epoch: 21 [5760/9000 images (64%)]\tLoss: 1.471785\n",
            "Train Epoch: 21 [6400/9000 images (71%)]\tLoss: 1.298328\n",
            "Train Epoch: 21 [7040/9000 images (78%)]\tLoss: 1.368579\n",
            "Train Epoch: 21 [7680/9000 images (85%)]\tLoss: 1.414566\n",
            "Train Epoch: 21 [8320/9000 images (92%)]\tLoss: 1.254528\n",
            "Train Epoch: 21 [5600/9000 images (62%)]\tLoss: 1.339904\n",
            "\n",
            "Test set (epoch 21):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 44.20%\n",
            "    Macro F1-score: 0.3041\n",
            "    Per-pair accuracy (unordered pair): 91.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.8809\n",
            "      circles: 0.6258\n",
            "      up     : 0.6741\n",
            "      right  : 0.7837\n",
            "      down   : 0.6781\n",
            "      left   : 0.7569\n",
            "    MAE per class:\n",
            "      squares: 0.5019\n",
            "      circles: 0.3929\n",
            "      up     : 0.3722\n",
            "      right  : 0.4971\n",
            "      down   : 0.3712\n",
            "      left   : 0.4306\n",
            "    RMSE overall: 0.7381\n",
            "    MAE overall: 0.4276\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3619, cnt=1.2963, total=2.0100\n",
            "\n",
            "Train Epoch: 22 [0/9000 images (0%)]\tLoss: 1.359594\n",
            "Train Epoch: 22 [640/9000 images (7%)]\tLoss: 1.239223\n",
            "Train Epoch: 22 [1280/9000 images (14%)]\tLoss: 1.194322\n",
            "Train Epoch: 22 [1920/9000 images (21%)]\tLoss: 1.431646\n",
            "Train Epoch: 22 [2560/9000 images (28%)]\tLoss: 1.290013\n",
            "Train Epoch: 22 [3200/9000 images (36%)]\tLoss: 1.200357\n",
            "Train Epoch: 22 [3840/9000 images (43%)]\tLoss: 1.256423\n",
            "Train Epoch: 22 [4480/9000 images (50%)]\tLoss: 1.246105\n",
            "Train Epoch: 22 [5120/9000 images (57%)]\tLoss: 1.300651\n",
            "Train Epoch: 22 [5760/9000 images (64%)]\tLoss: 1.597194\n",
            "Train Epoch: 22 [6400/9000 images (71%)]\tLoss: 1.316878\n",
            "Train Epoch: 22 [7040/9000 images (78%)]\tLoss: 1.163402\n",
            "Train Epoch: 22 [7680/9000 images (85%)]\tLoss: 1.301718\n",
            "Train Epoch: 22 [8320/9000 images (92%)]\tLoss: 1.213946\n",
            "Train Epoch: 22 [5600/9000 images (62%)]\tLoss: 1.291805\n",
            "\n",
            "Test set (epoch 22):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.40%\n",
            "    Macro F1-score: 0.3559\n",
            "    Per-pair accuracy (unordered pair): 93.10%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5822\n",
            "      circles: 0.7539\n",
            "      up     : 0.7329\n",
            "      right  : 0.7015\n",
            "      down   : 0.6420\n",
            "      left   : 0.7126\n",
            "    MAE per class:\n",
            "      squares: 0.3175\n",
            "      circles: 0.4234\n",
            "      up     : 0.4073\n",
            "      right  : 0.4265\n",
            "      down   : 0.4005\n",
            "      left   : 0.3955\n",
            "    RMSE overall: 0.6900\n",
            "    MAE overall: 0.3951\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2687, cnt=1.1577, total=1.8476\n",
            "\n",
            "Train Epoch: 23 [0/9000 images (0%)]\tLoss: 1.333628\n",
            "Train Epoch: 23 [640/9000 images (7%)]\tLoss: 1.345445\n",
            "Train Epoch: 23 [1280/9000 images (14%)]\tLoss: 1.103283\n",
            "Train Epoch: 23 [1920/9000 images (21%)]\tLoss: 1.155185\n",
            "Train Epoch: 23 [2560/9000 images (28%)]\tLoss: 1.337409\n",
            "Train Epoch: 23 [3200/9000 images (36%)]\tLoss: 1.208056\n",
            "Train Epoch: 23 [3840/9000 images (43%)]\tLoss: 1.300863\n",
            "Train Epoch: 23 [4480/9000 images (50%)]\tLoss: 1.126523\n",
            "Train Epoch: 23 [5120/9000 images (57%)]\tLoss: 1.332693\n",
            "Train Epoch: 23 [5760/9000 images (64%)]\tLoss: 1.337847\n",
            "Train Epoch: 23 [6400/9000 images (71%)]\tLoss: 1.161627\n",
            "Train Epoch: 23 [7040/9000 images (78%)]\tLoss: 1.048901\n",
            "Train Epoch: 23 [7680/9000 images (85%)]\tLoss: 1.422792\n",
            "Train Epoch: 23 [8320/9000 images (92%)]\tLoss: 1.275248\n",
            "Train Epoch: 23 [5600/9000 images (62%)]\tLoss: 1.086064\n",
            "\n",
            "Test set (epoch 23):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 45.30%\n",
            "    Macro F1-score: 0.3180\n",
            "    Per-pair accuracy (unordered pair): 93.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5385\n",
            "      circles: 0.6033\n",
            "      up     : 0.6574\n",
            "      right  : 0.6923\n",
            "      down   : 0.6300\n",
            "      left   : 0.7547\n",
            "    MAE per class:\n",
            "      squares: 0.3486\n",
            "      circles: 0.3758\n",
            "      up     : 0.3735\n",
            "      right  : 0.3797\n",
            "      down   : 0.3512\n",
            "      left   : 0.4193\n",
            "    RMSE overall: 0.6496\n",
            "    MAE overall: 0.3747\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2868, cnt=1.0484, total=1.8110\n",
            "\n",
            "Train Epoch: 24 [0/9000 images (0%)]\tLoss: 1.404332\n",
            "Train Epoch: 24 [640/9000 images (7%)]\tLoss: 1.123740\n",
            "Train Epoch: 24 [1280/9000 images (14%)]\tLoss: 1.232944\n",
            "Train Epoch: 24 [1920/9000 images (21%)]\tLoss: 1.191749\n",
            "Train Epoch: 24 [2560/9000 images (28%)]\tLoss: 1.182032\n",
            "Train Epoch: 24 [3200/9000 images (36%)]\tLoss: 1.243643\n",
            "Train Epoch: 24 [3840/9000 images (43%)]\tLoss: 1.321603\n",
            "Train Epoch: 24 [4480/9000 images (50%)]\tLoss: 1.141749\n",
            "Train Epoch: 24 [5120/9000 images (57%)]\tLoss: 1.121924\n",
            "Train Epoch: 24 [5760/9000 images (64%)]\tLoss: 1.122376\n",
            "Train Epoch: 24 [6400/9000 images (71%)]\tLoss: 1.011343\n",
            "Train Epoch: 24 [7040/9000 images (78%)]\tLoss: 1.250533\n",
            "Train Epoch: 24 [7680/9000 images (85%)]\tLoss: 1.198619\n",
            "Train Epoch: 24 [8320/9000 images (92%)]\tLoss: 1.363481\n",
            "Train Epoch: 24 [5600/9000 images (62%)]\tLoss: 0.974631\n",
            "\n",
            "Test set (epoch 24):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.50%\n",
            "    Macro F1-score: 0.3526\n",
            "    Per-pair accuracy (unordered pair): 92.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6251\n",
            "      circles: 0.6241\n",
            "      up     : 0.6592\n",
            "      right  : 0.6789\n",
            "      down   : 0.6595\n",
            "      left   : 0.7222\n",
            "    MAE per class:\n",
            "      squares: 0.3351\n",
            "      circles: 0.4153\n",
            "      up     : 0.3774\n",
            "      right  : 0.4218\n",
            "      down   : 0.3584\n",
            "      left   : 0.3987\n",
            "    RMSE overall: 0.6623\n",
            "    MAE overall: 0.3844\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2746, cnt=1.0892, total=1.8192\n",
            "\n",
            "Train Epoch: 25 [0/9000 images (0%)]\tLoss: 1.336010\n",
            "Train Epoch: 25 [640/9000 images (7%)]\tLoss: 1.375347\n",
            "Train Epoch: 25 [1280/9000 images (14%)]\tLoss: 1.182997\n",
            "Train Epoch: 25 [1920/9000 images (21%)]\tLoss: 1.199291\n",
            "Train Epoch: 25 [2560/9000 images (28%)]\tLoss: 1.192609\n",
            "Train Epoch: 25 [3200/9000 images (36%)]\tLoss: 0.905665\n",
            "Train Epoch: 25 [3840/9000 images (43%)]\tLoss: 1.204582\n",
            "Train Epoch: 25 [4480/9000 images (50%)]\tLoss: 1.302275\n",
            "Train Epoch: 25 [5120/9000 images (57%)]\tLoss: 1.038574\n",
            "Train Epoch: 25 [5760/9000 images (64%)]\tLoss: 1.194471\n",
            "Train Epoch: 25 [6400/9000 images (71%)]\tLoss: 1.187526\n",
            "Train Epoch: 25 [7040/9000 images (78%)]\tLoss: 0.993662\n",
            "Train Epoch: 25 [7680/9000 images (85%)]\tLoss: 1.215068\n",
            "Train Epoch: 25 [8320/9000 images (92%)]\tLoss: 1.130078\n",
            "Train Epoch: 25 [5600/9000 images (62%)]\tLoss: 1.201284\n",
            "\n",
            "Test set (epoch 25):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.00%\n",
            "    Macro F1-score: 0.3570\n",
            "    Per-pair accuracy (unordered pair): 93.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5617\n",
            "      circles: 0.5868\n",
            "      up     : 0.6683\n",
            "      right  : 0.6688\n",
            "      down   : 0.6374\n",
            "      left   : 0.7098\n",
            "    MAE per class:\n",
            "      squares: 0.3114\n",
            "      circles: 0.3212\n",
            "      up     : 0.3697\n",
            "      right  : 0.3958\n",
            "      down   : 0.3725\n",
            "      left   : 0.4158\n",
            "    RMSE overall: 0.6408\n",
            "    MAE overall: 0.3644\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2309, cnt=1.0232, total=1.7425\n",
            "\n",
            "Train Epoch: 26 [0/9000 images (0%)]\tLoss: 1.263041\n",
            "Train Epoch: 26 [640/9000 images (7%)]\tLoss: 1.122609\n",
            "Train Epoch: 26 [1280/9000 images (14%)]\tLoss: 1.310009\n",
            "Train Epoch: 26 [1920/9000 images (21%)]\tLoss: 1.182015\n",
            "Train Epoch: 26 [2560/9000 images (28%)]\tLoss: 0.997352\n",
            "Train Epoch: 26 [3200/9000 images (36%)]\tLoss: 1.161032\n",
            "Train Epoch: 26 [3840/9000 images (43%)]\tLoss: 1.181865\n",
            "Train Epoch: 26 [4480/9000 images (50%)]\tLoss: 1.315521\n",
            "Train Epoch: 26 [5120/9000 images (57%)]\tLoss: 1.253255\n",
            "Train Epoch: 26 [5760/9000 images (64%)]\tLoss: 1.083360\n",
            "Train Epoch: 26 [6400/9000 images (71%)]\tLoss: 1.132159\n",
            "Train Epoch: 26 [7040/9000 images (78%)]\tLoss: 1.396495\n",
            "Train Epoch: 26 [7680/9000 images (85%)]\tLoss: 1.231439\n",
            "Train Epoch: 26 [8320/9000 images (92%)]\tLoss: 1.177446\n",
            "Train Epoch: 26 [5600/9000 images (62%)]\tLoss: 1.242026\n",
            "\n",
            "Test set (epoch 26):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.00%\n",
            "    Macro F1-score: 0.3376\n",
            "    Per-pair accuracy (unordered pair): 94.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5875\n",
            "      circles: 0.6050\n",
            "      up     : 0.6835\n",
            "      right  : 0.6817\n",
            "      down   : 0.6278\n",
            "      left   : 0.7473\n",
            "    MAE per class:\n",
            "      squares: 0.3350\n",
            "      circles: 0.3656\n",
            "      up     : 0.3843\n",
            "      right  : 0.3727\n",
            "      down   : 0.3742\n",
            "      left   : 0.4161\n",
            "    RMSE overall: 0.6577\n",
            "    MAE overall: 0.3747\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2614, cnt=1.0715, total=1.7971\n",
            "\n",
            "Train Epoch: 27 [0/9000 images (0%)]\tLoss: 1.220509\n",
            "Train Epoch: 27 [640/9000 images (7%)]\tLoss: 1.162732\n",
            "Train Epoch: 27 [1280/9000 images (14%)]\tLoss: 1.114933\n",
            "Train Epoch: 27 [1920/9000 images (21%)]\tLoss: 1.256373\n",
            "Train Epoch: 27 [2560/9000 images (28%)]\tLoss: 1.160398\n",
            "Train Epoch: 27 [3200/9000 images (36%)]\tLoss: 0.980690\n",
            "Train Epoch: 27 [3840/9000 images (43%)]\tLoss: 1.087770\n",
            "Train Epoch: 27 [4480/9000 images (50%)]\tLoss: 1.165070\n",
            "Train Epoch: 27 [5120/9000 images (57%)]\tLoss: 1.125874\n",
            "Train Epoch: 27 [5760/9000 images (64%)]\tLoss: 1.336353\n",
            "Train Epoch: 27 [6400/9000 images (71%)]\tLoss: 1.231909\n",
            "Train Epoch: 27 [7040/9000 images (78%)]\tLoss: 1.555673\n",
            "Train Epoch: 27 [7680/9000 images (85%)]\tLoss: 1.150115\n",
            "Train Epoch: 27 [8320/9000 images (92%)]\tLoss: 1.134183\n",
            "Train Epoch: 27 [5600/9000 images (62%)]\tLoss: 1.301538\n",
            "\n",
            "Test set (epoch 27):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.50%\n",
            "    Macro F1-score: 0.3459\n",
            "    Per-pair accuracy (unordered pair): 93.80%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5791\n",
            "      circles: 0.5888\n",
            "      up     : 0.6613\n",
            "      right  : 0.6791\n",
            "      down   : 0.6710\n",
            "      left   : 0.7108\n",
            "    MAE per class:\n",
            "      squares: 0.3158\n",
            "      circles: 0.3242\n",
            "      up     : 0.3835\n",
            "      right  : 0.3941\n",
            "      down   : 0.3614\n",
            "      left   : 0.4162\n",
            "    RMSE overall: 0.6501\n",
            "    MAE overall: 0.3659\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2759, cnt=1.0455, total=1.7987\n",
            "\n",
            "Train Epoch: 28 [0/9000 images (0%)]\tLoss: 1.191158\n",
            "Train Epoch: 28 [640/9000 images (7%)]\tLoss: 1.151243\n",
            "Train Epoch: 28 [1280/9000 images (14%)]\tLoss: 1.303244\n",
            "Train Epoch: 28 [1920/9000 images (21%)]\tLoss: 1.015395\n",
            "Train Epoch: 28 [2560/9000 images (28%)]\tLoss: 0.943520\n",
            "Train Epoch: 28 [3200/9000 images (36%)]\tLoss: 1.112816\n",
            "Train Epoch: 28 [3840/9000 images (43%)]\tLoss: 1.307377\n",
            "Train Epoch: 28 [4480/9000 images (50%)]\tLoss: 1.300637\n",
            "Train Epoch: 28 [5120/9000 images (57%)]\tLoss: 1.066860\n",
            "Train Epoch: 28 [5760/9000 images (64%)]\tLoss: 1.037393\n",
            "Train Epoch: 28 [6400/9000 images (71%)]\tLoss: 1.121895\n",
            "Train Epoch: 28 [7040/9000 images (78%)]\tLoss: 1.022105\n",
            "Train Epoch: 28 [7680/9000 images (85%)]\tLoss: 1.050866\n",
            "Train Epoch: 28 [8320/9000 images (92%)]\tLoss: 1.197482\n",
            "Train Epoch: 28 [5600/9000 images (62%)]\tLoss: 1.111542\n",
            "\n",
            "Test set (epoch 28):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.10%\n",
            "    Macro F1-score: 0.3421\n",
            "    Per-pair accuracy (unordered pair): 94.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5077\n",
            "      circles: 0.5466\n",
            "      up     : 0.6721\n",
            "      right  : 0.6497\n",
            "      down   : 0.6916\n",
            "      left   : 0.7486\n",
            "    MAE per class:\n",
            "      squares: 0.2950\n",
            "      circles: 0.3153\n",
            "      up     : 0.3681\n",
            "      right  : 0.3745\n",
            "      down   : 0.3741\n",
            "      left   : 0.4155\n",
            "    RMSE overall: 0.6415\n",
            "    MAE overall: 0.3571\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2754, cnt=1.0124, total=1.7816\n",
            "\n",
            "Train Epoch: 29 [0/9000 images (0%)]\tLoss: 1.197705\n",
            "Train Epoch: 29 [640/9000 images (7%)]\tLoss: 1.087745\n",
            "Train Epoch: 29 [1280/9000 images (14%)]\tLoss: 1.266759\n",
            "Train Epoch: 29 [1920/9000 images (21%)]\tLoss: 1.116529\n",
            "Train Epoch: 29 [2560/9000 images (28%)]\tLoss: 1.167070\n",
            "Train Epoch: 29 [3200/9000 images (36%)]\tLoss: 1.108391\n",
            "Train Epoch: 29 [3840/9000 images (43%)]\tLoss: 1.068597\n",
            "Train Epoch: 29 [4480/9000 images (50%)]\tLoss: 1.024470\n",
            "Train Epoch: 29 [5120/9000 images (57%)]\tLoss: 1.174530\n",
            "Train Epoch: 29 [5760/9000 images (64%)]\tLoss: 1.464154\n",
            "Train Epoch: 29 [6400/9000 images (71%)]\tLoss: 1.206937\n",
            "Train Epoch: 29 [7040/9000 images (78%)]\tLoss: 1.020732\n",
            "Train Epoch: 29 [7680/9000 images (85%)]\tLoss: 1.196692\n",
            "Train Epoch: 29 [8320/9000 images (92%)]\tLoss: 1.380658\n",
            "Train Epoch: 29 [5600/9000 images (62%)]\tLoss: 1.197474\n",
            "\n",
            "Test set (epoch 29):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.10%\n",
            "    Macro F1-score: 0.3481\n",
            "    Per-pair accuracy (unordered pair): 94.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5411\n",
            "      circles: 0.6049\n",
            "      up     : 0.6601\n",
            "      right  : 0.6533\n",
            "      down   : 0.6180\n",
            "      left   : 0.7405\n",
            "    MAE per class:\n",
            "      squares: 0.2925\n",
            "      circles: 0.3725\n",
            "      up     : 0.3595\n",
            "      right  : 0.3953\n",
            "      down   : 0.3635\n",
            "      left   : 0.4207\n",
            "    RMSE overall: 0.6392\n",
            "    MAE overall: 0.3673\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2634, cnt=1.0206, total=1.7737\n",
            "\n",
            "Train Epoch: 30 [0/9000 images (0%)]\tLoss: 1.283059\n",
            "Train Epoch: 30 [640/9000 images (7%)]\tLoss: 0.946004\n",
            "Train Epoch: 30 [1280/9000 images (14%)]\tLoss: 1.011387\n",
            "Train Epoch: 30 [1920/9000 images (21%)]\tLoss: 1.070937\n",
            "Train Epoch: 30 [2560/9000 images (28%)]\tLoss: 0.857208\n",
            "Train Epoch: 30 [3200/9000 images (36%)]\tLoss: 1.137094\n",
            "Train Epoch: 30 [3840/9000 images (43%)]\tLoss: 1.217046\n",
            "Train Epoch: 30 [4480/9000 images (50%)]\tLoss: 0.990101\n",
            "Train Epoch: 30 [5120/9000 images (57%)]\tLoss: 1.233551\n",
            "Train Epoch: 30 [5760/9000 images (64%)]\tLoss: 1.080726\n",
            "Train Epoch: 30 [6400/9000 images (71%)]\tLoss: 1.108242\n",
            "Train Epoch: 30 [7040/9000 images (78%)]\tLoss: 1.222971\n",
            "Train Epoch: 30 [7680/9000 images (85%)]\tLoss: 0.976098\n",
            "Train Epoch: 30 [8320/9000 images (92%)]\tLoss: 1.187089\n",
            "Train Epoch: 30 [5600/9000 images (62%)]\tLoss: 1.029202\n",
            "\n",
            "Test set (epoch 30):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.80%\n",
            "    Macro F1-score: 0.3497\n",
            "    Per-pair accuracy (unordered pair): 94.60%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6858\n",
            "      circles: 0.5315\n",
            "      up     : 0.6348\n",
            "      right  : 0.6992\n",
            "      down   : 0.6221\n",
            "      left   : 0.7058\n",
            "    MAE per class:\n",
            "      squares: 0.3776\n",
            "      circles: 0.3110\n",
            "      up     : 0.3633\n",
            "      right  : 0.3842\n",
            "      down   : 0.3611\n",
            "      left   : 0.4099\n",
            "    RMSE overall: 0.6493\n",
            "    MAE overall: 0.3678\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2679, cnt=1.0497, total=1.7927\n",
            "\n",
            "Train Epoch: 31 [0/9000 images (0%)]\tLoss: 1.054862\n",
            "Train Epoch: 31 [640/9000 images (7%)]\tLoss: 1.136116\n",
            "Train Epoch: 31 [1280/9000 images (14%)]\tLoss: 1.082524\n",
            "Train Epoch: 31 [1920/9000 images (21%)]\tLoss: 1.201985\n",
            "Train Epoch: 31 [2560/9000 images (28%)]\tLoss: 1.012376\n",
            "Train Epoch: 31 [3200/9000 images (36%)]\tLoss: 1.034051\n",
            "Train Epoch: 31 [3840/9000 images (43%)]\tLoss: 1.094324\n",
            "Train Epoch: 31 [4480/9000 images (50%)]\tLoss: 1.017107\n",
            "Train Epoch: 31 [5120/9000 images (57%)]\tLoss: 1.081161\n",
            "Train Epoch: 31 [5760/9000 images (64%)]\tLoss: 1.007019\n",
            "Train Epoch: 31 [6400/9000 images (71%)]\tLoss: 1.071214\n",
            "Train Epoch: 31 [7040/9000 images (78%)]\tLoss: 1.344476\n",
            "Train Epoch: 31 [7680/9000 images (85%)]\tLoss: 1.271219\n",
            "Train Epoch: 31 [8320/9000 images (92%)]\tLoss: 1.039078\n",
            "Train Epoch: 31 [5600/9000 images (62%)]\tLoss: 0.861350\n",
            "\n",
            "Test set (epoch 31):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.50%\n",
            "    Macro F1-score: 0.3600\n",
            "    Per-pair accuracy (unordered pair): 94.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6010\n",
            "      circles: 0.6197\n",
            "      up     : 0.6236\n",
            "      right  : 0.6555\n",
            "      down   : 0.6492\n",
            "      left   : 0.7004\n",
            "    MAE per class:\n",
            "      squares: 0.3301\n",
            "      circles: 0.3307\n",
            "      up     : 0.3524\n",
            "      right  : 0.4006\n",
            "      down   : 0.3980\n",
            "      left   : 0.3919\n",
            "    RMSE overall: 0.6424\n",
            "    MAE overall: 0.3673\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2691, cnt=1.0350, total=1.7866\n",
            "\n",
            "Train Epoch: 32 [0/9000 images (0%)]\tLoss: 0.995448\n",
            "Train Epoch: 32 [640/9000 images (7%)]\tLoss: 0.983608\n",
            "Train Epoch: 32 [1280/9000 images (14%)]\tLoss: 1.103162\n",
            "Train Epoch: 32 [1920/9000 images (21%)]\tLoss: 0.898303\n",
            "Train Epoch: 32 [2560/9000 images (28%)]\tLoss: 1.326304\n",
            "Train Epoch: 32 [3200/9000 images (36%)]\tLoss: 1.137323\n",
            "Train Epoch: 32 [3840/9000 images (43%)]\tLoss: 1.258878\n",
            "Train Epoch: 32 [4480/9000 images (50%)]\tLoss: 1.031531\n",
            "Train Epoch: 32 [5120/9000 images (57%)]\tLoss: 0.949037\n",
            "Train Epoch: 32 [5760/9000 images (64%)]\tLoss: 1.176031\n",
            "Train Epoch: 32 [6400/9000 images (71%)]\tLoss: 1.110904\n",
            "Train Epoch: 32 [7040/9000 images (78%)]\tLoss: 1.141248\n",
            "Train Epoch: 32 [7680/9000 images (85%)]\tLoss: 1.117941\n",
            "Train Epoch: 32 [8320/9000 images (92%)]\tLoss: 1.100649\n",
            "Train Epoch: 32 [5600/9000 images (62%)]\tLoss: 0.813801\n",
            "\n",
            "Test set (epoch 32):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.60%\n",
            "    Macro F1-score: 0.3446\n",
            "    Per-pair accuracy (unordered pair): 94.30%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5582\n",
            "      circles: 0.5620\n",
            "      up     : 0.6611\n",
            "      right  : 0.6808\n",
            "      down   : 0.6340\n",
            "      left   : 0.7337\n",
            "    MAE per class:\n",
            "      squares: 0.3067\n",
            "      circles: 0.3116\n",
            "      up     : 0.3796\n",
            "      right  : 0.3765\n",
            "      down   : 0.3601\n",
            "      left   : 0.4449\n",
            "    RMSE overall: 0.6414\n",
            "    MAE overall: 0.3632\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3149, cnt=1.0234, total=1.8266\n",
            "\n",
            "Train Epoch: 33 [0/9000 images (0%)]\tLoss: 0.907250\n",
            "Train Epoch: 33 [640/9000 images (7%)]\tLoss: 1.150459\n",
            "Train Epoch: 33 [1280/9000 images (14%)]\tLoss: 1.236599\n",
            "Train Epoch: 33 [1920/9000 images (21%)]\tLoss: 1.016365\n",
            "Train Epoch: 33 [2560/9000 images (28%)]\tLoss: 0.919437\n",
            "Train Epoch: 33 [3200/9000 images (36%)]\tLoss: 1.127589\n",
            "Train Epoch: 33 [3840/9000 images (43%)]\tLoss: 1.039441\n",
            "Train Epoch: 33 [4480/9000 images (50%)]\tLoss: 0.991848\n",
            "Train Epoch: 33 [5120/9000 images (57%)]\tLoss: 0.980580\n",
            "Train Epoch: 33 [5760/9000 images (64%)]\tLoss: 1.032732\n",
            "Train Epoch: 33 [6400/9000 images (71%)]\tLoss: 1.017358\n",
            "Train Epoch: 33 [7040/9000 images (78%)]\tLoss: 1.082799\n",
            "Train Epoch: 33 [7680/9000 images (85%)]\tLoss: 0.982658\n",
            "Train Epoch: 33 [8320/9000 images (92%)]\tLoss: 0.756666\n",
            "Train Epoch: 33 [5600/9000 images (62%)]\tLoss: 0.697398\n",
            "\n",
            "Test set (epoch 33):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.00%\n",
            "    Macro F1-score: 0.3496\n",
            "    Per-pair accuracy (unordered pair): 93.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5355\n",
            "      circles: 0.5723\n",
            "      up     : 0.7083\n",
            "      right  : 0.6803\n",
            "      down   : 0.6881\n",
            "      left   : 0.6986\n",
            "    MAE per class:\n",
            "      squares: 0.3371\n",
            "      circles: 0.3352\n",
            "      up     : 0.4002\n",
            "      right  : 0.3802\n",
            "      down   : 0.3780\n",
            "      left   : 0.3958\n",
            "    RMSE overall: 0.6507\n",
            "    MAE overall: 0.3711\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3552, cnt=1.0508, total=1.8807\n",
            "\n",
            "Train Epoch: 34 [0/9000 images (0%)]\tLoss: 1.046691\n",
            "Train Epoch: 34 [640/9000 images (7%)]\tLoss: 1.005081\n",
            "Train Epoch: 34 [1280/9000 images (14%)]\tLoss: 0.877005\n",
            "Train Epoch: 34 [1920/9000 images (21%)]\tLoss: 0.920707\n",
            "Train Epoch: 34 [2560/9000 images (28%)]\tLoss: 0.942075\n",
            "Train Epoch: 34 [3200/9000 images (36%)]\tLoss: 1.015547\n",
            "Train Epoch: 34 [3840/9000 images (43%)]\tLoss: 0.972454\n",
            "Train Epoch: 34 [4480/9000 images (50%)]\tLoss: 1.266395\n",
            "Train Epoch: 34 [5120/9000 images (57%)]\tLoss: 1.237639\n",
            "Train Epoch: 34 [5760/9000 images (64%)]\tLoss: 0.859313\n",
            "Train Epoch: 34 [6400/9000 images (71%)]\tLoss: 0.843257\n",
            "Train Epoch: 34 [7040/9000 images (78%)]\tLoss: 0.765789\n",
            "Train Epoch: 34 [7680/9000 images (85%)]\tLoss: 1.205972\n",
            "Train Epoch: 34 [8320/9000 images (92%)]\tLoss: 1.068914\n",
            "Train Epoch: 34 [5600/9000 images (62%)]\tLoss: 0.783768\n",
            "\n",
            "Test set (epoch 34):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.50%\n",
            "    Macro F1-score: 0.3727\n",
            "    Per-pair accuracy (unordered pair): 93.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5213\n",
            "      circles: 0.5493\n",
            "      up     : 0.6446\n",
            "      right  : 0.6554\n",
            "      down   : 0.6229\n",
            "      left   : 0.7012\n",
            "    MAE per class:\n",
            "      squares: 0.2933\n",
            "      circles: 0.3225\n",
            "      up     : 0.3588\n",
            "      right  : 0.3897\n",
            "      down   : 0.3499\n",
            "      left   : 0.3889\n",
            "    RMSE overall: 0.6189\n",
            "    MAE overall: 0.3505\n",
            "\n",
            "  Losses:\n",
            "    cls=1.2710, cnt=0.9675, total=1.7548\n",
            "\n",
            "Train Epoch: 35 [0/9000 images (0%)]\tLoss: 0.989606\n",
            "Train Epoch: 35 [640/9000 images (7%)]\tLoss: 0.972028\n",
            "Train Epoch: 35 [1280/9000 images (14%)]\tLoss: 1.177395\n",
            "Train Epoch: 35 [1920/9000 images (21%)]\tLoss: 0.881361\n",
            "Train Epoch: 35 [2560/9000 images (28%)]\tLoss: 1.021599\n",
            "Train Epoch: 35 [3200/9000 images (36%)]\tLoss: 0.858046\n",
            "Train Epoch: 35 [3840/9000 images (43%)]\tLoss: 0.934133\n",
            "Train Epoch: 35 [4480/9000 images (50%)]\tLoss: 0.956671\n",
            "Train Epoch: 35 [5120/9000 images (57%)]\tLoss: 1.014423\n",
            "Train Epoch: 35 [5760/9000 images (64%)]\tLoss: 0.876240\n",
            "Train Epoch: 35 [6400/9000 images (71%)]\tLoss: 0.906269\n",
            "Train Epoch: 35 [7040/9000 images (78%)]\tLoss: 0.926582\n",
            "Train Epoch: 35 [7680/9000 images (85%)]\tLoss: 0.996215\n",
            "Train Epoch: 35 [8320/9000 images (92%)]\tLoss: 0.868126\n",
            "Train Epoch: 35 [5600/9000 images (62%)]\tLoss: 1.068170\n",
            "\n",
            "Test set (epoch 35):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.30%\n",
            "    Macro F1-score: 0.3532\n",
            "    Per-pair accuracy (unordered pair): 93.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5336\n",
            "      circles: 0.5523\n",
            "      up     : 0.7173\n",
            "      right  : 0.6520\n",
            "      down   : 0.6057\n",
            "      left   : 0.6986\n",
            "    MAE per class:\n",
            "      squares: 0.3012\n",
            "      circles: 0.3313\n",
            "      up     : 0.4081\n",
            "      right  : 0.3858\n",
            "      down   : 0.3441\n",
            "      left   : 0.3902\n",
            "    RMSE overall: 0.6304\n",
            "    MAE overall: 0.3601\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3354, cnt=0.9941, total=1.8324\n",
            "\n",
            "Train Epoch: 36 [0/9000 images (0%)]\tLoss: 0.995624\n",
            "Train Epoch: 36 [640/9000 images (7%)]\tLoss: 0.778893\n",
            "Train Epoch: 36 [1280/9000 images (14%)]\tLoss: 0.892250\n",
            "Train Epoch: 36 [1920/9000 images (21%)]\tLoss: 1.003570\n",
            "Train Epoch: 36 [2560/9000 images (28%)]\tLoss: 0.950921\n",
            "Train Epoch: 36 [3200/9000 images (36%)]\tLoss: 1.164807\n",
            "Train Epoch: 36 [3840/9000 images (43%)]\tLoss: 1.023452\n",
            "Train Epoch: 36 [4480/9000 images (50%)]\tLoss: 0.833902\n",
            "Train Epoch: 36 [5120/9000 images (57%)]\tLoss: 0.908338\n",
            "Train Epoch: 36 [5760/9000 images (64%)]\tLoss: 0.963275\n",
            "Train Epoch: 36 [6400/9000 images (71%)]\tLoss: 1.030919\n",
            "Train Epoch: 36 [7040/9000 images (78%)]\tLoss: 0.923294\n",
            "Train Epoch: 36 [7680/9000 images (85%)]\tLoss: 0.902960\n",
            "Train Epoch: 36 [8320/9000 images (92%)]\tLoss: 0.997170\n",
            "Train Epoch: 36 [5600/9000 images (62%)]\tLoss: 1.211639\n",
            "\n",
            "Test set (epoch 36):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.10%\n",
            "    Macro F1-score: 0.3502\n",
            "    Per-pair accuracy (unordered pair): 93.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6326\n",
            "      circles: 0.5513\n",
            "      up     : 0.6903\n",
            "      right  : 0.6504\n",
            "      down   : 0.6254\n",
            "      left   : 0.7003\n",
            "    MAE per class:\n",
            "      squares: 0.3319\n",
            "      circles: 0.3163\n",
            "      up     : 0.3859\n",
            "      right  : 0.4054\n",
            "      down   : 0.3809\n",
            "      left   : 0.4083\n",
            "    RMSE overall: 0.6436\n",
            "    MAE overall: 0.3715\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3529, cnt=1.0351, total=1.8704\n",
            "\n",
            "Train Epoch: 37 [0/9000 images (0%)]\tLoss: 1.045727\n",
            "Train Epoch: 37 [640/9000 images (7%)]\tLoss: 1.067518\n",
            "Train Epoch: 37 [1280/9000 images (14%)]\tLoss: 0.814717\n",
            "Train Epoch: 37 [1920/9000 images (21%)]\tLoss: 1.347858\n",
            "Train Epoch: 37 [2560/9000 images (28%)]\tLoss: 0.757064\n",
            "Train Epoch: 37 [3200/9000 images (36%)]\tLoss: 1.015476\n",
            "Train Epoch: 37 [3840/9000 images (43%)]\tLoss: 0.978140\n",
            "Train Epoch: 37 [4480/9000 images (50%)]\tLoss: 0.858651\n",
            "Train Epoch: 37 [5120/9000 images (57%)]\tLoss: 0.984815\n",
            "Train Epoch: 37 [5760/9000 images (64%)]\tLoss: 0.973725\n",
            "Train Epoch: 37 [6400/9000 images (71%)]\tLoss: 0.822341\n",
            "Train Epoch: 37 [7040/9000 images (78%)]\tLoss: 0.882956\n",
            "Train Epoch: 37 [7680/9000 images (85%)]\tLoss: 0.870944\n",
            "Train Epoch: 37 [8320/9000 images (92%)]\tLoss: 0.711568\n",
            "Train Epoch: 37 [5600/9000 images (62%)]\tLoss: 0.950462\n",
            "\n",
            "Test set (epoch 37):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.20%\n",
            "    Macro F1-score: 0.3657\n",
            "    Per-pair accuracy (unordered pair): 94.10%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5423\n",
            "      circles: 0.6223\n",
            "      up     : 0.6462\n",
            "      right  : 0.6448\n",
            "      down   : 0.6129\n",
            "      left   : 0.8197\n",
            "    MAE per class:\n",
            "      squares: 0.3306\n",
            "      circles: 0.3419\n",
            "      up     : 0.3642\n",
            "      right  : 0.3897\n",
            "      down   : 0.3605\n",
            "      left   : 0.4531\n",
            "    RMSE overall: 0.6535\n",
            "    MAE overall: 0.3733\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3404, cnt=1.0520, total=1.8665\n",
            "\n",
            "Train Epoch: 38 [0/9000 images (0%)]\tLoss: 0.869290\n",
            "Train Epoch: 38 [640/9000 images (7%)]\tLoss: 0.755517\n",
            "Train Epoch: 38 [1280/9000 images (14%)]\tLoss: 0.858220\n",
            "Train Epoch: 38 [1920/9000 images (21%)]\tLoss: 0.933407\n",
            "Train Epoch: 38 [2560/9000 images (28%)]\tLoss: 0.967719\n",
            "Train Epoch: 38 [3200/9000 images (36%)]\tLoss: 0.884542\n",
            "Train Epoch: 38 [3840/9000 images (43%)]\tLoss: 0.887094\n",
            "Train Epoch: 38 [4480/9000 images (50%)]\tLoss: 0.754114\n",
            "Train Epoch: 38 [5120/9000 images (57%)]\tLoss: 0.837697\n",
            "Train Epoch: 38 [5760/9000 images (64%)]\tLoss: 0.798719\n",
            "Train Epoch: 38 [6400/9000 images (71%)]\tLoss: 0.817127\n",
            "Train Epoch: 38 [7040/9000 images (78%)]\tLoss: 0.923133\n",
            "Train Epoch: 38 [7680/9000 images (85%)]\tLoss: 0.842459\n",
            "Train Epoch: 38 [8320/9000 images (92%)]\tLoss: 1.174723\n",
            "Train Epoch: 38 [5600/9000 images (62%)]\tLoss: 0.929177\n",
            "\n",
            "Test set (epoch 38):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 52.20%\n",
            "    Macro F1-score: 0.3922\n",
            "    Per-pair accuracy (unordered pair): 93.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5254\n",
            "      circles: 0.5401\n",
            "      up     : 0.6424\n",
            "      right  : 0.6268\n",
            "      down   : 0.6914\n",
            "      left   : 0.7043\n",
            "    MAE per class:\n",
            "      squares: 0.3225\n",
            "      circles: 0.3271\n",
            "      up     : 0.3838\n",
            "      right  : 0.3623\n",
            "      down   : 0.3780\n",
            "      left   : 0.3927\n",
            "    RMSE overall: 0.6255\n",
            "    MAE overall: 0.3611\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3082, cnt=0.9786, total=1.7975\n",
            "\n",
            "Train Epoch: 39 [0/9000 images (0%)]\tLoss: 0.714642\n",
            "Train Epoch: 39 [640/9000 images (7%)]\tLoss: 0.780832\n",
            "Train Epoch: 39 [1280/9000 images (14%)]\tLoss: 0.678743\n",
            "Train Epoch: 39 [1920/9000 images (21%)]\tLoss: 0.901423\n",
            "Train Epoch: 39 [2560/9000 images (28%)]\tLoss: 1.033082\n",
            "Train Epoch: 39 [3200/9000 images (36%)]\tLoss: 1.303037\n",
            "Train Epoch: 39 [3840/9000 images (43%)]\tLoss: 0.853262\n",
            "Train Epoch: 39 [4480/9000 images (50%)]\tLoss: 0.910717\n",
            "Train Epoch: 39 [5120/9000 images (57%)]\tLoss: 1.104238\n",
            "Train Epoch: 39 [5760/9000 images (64%)]\tLoss: 0.691459\n",
            "Train Epoch: 39 [6400/9000 images (71%)]\tLoss: 0.724511\n",
            "Train Epoch: 39 [7040/9000 images (78%)]\tLoss: 0.859070\n",
            "Train Epoch: 39 [7680/9000 images (85%)]\tLoss: 0.932310\n",
            "Train Epoch: 39 [8320/9000 images (92%)]\tLoss: 0.827943\n",
            "Train Epoch: 39 [5600/9000 images (62%)]\tLoss: 1.244465\n",
            "\n",
            "Test set (epoch 39):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.20%\n",
            "    Macro F1-score: 0.3547\n",
            "    Per-pair accuracy (unordered pair): 93.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5527\n",
            "      circles: 0.5276\n",
            "      up     : 0.7688\n",
            "      right  : 0.6514\n",
            "      down   : 0.6161\n",
            "      left   : 0.8146\n",
            "    MAE per class:\n",
            "      squares: 0.3496\n",
            "      circles: 0.3052\n",
            "      up     : 0.4385\n",
            "      right  : 0.3772\n",
            "      down   : 0.3792\n",
            "      left   : 0.4455\n",
            "    RMSE overall: 0.6636\n",
            "    MAE overall: 0.3825\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4162, cnt=1.0814, total=1.9568\n",
            "\n",
            "Train Epoch: 40 [0/9000 images (0%)]\tLoss: 0.821800\n",
            "Train Epoch: 40 [640/9000 images (7%)]\tLoss: 1.072801\n",
            "Train Epoch: 40 [1280/9000 images (14%)]\tLoss: 0.977404\n",
            "Train Epoch: 40 [1920/9000 images (21%)]\tLoss: 0.570959\n",
            "Train Epoch: 40 [2560/9000 images (28%)]\tLoss: 0.683922\n",
            "Train Epoch: 40 [3200/9000 images (36%)]\tLoss: 0.674571\n",
            "Train Epoch: 40 [3840/9000 images (43%)]\tLoss: 0.862749\n",
            "Train Epoch: 40 [4480/9000 images (50%)]\tLoss: 0.751037\n",
            "Train Epoch: 40 [5120/9000 images (57%)]\tLoss: 0.742710\n",
            "Train Epoch: 40 [5760/9000 images (64%)]\tLoss: 0.915089\n",
            "Train Epoch: 40 [6400/9000 images (71%)]\tLoss: 0.927302\n",
            "Train Epoch: 40 [7040/9000 images (78%)]\tLoss: 0.801097\n",
            "Train Epoch: 40 [7680/9000 images (85%)]\tLoss: 0.572803\n",
            "Train Epoch: 40 [8320/9000 images (92%)]\tLoss: 0.836769\n",
            "Train Epoch: 40 [5600/9000 images (62%)]\tLoss: 0.791033\n",
            "\n",
            "Test set (epoch 40):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 50.70%\n",
            "    Macro F1-score: 0.3810\n",
            "    Per-pair accuracy (unordered pair): 94.30%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5343\n",
            "      circles: 0.5160\n",
            "      up     : 0.6516\n",
            "      right  : 0.6317\n",
            "      down   : 0.6181\n",
            "      left   : 0.6763\n",
            "    MAE per class:\n",
            "      squares: 0.3011\n",
            "      circles: 0.3018\n",
            "      up     : 0.3815\n",
            "      right  : 0.3547\n",
            "      down   : 0.3565\n",
            "      left   : 0.3715\n",
            "    RMSE overall: 0.6076\n",
            "    MAE overall: 0.3445\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3096, cnt=0.9331, total=1.7762\n",
            "\n",
            "Train Epoch: 41 [0/9000 images (0%)]\tLoss: 0.762848\n",
            "Train Epoch: 41 [640/9000 images (7%)]\tLoss: 0.881713\n",
            "Train Epoch: 41 [1280/9000 images (14%)]\tLoss: 0.771147\n",
            "Train Epoch: 41 [1920/9000 images (21%)]\tLoss: 0.656185\n",
            "Train Epoch: 41 [2560/9000 images (28%)]\tLoss: 0.909909\n",
            "Train Epoch: 41 [3200/9000 images (36%)]\tLoss: 0.864543\n",
            "Train Epoch: 41 [3840/9000 images (43%)]\tLoss: 0.937304\n",
            "Train Epoch: 41 [4480/9000 images (50%)]\tLoss: 0.927385\n",
            "Train Epoch: 41 [5120/9000 images (57%)]\tLoss: 0.668743\n",
            "Train Epoch: 41 [5760/9000 images (64%)]\tLoss: 0.757456\n",
            "Train Epoch: 41 [6400/9000 images (71%)]\tLoss: 0.963763\n",
            "Train Epoch: 41 [7040/9000 images (78%)]\tLoss: 0.794325\n",
            "Train Epoch: 41 [7680/9000 images (85%)]\tLoss: 0.770945\n",
            "Train Epoch: 41 [8320/9000 images (92%)]\tLoss: 0.716617\n",
            "Train Epoch: 41 [5600/9000 images (62%)]\tLoss: 0.965550\n",
            "\n",
            "Test set (epoch 41):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.80%\n",
            "    Macro F1-score: 0.3499\n",
            "    Per-pair accuracy (unordered pair): 93.80%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5206\n",
            "      circles: 0.5349\n",
            "      up     : 0.6313\n",
            "      right  : 0.6745\n",
            "      down   : 0.6414\n",
            "      left   : 0.7299\n",
            "    MAE per class:\n",
            "      squares: 0.3040\n",
            "      circles: 0.3226\n",
            "      up     : 0.3831\n",
            "      right  : 0.3677\n",
            "      down   : 0.3581\n",
            "      left   : 0.3988\n",
            "    RMSE overall: 0.6265\n",
            "    MAE overall: 0.3557\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3954, cnt=0.9737, total=1.8822\n",
            "\n",
            "Train Epoch: 42 [0/9000 images (0%)]\tLoss: 0.697950\n",
            "Train Epoch: 42 [640/9000 images (7%)]\tLoss: 0.770477\n",
            "Train Epoch: 42 [1280/9000 images (14%)]\tLoss: 0.729564\n",
            "Train Epoch: 42 [1920/9000 images (21%)]\tLoss: 1.058262\n",
            "Train Epoch: 42 [2560/9000 images (28%)]\tLoss: 0.668514\n",
            "Train Epoch: 42 [3200/9000 images (36%)]\tLoss: 0.650154\n",
            "Train Epoch: 42 [3840/9000 images (43%)]\tLoss: 0.701818\n",
            "Train Epoch: 42 [4480/9000 images (50%)]\tLoss: 0.703359\n",
            "Train Epoch: 42 [5120/9000 images (57%)]\tLoss: 0.790411\n",
            "Train Epoch: 42 [5760/9000 images (64%)]\tLoss: 0.765971\n",
            "Train Epoch: 42 [6400/9000 images (71%)]\tLoss: 0.770101\n",
            "Train Epoch: 42 [7040/9000 images (78%)]\tLoss: 0.834321\n",
            "Train Epoch: 42 [7680/9000 images (85%)]\tLoss: 0.858530\n",
            "Train Epoch: 42 [8320/9000 images (92%)]\tLoss: 0.813170\n",
            "Train Epoch: 42 [5600/9000 images (62%)]\tLoss: 0.755445\n",
            "\n",
            "Test set (epoch 42):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.40%\n",
            "    Macro F1-score: 0.3564\n",
            "    Per-pair accuracy (unordered pair): 94.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5465\n",
            "      circles: 0.5606\n",
            "      up     : 0.6929\n",
            "      right  : 0.6309\n",
            "      down   : 0.6265\n",
            "      left   : 0.7316\n",
            "    MAE per class:\n",
            "      squares: 0.3063\n",
            "      circles: 0.3075\n",
            "      up     : 0.4211\n",
            "      right  : 0.3405\n",
            "      down   : 0.3798\n",
            "      left   : 0.3921\n",
            "    RMSE overall: 0.6349\n",
            "    MAE overall: 0.3579\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4137, cnt=1.0005, total=1.9139\n",
            "\n",
            "Train Epoch: 43 [0/9000 images (0%)]\tLoss: 0.984711\n",
            "Train Epoch: 43 [640/9000 images (7%)]\tLoss: 0.939571\n",
            "Train Epoch: 43 [1280/9000 images (14%)]\tLoss: 0.739179\n",
            "Train Epoch: 43 [1920/9000 images (21%)]\tLoss: 0.752647\n",
            "Train Epoch: 43 [2560/9000 images (28%)]\tLoss: 0.644793\n",
            "Train Epoch: 43 [3200/9000 images (36%)]\tLoss: 0.802475\n",
            "Train Epoch: 43 [3840/9000 images (43%)]\tLoss: 0.689999\n",
            "Train Epoch: 43 [4480/9000 images (50%)]\tLoss: 0.880439\n",
            "Train Epoch: 43 [5120/9000 images (57%)]\tLoss: 0.712355\n",
            "Train Epoch: 43 [5760/9000 images (64%)]\tLoss: 0.768331\n",
            "Train Epoch: 43 [6400/9000 images (71%)]\tLoss: 0.985584\n",
            "Train Epoch: 43 [7040/9000 images (78%)]\tLoss: 0.904986\n",
            "Train Epoch: 43 [7680/9000 images (85%)]\tLoss: 0.645571\n",
            "Train Epoch: 43 [8320/9000 images (92%)]\tLoss: 1.035895\n",
            "Train Epoch: 43 [5600/9000 images (62%)]\tLoss: 0.895180\n",
            "\n",
            "Test set (epoch 43):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.50%\n",
            "    Macro F1-score: 0.3652\n",
            "    Per-pair accuracy (unordered pair): 94.60%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5158\n",
            "      circles: 0.5243\n",
            "      up     : 0.6236\n",
            "      right  : 0.6463\n",
            "      down   : 0.6371\n",
            "      left   : 0.7769\n",
            "    MAE per class:\n",
            "      squares: 0.2992\n",
            "      circles: 0.2930\n",
            "      up     : 0.3621\n",
            "      right  : 0.3761\n",
            "      down   : 0.3979\n",
            "      left   : 0.4314\n",
            "    RMSE overall: 0.6268\n",
            "    MAE overall: 0.3600\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4081, cnt=0.9801, total=1.8981\n",
            "\n",
            "Train Epoch: 44 [0/9000 images (0%)]\tLoss: 0.796426\n",
            "Train Epoch: 44 [640/9000 images (7%)]\tLoss: 0.785344\n",
            "Train Epoch: 44 [1280/9000 images (14%)]\tLoss: 0.898900\n",
            "Train Epoch: 44 [1920/9000 images (21%)]\tLoss: 0.770697\n",
            "Train Epoch: 44 [2560/9000 images (28%)]\tLoss: 0.603521\n",
            "Train Epoch: 44 [3200/9000 images (36%)]\tLoss: 0.915108\n",
            "Train Epoch: 44 [3840/9000 images (43%)]\tLoss: 0.583174\n",
            "Train Epoch: 44 [4480/9000 images (50%)]\tLoss: 0.583506\n",
            "Train Epoch: 44 [5120/9000 images (57%)]\tLoss: 0.874594\n",
            "Train Epoch: 44 [5760/9000 images (64%)]\tLoss: 0.889161\n",
            "Train Epoch: 44 [6400/9000 images (71%)]\tLoss: 0.863752\n",
            "Train Epoch: 44 [7040/9000 images (78%)]\tLoss: 0.968323\n",
            "Train Epoch: 44 [7680/9000 images (85%)]\tLoss: 0.572755\n",
            "Train Epoch: 44 [8320/9000 images (92%)]\tLoss: 0.807254\n",
            "Train Epoch: 44 [5600/9000 images (62%)]\tLoss: 0.669574\n",
            "\n",
            "Test set (epoch 44):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.70%\n",
            "    Macro F1-score: 0.3496\n",
            "    Per-pair accuracy (unordered pair): 93.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5065\n",
            "      circles: 0.5412\n",
            "      up     : 0.6370\n",
            "      right  : 0.6206\n",
            "      down   : 0.6126\n",
            "      left   : 0.7113\n",
            "    MAE per class:\n",
            "      squares: 0.2865\n",
            "      circles: 0.3096\n",
            "      up     : 0.3698\n",
            "      right  : 0.3576\n",
            "      down   : 0.3605\n",
            "      left   : 0.3812\n",
            "    RMSE overall: 0.6085\n",
            "    MAE overall: 0.3442\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4023, cnt=0.9282, total=1.8664\n",
            "\n",
            "Train Epoch: 45 [0/9000 images (0%)]\tLoss: 0.603088\n",
            "Train Epoch: 45 [640/9000 images (7%)]\tLoss: 0.591997\n",
            "Train Epoch: 45 [1280/9000 images (14%)]\tLoss: 0.874901\n",
            "Train Epoch: 45 [1920/9000 images (21%)]\tLoss: 0.597298\n",
            "Train Epoch: 45 [2560/9000 images (28%)]\tLoss: 0.733142\n",
            "Train Epoch: 45 [3200/9000 images (36%)]\tLoss: 0.673482\n",
            "Train Epoch: 45 [3840/9000 images (43%)]\tLoss: 0.786710\n",
            "Train Epoch: 45 [4480/9000 images (50%)]\tLoss: 0.549353\n",
            "Train Epoch: 45 [5120/9000 images (57%)]\tLoss: 0.811326\n",
            "Train Epoch: 45 [5760/9000 images (64%)]\tLoss: 0.757572\n",
            "Train Epoch: 45 [6400/9000 images (71%)]\tLoss: 0.623180\n",
            "Train Epoch: 45 [7040/9000 images (78%)]\tLoss: 0.954078\n",
            "Train Epoch: 45 [7680/9000 images (85%)]\tLoss: 0.744782\n",
            "Train Epoch: 45 [8320/9000 images (92%)]\tLoss: 1.068180\n",
            "Train Epoch: 45 [5600/9000 images (62%)]\tLoss: 0.710678\n",
            "\n",
            "Test set (epoch 45):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.70%\n",
            "    Macro F1-score: 0.3443\n",
            "    Per-pair accuracy (unordered pair): 94.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5095\n",
            "      circles: 0.6089\n",
            "      up     : 0.6487\n",
            "      right  : 0.6249\n",
            "      down   : 0.6156\n",
            "      left   : 0.7070\n",
            "    MAE per class:\n",
            "      squares: 0.2950\n",
            "      circles: 0.3466\n",
            "      up     : 0.3748\n",
            "      right  : 0.3564\n",
            "      down   : 0.3839\n",
            "      left   : 0.3926\n",
            "    RMSE overall: 0.6219\n",
            "    MAE overall: 0.3582\n",
            "\n",
            "  Losses:\n",
            "    cls=1.3807, cnt=0.9751, total=1.8682\n",
            "\n",
            "Train Epoch: 46 [0/9000 images (0%)]\tLoss: 0.703293\n",
            "Train Epoch: 46 [640/9000 images (7%)]\tLoss: 0.801559\n",
            "Train Epoch: 46 [1280/9000 images (14%)]\tLoss: 0.805847\n",
            "Train Epoch: 46 [1920/9000 images (21%)]\tLoss: 0.929003\n",
            "Train Epoch: 46 [2560/9000 images (28%)]\tLoss: 0.682559\n",
            "Train Epoch: 46 [3200/9000 images (36%)]\tLoss: 0.726258\n",
            "Train Epoch: 46 [3840/9000 images (43%)]\tLoss: 0.677609\n",
            "Train Epoch: 46 [4480/9000 images (50%)]\tLoss: 0.835360\n",
            "Train Epoch: 46 [5120/9000 images (57%)]\tLoss: 0.793804\n",
            "Train Epoch: 46 [5760/9000 images (64%)]\tLoss: 0.906191\n",
            "Train Epoch: 46 [6400/9000 images (71%)]\tLoss: 0.815069\n",
            "Train Epoch: 46 [7040/9000 images (78%)]\tLoss: 0.756756\n",
            "Train Epoch: 46 [7680/9000 images (85%)]\tLoss: 0.716575\n",
            "Train Epoch: 46 [8320/9000 images (92%)]\tLoss: 0.767650\n",
            "Train Epoch: 46 [5600/9000 images (62%)]\tLoss: 0.716850\n",
            "\n",
            "Test set (epoch 46):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.90%\n",
            "    Macro F1-score: 0.3646\n",
            "    Per-pair accuracy (unordered pair): 95.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5052\n",
            "      circles: 0.5295\n",
            "      up     : 0.6440\n",
            "      right  : 0.6240\n",
            "      down   : 0.7324\n",
            "      left   : 0.6979\n",
            "    MAE per class:\n",
            "      squares: 0.2924\n",
            "      circles: 0.3267\n",
            "      up     : 0.3797\n",
            "      right  : 0.3654\n",
            "      down   : 0.3945\n",
            "      left   : 0.3708\n",
            "    RMSE overall: 0.6276\n",
            "    MAE overall: 0.3549\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4572, cnt=0.9774, total=1.9458\n",
            "\n",
            "Train Epoch: 47 [0/9000 images (0%)]\tLoss: 0.636399\n",
            "Train Epoch: 47 [640/9000 images (7%)]\tLoss: 0.712494\n",
            "Train Epoch: 47 [1280/9000 images (14%)]\tLoss: 0.823360\n",
            "Train Epoch: 47 [1920/9000 images (21%)]\tLoss: 0.428200\n",
            "Train Epoch: 47 [2560/9000 images (28%)]\tLoss: 0.655701\n",
            "Train Epoch: 47 [3200/9000 images (36%)]\tLoss: 0.832230\n",
            "Train Epoch: 47 [3840/9000 images (43%)]\tLoss: 0.715052\n",
            "Train Epoch: 47 [4480/9000 images (50%)]\tLoss: 0.788976\n",
            "Train Epoch: 47 [5120/9000 images (57%)]\tLoss: 0.679691\n",
            "Train Epoch: 47 [5760/9000 images (64%)]\tLoss: 0.750038\n",
            "Train Epoch: 47 [6400/9000 images (71%)]\tLoss: 0.837463\n",
            "Train Epoch: 47 [7040/9000 images (78%)]\tLoss: 0.621926\n",
            "Train Epoch: 47 [7680/9000 images (85%)]\tLoss: 0.659245\n",
            "Train Epoch: 47 [8320/9000 images (92%)]\tLoss: 0.811713\n",
            "Train Epoch: 47 [5600/9000 images (62%)]\tLoss: 0.776139\n",
            "\n",
            "Test set (epoch 47):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 45.40%\n",
            "    Macro F1-score: 0.3431\n",
            "    Per-pair accuracy (unordered pair): 94.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5090\n",
            "      circles: 0.5086\n",
            "      up     : 0.6571\n",
            "      right  : 0.6194\n",
            "      down   : 0.6399\n",
            "      left   : 0.7841\n",
            "    MAE per class:\n",
            "      squares: 0.3087\n",
            "      circles: 0.2942\n",
            "      up     : 0.3618\n",
            "      right  : 0.3458\n",
            "      down   : 0.3907\n",
            "      left   : 0.4240\n",
            "    RMSE overall: 0.6268\n",
            "    MAE overall: 0.3542\n",
            "\n",
            "  Losses:\n",
            "    cls=1.5909, cnt=0.9775, total=2.0796\n",
            "\n",
            "Train Epoch: 48 [0/9000 images (0%)]\tLoss: 0.903961\n",
            "Train Epoch: 48 [640/9000 images (7%)]\tLoss: 0.722209\n",
            "Train Epoch: 48 [1280/9000 images (14%)]\tLoss: 0.771237\n",
            "Train Epoch: 48 [1920/9000 images (21%)]\tLoss: 0.691678\n",
            "Train Epoch: 48 [2560/9000 images (28%)]\tLoss: 0.754863\n",
            "Train Epoch: 48 [3200/9000 images (36%)]\tLoss: 0.697294\n",
            "Train Epoch: 48 [3840/9000 images (43%)]\tLoss: 0.677546\n",
            "Train Epoch: 48 [4480/9000 images (50%)]\tLoss: 0.792350\n",
            "Train Epoch: 48 [5120/9000 images (57%)]\tLoss: 0.631137\n",
            "Train Epoch: 48 [5760/9000 images (64%)]\tLoss: 0.665145\n",
            "Train Epoch: 48 [6400/9000 images (71%)]\tLoss: 0.763797\n",
            "Train Epoch: 48 [7040/9000 images (78%)]\tLoss: 0.659705\n",
            "Train Epoch: 48 [7680/9000 images (85%)]\tLoss: 0.620082\n",
            "Train Epoch: 48 [8320/9000 images (92%)]\tLoss: 0.812821\n",
            "Train Epoch: 48 [5600/9000 images (62%)]\tLoss: 0.818481\n",
            "\n",
            "Test set (epoch 48):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.90%\n",
            "    Macro F1-score: 0.3678\n",
            "    Per-pair accuracy (unordered pair): 94.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5234\n",
            "      circles: 0.5099\n",
            "      up     : 0.6357\n",
            "      right  : 0.6683\n",
            "      down   : 0.6605\n",
            "      left   : 0.7046\n",
            "    MAE per class:\n",
            "      squares: 0.2858\n",
            "      circles: 0.3050\n",
            "      up     : 0.3866\n",
            "      right  : 0.3786\n",
            "      down   : 0.3647\n",
            "      left   : 0.3794\n",
            "    RMSE overall: 0.6215\n",
            "    MAE overall: 0.3500\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4580, cnt=0.9608, total=1.9384\n",
            "\n",
            "Train Epoch: 49 [0/9000 images (0%)]\tLoss: 0.752228\n",
            "Train Epoch: 49 [640/9000 images (7%)]\tLoss: 0.570069\n",
            "Train Epoch: 49 [1280/9000 images (14%)]\tLoss: 1.087220\n",
            "Train Epoch: 49 [1920/9000 images (21%)]\tLoss: 0.549661\n",
            "Train Epoch: 49 [2560/9000 images (28%)]\tLoss: 0.609509\n",
            "Train Epoch: 49 [3200/9000 images (36%)]\tLoss: 0.732953\n",
            "Train Epoch: 49 [3840/9000 images (43%)]\tLoss: 0.774245\n",
            "Train Epoch: 49 [4480/9000 images (50%)]\tLoss: 0.660594\n",
            "Train Epoch: 49 [5120/9000 images (57%)]\tLoss: 0.666698\n",
            "Train Epoch: 49 [5760/9000 images (64%)]\tLoss: 0.549409\n",
            "Train Epoch: 49 [6400/9000 images (71%)]\tLoss: 0.591851\n",
            "Train Epoch: 49 [7040/9000 images (78%)]\tLoss: 0.613536\n",
            "Train Epoch: 49 [7680/9000 images (85%)]\tLoss: 0.701364\n",
            "Train Epoch: 49 [8320/9000 images (92%)]\tLoss: 0.829185\n",
            "Train Epoch: 49 [5600/9000 images (62%)]\tLoss: 0.688845\n",
            "\n",
            "Test set (epoch 49):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.60%\n",
            "    Macro F1-score: 0.3637\n",
            "    Per-pair accuracy (unordered pair): 93.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4885\n",
            "      circles: 0.5155\n",
            "      up     : 0.6986\n",
            "      right  : 0.6603\n",
            "      down   : 0.6131\n",
            "      left   : 0.7506\n",
            "    MAE per class:\n",
            "      squares: 0.2851\n",
            "      circles: 0.2827\n",
            "      up     : 0.4412\n",
            "      right  : 0.3667\n",
            "      down   : 0.3562\n",
            "      left   : 0.4031\n",
            "    RMSE overall: 0.6282\n",
            "    MAE overall: 0.3558\n",
            "\n",
            "  Losses:\n",
            "    cls=1.5733, cnt=0.9757, total=2.0611\n",
            "\n",
            "Train Epoch: 50 [0/9000 images (0%)]\tLoss: 0.600008\n",
            "Train Epoch: 50 [640/9000 images (7%)]\tLoss: 0.518308\n",
            "Train Epoch: 50 [1280/9000 images (14%)]\tLoss: 0.767548\n",
            "Train Epoch: 50 [1920/9000 images (21%)]\tLoss: 0.819246\n",
            "Train Epoch: 50 [2560/9000 images (28%)]\tLoss: 0.700320\n",
            "Train Epoch: 50 [3200/9000 images (36%)]\tLoss: 0.627562\n",
            "Train Epoch: 50 [3840/9000 images (43%)]\tLoss: 0.602190\n",
            "Train Epoch: 50 [4480/9000 images (50%)]\tLoss: 0.643433\n",
            "Train Epoch: 50 [5120/9000 images (57%)]\tLoss: 0.492050\n",
            "Train Epoch: 50 [5760/9000 images (64%)]\tLoss: 0.847863\n",
            "Train Epoch: 50 [6400/9000 images (71%)]\tLoss: 0.737712\n",
            "Train Epoch: 50 [7040/9000 images (78%)]\tLoss: 0.703603\n",
            "Train Epoch: 50 [7680/9000 images (85%)]\tLoss: 0.706022\n",
            "Train Epoch: 50 [8320/9000 images (92%)]\tLoss: 0.395375\n",
            "Train Epoch: 50 [5600/9000 images (62%)]\tLoss: 0.502098\n",
            "\n",
            "Test set (epoch 50):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.50%\n",
            "    Macro F1-score: 0.3641\n",
            "    Per-pair accuracy (unordered pair): 95.30%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4999\n",
            "      circles: 0.6098\n",
            "      up     : 0.6195\n",
            "      right  : 0.6285\n",
            "      down   : 0.6100\n",
            "      left   : 0.6673\n",
            "    MAE per class:\n",
            "      squares: 0.2839\n",
            "      circles: 0.3370\n",
            "      up     : 0.3601\n",
            "      right  : 0.3785\n",
            "      down   : 0.3562\n",
            "      left   : 0.3726\n",
            "    RMSE overall: 0.6080\n",
            "    MAE overall: 0.3480\n",
            "\n",
            "  Losses:\n",
            "    cls=1.4809, cnt=0.9338, total=1.9478\n",
            "\n",
            "Train Epoch: 51 [0/9000 images (0%)]\tLoss: 0.671542\n",
            "Train Epoch: 51 [640/9000 images (7%)]\tLoss: 0.562230\n",
            "Train Epoch: 51 [1280/9000 images (14%)]\tLoss: 0.476759\n",
            "Train Epoch: 51 [1920/9000 images (21%)]\tLoss: 0.498874\n",
            "Train Epoch: 51 [2560/9000 images (28%)]\tLoss: 0.707906\n",
            "Train Epoch: 51 [3200/9000 images (36%)]\tLoss: 0.625252\n",
            "Train Epoch: 51 [3840/9000 images (43%)]\tLoss: 0.648326\n",
            "Train Epoch: 51 [4480/9000 images (50%)]\tLoss: 0.509723\n",
            "Train Epoch: 51 [5120/9000 images (57%)]\tLoss: 0.584227\n",
            "Train Epoch: 51 [5760/9000 images (64%)]\tLoss: 0.552782\n",
            "Train Epoch: 51 [6400/9000 images (71%)]\tLoss: 0.543577\n",
            "Train Epoch: 51 [7040/9000 images (78%)]\tLoss: 1.075505\n",
            "Train Epoch: 51 [7680/9000 images (85%)]\tLoss: 0.651875\n",
            "Train Epoch: 51 [8320/9000 images (92%)]\tLoss: 0.801348\n",
            "Train Epoch: 51 [5600/9000 images (62%)]\tLoss: 0.817201\n",
            "\n",
            "Test set (epoch 51):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.00%\n",
            "    Macro F1-score: 0.3682\n",
            "    Per-pair accuracy (unordered pair): 95.10%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5286\n",
            "      circles: 0.5060\n",
            "      up     : 0.6355\n",
            "      right  : 0.6254\n",
            "      down   : 0.6404\n",
            "      left   : 0.6735\n",
            "    MAE per class:\n",
            "      squares: 0.3142\n",
            "      circles: 0.3215\n",
            "      up     : 0.3729\n",
            "      right  : 0.3559\n",
            "      down   : 0.3669\n",
            "      left   : 0.3685\n",
            "    RMSE overall: 0.6047\n",
            "    MAE overall: 0.3500\n",
            "\n",
            "  Losses:\n",
            "    cls=1.5179, cnt=0.9286, total=1.9822\n",
            "\n",
            "Train Epoch: 52 [0/9000 images (0%)]\tLoss: 0.489154\n",
            "Train Epoch: 52 [640/9000 images (7%)]\tLoss: 0.620131\n",
            "Train Epoch: 52 [1280/9000 images (14%)]\tLoss: 0.918440\n",
            "Train Epoch: 52 [1920/9000 images (21%)]\tLoss: 0.583434\n",
            "Train Epoch: 52 [2560/9000 images (28%)]\tLoss: 0.702228\n",
            "Train Epoch: 52 [3200/9000 images (36%)]\tLoss: 0.752025\n",
            "Train Epoch: 52 [3840/9000 images (43%)]\tLoss: 0.587208\n",
            "Train Epoch: 52 [4480/9000 images (50%)]\tLoss: 0.450533\n",
            "Train Epoch: 52 [5120/9000 images (57%)]\tLoss: 0.687656\n",
            "Train Epoch: 52 [5760/9000 images (64%)]\tLoss: 0.657661\n",
            "Train Epoch: 52 [6400/9000 images (71%)]\tLoss: 0.636379\n",
            "Train Epoch: 52 [7040/9000 images (78%)]\tLoss: 0.629586\n",
            "Train Epoch: 52 [7680/9000 images (85%)]\tLoss: 0.606318\n",
            "Train Epoch: 52 [8320/9000 images (92%)]\tLoss: 0.648885\n",
            "Train Epoch: 52 [5600/9000 images (62%)]\tLoss: 0.638252\n",
            "\n",
            "Test set (epoch 52):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.70%\n",
            "    Macro F1-score: 0.3490\n",
            "    Per-pair accuracy (unordered pair): 95.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4956\n",
            "      circles: 0.5129\n",
            "      up     : 0.6373\n",
            "      right  : 0.6850\n",
            "      down   : 0.5908\n",
            "      left   : 0.7461\n",
            "    MAE per class:\n",
            "      squares: 0.2872\n",
            "      circles: 0.3205\n",
            "      up     : 0.3665\n",
            "      right  : 0.3972\n",
            "      down   : 0.3622\n",
            "      left   : 0.4062\n",
            "    RMSE overall: 0.6178\n",
            "    MAE overall: 0.3566\n",
            "\n",
            "  Losses:\n",
            "    cls=1.5767, cnt=0.9578, total=2.0556\n",
            "\n",
            "Train Epoch: 53 [0/9000 images (0%)]\tLoss: 0.569834\n",
            "Train Epoch: 53 [640/9000 images (7%)]\tLoss: 1.004358\n",
            "Train Epoch: 53 [1280/9000 images (14%)]\tLoss: 0.682428\n",
            "Train Epoch: 53 [1920/9000 images (21%)]\tLoss: 0.676726\n",
            "Train Epoch: 53 [2560/9000 images (28%)]\tLoss: 0.517766\n",
            "Train Epoch: 53 [3200/9000 images (36%)]\tLoss: 0.858352\n",
            "Train Epoch: 53 [3840/9000 images (43%)]\tLoss: 0.724941\n",
            "Train Epoch: 53 [4480/9000 images (50%)]\tLoss: 0.855986\n",
            "Train Epoch: 53 [5120/9000 images (57%)]\tLoss: 0.764801\n",
            "Train Epoch: 53 [5760/9000 images (64%)]\tLoss: 0.879558\n",
            "Train Epoch: 53 [6400/9000 images (71%)]\tLoss: 0.767277\n",
            "Train Epoch: 53 [7040/9000 images (78%)]\tLoss: 0.667561\n",
            "Train Epoch: 53 [7680/9000 images (85%)]\tLoss: 0.533029\n",
            "Train Epoch: 53 [8320/9000 images (92%)]\tLoss: 0.543429\n",
            "Train Epoch: 53 [5600/9000 images (62%)]\tLoss: 0.418102\n",
            "\n",
            "Test set (epoch 53):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.60%\n",
            "    Macro F1-score: 0.3592\n",
            "    Per-pair accuracy (unordered pair): 93.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5172\n",
            "      circles: 0.5941\n",
            "      up     : 0.6905\n",
            "      right  : 0.6551\n",
            "      down   : 0.6087\n",
            "      left   : 0.7280\n",
            "    MAE per class:\n",
            "      squares: 0.3206\n",
            "      circles: 0.3472\n",
            "      up     : 0.4030\n",
            "      right  : 0.3881\n",
            "      down   : 0.3622\n",
            "      left   : 0.4337\n",
            "    RMSE overall: 0.6360\n",
            "    MAE overall: 0.3758\n",
            "\n",
            "  Losses:\n",
            "    cls=1.5809, cnt=1.0088, total=2.0852\n",
            "\n",
            "Train Epoch: 54 [0/9000 images (0%)]\tLoss: 0.552134\n",
            "Train Epoch: 54 [640/9000 images (7%)]\tLoss: 0.500817\n",
            "Train Epoch: 54 [1280/9000 images (14%)]\tLoss: 0.830184\n",
            "Train Epoch: 54 [1920/9000 images (21%)]\tLoss: 0.554459\n",
            "Train Epoch: 54 [2560/9000 images (28%)]\tLoss: 0.559029\n",
            "Train Epoch: 54 [3200/9000 images (36%)]\tLoss: 0.753453\n",
            "Train Epoch: 54 [3840/9000 images (43%)]\tLoss: 0.594181\n",
            "Train Epoch: 54 [4480/9000 images (50%)]\tLoss: 0.684897\n",
            "Train Epoch: 54 [5120/9000 images (57%)]\tLoss: 0.392740\n",
            "Train Epoch: 54 [5760/9000 images (64%)]\tLoss: 0.698030\n",
            "Train Epoch: 54 [6400/9000 images (71%)]\tLoss: 0.453748\n",
            "Train Epoch: 54 [7040/9000 images (78%)]\tLoss: 0.533580\n",
            "Train Epoch: 54 [7680/9000 images (85%)]\tLoss: 0.671106\n",
            "Train Epoch: 54 [8320/9000 images (92%)]\tLoss: 0.677032\n",
            "Train Epoch: 54 [5600/9000 images (62%)]\tLoss: 0.776044\n",
            "\n",
            "Test set (epoch 54):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.20%\n",
            "    Macro F1-score: 0.3611\n",
            "    Per-pair accuracy (unordered pair): 94.10%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5463\n",
            "      circles: 0.5269\n",
            "      up     : 0.6537\n",
            "      right  : 0.6674\n",
            "      down   : 0.6540\n",
            "      left   : 0.7270\n",
            "    MAE per class:\n",
            "      squares: 0.3404\n",
            "      circles: 0.3032\n",
            "      up     : 0.3826\n",
            "      right  : 0.3748\n",
            "      down   : 0.3985\n",
            "      left   : 0.4024\n",
            "    RMSE overall: 0.6331\n",
            "    MAE overall: 0.3670\n",
            "\n",
            "  Losses:\n",
            "    cls=1.6284, cnt=0.9995, total=2.1281\n",
            "\n",
            "Train Epoch: 55 [0/9000 images (0%)]\tLoss: 0.614912\n",
            "Train Epoch: 55 [640/9000 images (7%)]\tLoss: 0.678187\n",
            "Train Epoch: 55 [1280/9000 images (14%)]\tLoss: 0.646118\n",
            "Train Epoch: 55 [1920/9000 images (21%)]\tLoss: 0.567907\n",
            "Train Epoch: 55 [2560/9000 images (28%)]\tLoss: 0.554660\n",
            "Train Epoch: 55 [3200/9000 images (36%)]\tLoss: 0.690546\n",
            "Train Epoch: 55 [3840/9000 images (43%)]\tLoss: 0.645656\n",
            "Train Epoch: 55 [4480/9000 images (50%)]\tLoss: 0.539701\n",
            "Train Epoch: 55 [5120/9000 images (57%)]\tLoss: 0.751037\n",
            "Train Epoch: 55 [5760/9000 images (64%)]\tLoss: 0.629663\n",
            "Train Epoch: 55 [6400/9000 images (71%)]\tLoss: 0.754073\n",
            "Train Epoch: 55 [7040/9000 images (78%)]\tLoss: 0.891110\n",
            "Train Epoch: 55 [7680/9000 images (85%)]\tLoss: 0.752955\n",
            "Train Epoch: 55 [8320/9000 images (92%)]\tLoss: 0.592742\n",
            "Train Epoch: 55 [5600/9000 images (62%)]\tLoss: 0.512484\n",
            "\n",
            "Test set (epoch 55):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.90%\n",
            "    Macro F1-score: 0.3711\n",
            "    Per-pair accuracy (unordered pair): 94.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5067\n",
            "      circles: 0.5534\n",
            "      up     : 0.6287\n",
            "      right  : 0.6252\n",
            "      down   : 0.6060\n",
            "      left   : 0.6788\n",
            "    MAE per class:\n",
            "      squares: 0.2971\n",
            "      circles: 0.3157\n",
            "      up     : 0.3658\n",
            "      right  : 0.3883\n",
            "      down   : 0.3495\n",
            "      left   : 0.3767\n",
            "    RMSE overall: 0.6024\n",
            "    MAE overall: 0.3489\n",
            "\n",
            "  Losses:\n",
            "    cls=1.5414, cnt=0.9218, total=2.0023\n",
            "\n",
            "Train Epoch: 56 [0/9000 images (0%)]\tLoss: 0.515904\n",
            "Train Epoch: 56 [640/9000 images (7%)]\tLoss: 0.404008\n",
            "Train Epoch: 56 [1280/9000 images (14%)]\tLoss: 0.658723\n",
            "Train Epoch: 56 [1920/9000 images (21%)]\tLoss: 0.537845\n",
            "Train Epoch: 56 [2560/9000 images (28%)]\tLoss: 0.738685\n",
            "Train Epoch: 56 [3200/9000 images (36%)]\tLoss: 0.630886\n",
            "Train Epoch: 56 [3840/9000 images (43%)]\tLoss: 0.481177\n",
            "Train Epoch: 56 [4480/9000 images (50%)]\tLoss: 0.457440\n",
            "Train Epoch: 56 [5120/9000 images (57%)]\tLoss: 0.612993\n",
            "Train Epoch: 56 [5760/9000 images (64%)]\tLoss: 0.640901\n",
            "Train Epoch: 56 [6400/9000 images (71%)]\tLoss: 0.574935\n",
            "Train Epoch: 56 [7040/9000 images (78%)]\tLoss: 0.626716\n",
            "Train Epoch: 56 [7680/9000 images (85%)]\tLoss: 0.671700\n",
            "Train Epoch: 56 [8320/9000 images (92%)]\tLoss: 0.590202\n",
            "Train Epoch: 56 [5600/9000 images (62%)]\tLoss: 0.616785\n",
            "\n",
            "Test set (epoch 56):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.60%\n",
            "    Macro F1-score: 0.3510\n",
            "    Per-pair accuracy (unordered pair): 93.30%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5036\n",
            "      circles: 0.5156\n",
            "      up     : 0.6512\n",
            "      right  : 0.6324\n",
            "      down   : 0.6023\n",
            "      left   : 0.7169\n",
            "    MAE per class:\n",
            "      squares: 0.3080\n",
            "      circles: 0.2937\n",
            "      up     : 0.3617\n",
            "      right  : 0.3913\n",
            "      down   : 0.3694\n",
            "      left   : 0.4085\n",
            "    RMSE overall: 0.6083\n",
            "    MAE overall: 0.3554\n",
            "\n",
            "  Losses:\n",
            "    cls=1.6311, cnt=0.9329, total=2.0976\n",
            "\n",
            "Train Epoch: 57 [0/9000 images (0%)]\tLoss: 0.572667\n",
            "Train Epoch: 57 [640/9000 images (7%)]\tLoss: 0.825461\n",
            "Train Epoch: 57 [1280/9000 images (14%)]\tLoss: 0.673304\n",
            "Train Epoch: 57 [1920/9000 images (21%)]\tLoss: 0.567626\n",
            "Train Epoch: 57 [2560/9000 images (28%)]\tLoss: 0.563697\n",
            "Train Epoch: 57 [3200/9000 images (36%)]\tLoss: 0.567281\n",
            "Train Epoch: 57 [3840/9000 images (43%)]\tLoss: 0.641060\n",
            "Train Epoch: 57 [4480/9000 images (50%)]\tLoss: 0.564314\n",
            "Train Epoch: 57 [5120/9000 images (57%)]\tLoss: 0.559688\n",
            "Train Epoch: 57 [5760/9000 images (64%)]\tLoss: 0.472891\n",
            "Train Epoch: 57 [6400/9000 images (71%)]\tLoss: 0.760483\n",
            "Train Epoch: 57 [7040/9000 images (78%)]\tLoss: 0.474520\n",
            "Train Epoch: 57 [7680/9000 images (85%)]\tLoss: 0.658947\n",
            "Train Epoch: 57 [8320/9000 images (92%)]\tLoss: 0.624955\n",
            "Train Epoch: 57 [5600/9000 images (62%)]\tLoss: 0.422059\n",
            "\n",
            "Test set (epoch 57):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.90%\n",
            "    Macro F1-score: 0.3673\n",
            "    Per-pair accuracy (unordered pair): 94.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5165\n",
            "      circles: 0.5420\n",
            "      up     : 0.6388\n",
            "      right  : 0.6572\n",
            "      down   : 0.5977\n",
            "      left   : 0.7100\n",
            "    MAE per class:\n",
            "      squares: 0.3085\n",
            "      circles: 0.3485\n",
            "      up     : 0.3789\n",
            "      right  : 0.3733\n",
            "      down   : 0.3537\n",
            "      left   : 0.3864\n",
            "    RMSE overall: 0.6140\n",
            "    MAE overall: 0.3582\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7149, cnt=0.9472, total=2.1885\n",
            "\n",
            "Train Epoch: 58 [0/9000 images (0%)]\tLoss: 0.636349\n",
            "Train Epoch: 58 [640/9000 images (7%)]\tLoss: 0.404294\n",
            "Train Epoch: 58 [1280/9000 images (14%)]\tLoss: 0.449776\n",
            "Train Epoch: 58 [1920/9000 images (21%)]\tLoss: 0.753663\n",
            "Train Epoch: 58 [2560/9000 images (28%)]\tLoss: 0.613536\n",
            "Train Epoch: 58 [3200/9000 images (36%)]\tLoss: 0.511518\n",
            "Train Epoch: 58 [3840/9000 images (43%)]\tLoss: 0.515349\n",
            "Train Epoch: 58 [4480/9000 images (50%)]\tLoss: 0.543943\n",
            "Train Epoch: 58 [5120/9000 images (57%)]\tLoss: 0.614718\n",
            "Train Epoch: 58 [5760/9000 images (64%)]\tLoss: 0.593622\n",
            "Train Epoch: 58 [6400/9000 images (71%)]\tLoss: 0.477900\n",
            "Train Epoch: 58 [7040/9000 images (78%)]\tLoss: 0.558780\n",
            "Train Epoch: 58 [7680/9000 images (85%)]\tLoss: 0.477814\n",
            "Train Epoch: 58 [8320/9000 images (92%)]\tLoss: 0.640258\n",
            "Train Epoch: 58 [5600/9000 images (62%)]\tLoss: 0.529306\n",
            "\n",
            "Test set (epoch 58):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.30%\n",
            "    Macro F1-score: 0.3526\n",
            "    Per-pair accuracy (unordered pair): 93.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5103\n",
            "      circles: 0.5173\n",
            "      up     : 0.6927\n",
            "      right  : 0.6252\n",
            "      down   : 0.7050\n",
            "      left   : 0.7236\n",
            "    MAE per class:\n",
            "      squares: 0.2913\n",
            "      circles: 0.3052\n",
            "      up     : 0.4067\n",
            "      right  : 0.3699\n",
            "      down   : 0.3937\n",
            "      left   : 0.4356\n",
            "    RMSE overall: 0.6350\n",
            "    MAE overall: 0.3671\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7034, cnt=1.0061, total=2.2064\n",
            "\n",
            "Train Epoch: 59 [0/9000 images (0%)]\tLoss: 0.594888\n",
            "Train Epoch: 59 [640/9000 images (7%)]\tLoss: 0.582651\n",
            "Train Epoch: 59 [1280/9000 images (14%)]\tLoss: 0.774391\n",
            "Train Epoch: 59 [1920/9000 images (21%)]\tLoss: 0.638919\n",
            "Train Epoch: 59 [2560/9000 images (28%)]\tLoss: 0.505792\n",
            "Train Epoch: 59 [3200/9000 images (36%)]\tLoss: 0.521616\n",
            "Train Epoch: 59 [3840/9000 images (43%)]\tLoss: 0.669680\n",
            "Train Epoch: 59 [4480/9000 images (50%)]\tLoss: 0.609490\n",
            "Train Epoch: 59 [5120/9000 images (57%)]\tLoss: 0.413363\n",
            "Train Epoch: 59 [5760/9000 images (64%)]\tLoss: 0.437690\n",
            "Train Epoch: 59 [6400/9000 images (71%)]\tLoss: 0.536816\n",
            "Train Epoch: 59 [7040/9000 images (78%)]\tLoss: 0.683190\n",
            "Train Epoch: 59 [7680/9000 images (85%)]\tLoss: 0.432403\n",
            "Train Epoch: 59 [8320/9000 images (92%)]\tLoss: 0.614371\n",
            "Train Epoch: 59 [5600/9000 images (62%)]\tLoss: 0.588796\n",
            "\n",
            "Test set (epoch 59):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.60%\n",
            "    Macro F1-score: 0.3747\n",
            "    Per-pair accuracy (unordered pair): 94.60%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4926\n",
            "      circles: 0.5315\n",
            "      up     : 0.6544\n",
            "      right  : 0.6088\n",
            "      down   : 0.5976\n",
            "      left   : 0.6782\n",
            "    MAE per class:\n",
            "      squares: 0.2871\n",
            "      circles: 0.2966\n",
            "      up     : 0.3764\n",
            "      right  : 0.3547\n",
            "      down   : 0.3426\n",
            "      left   : 0.3774\n",
            "    RMSE overall: 0.5974\n",
            "    MAE overall: 0.3391\n",
            "\n",
            "  Losses:\n",
            "    cls=1.6346, cnt=0.8979, total=2.0835\n",
            "\n",
            "Train Epoch: 60 [0/9000 images (0%)]\tLoss: 0.581124\n",
            "Train Epoch: 60 [640/9000 images (7%)]\tLoss: 0.438136\n",
            "Train Epoch: 60 [1280/9000 images (14%)]\tLoss: 0.530587\n",
            "Train Epoch: 60 [1920/9000 images (21%)]\tLoss: 0.545884\n",
            "Train Epoch: 60 [2560/9000 images (28%)]\tLoss: 0.649726\n",
            "Train Epoch: 60 [3200/9000 images (36%)]\tLoss: 0.285678\n",
            "Train Epoch: 60 [3840/9000 images (43%)]\tLoss: 0.549311\n",
            "Train Epoch: 60 [4480/9000 images (50%)]\tLoss: 0.506321\n",
            "Train Epoch: 60 [5120/9000 images (57%)]\tLoss: 0.480468\n",
            "Train Epoch: 60 [5760/9000 images (64%)]\tLoss: 0.426980\n",
            "Train Epoch: 60 [6400/9000 images (71%)]\tLoss: 0.551191\n",
            "Train Epoch: 60 [7040/9000 images (78%)]\tLoss: 0.423538\n",
            "Train Epoch: 60 [7680/9000 images (85%)]\tLoss: 0.771952\n",
            "Train Epoch: 60 [8320/9000 images (92%)]\tLoss: 0.429718\n",
            "Train Epoch: 60 [5600/9000 images (62%)]\tLoss: 0.554807\n",
            "\n",
            "Test set (epoch 60):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.40%\n",
            "    Macro F1-score: 0.3570\n",
            "    Per-pair accuracy (unordered pair): 94.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5037\n",
            "      circles: 0.5058\n",
            "      up     : 0.6760\n",
            "      right  : 0.6293\n",
            "      down   : 0.6429\n",
            "      left   : 0.6967\n",
            "    MAE per class:\n",
            "      squares: 0.3159\n",
            "      circles: 0.2999\n",
            "      up     : 0.3798\n",
            "      right  : 0.3561\n",
            "      down   : 0.3765\n",
            "      left   : 0.4053\n",
            "    RMSE overall: 0.6139\n",
            "    MAE overall: 0.3556\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7129, cnt=0.9490, total=2.1874\n",
            "\n",
            "Train Epoch: 61 [0/9000 images (0%)]\tLoss: 0.658926\n",
            "Train Epoch: 61 [640/9000 images (7%)]\tLoss: 0.397706\n",
            "Train Epoch: 61 [1280/9000 images (14%)]\tLoss: 0.704004\n",
            "Train Epoch: 61 [1920/9000 images (21%)]\tLoss: 0.551300\n",
            "Train Epoch: 61 [2560/9000 images (28%)]\tLoss: 0.578532\n",
            "Train Epoch: 61 [3200/9000 images (36%)]\tLoss: 0.435843\n",
            "Train Epoch: 61 [3840/9000 images (43%)]\tLoss: 0.724465\n",
            "Train Epoch: 61 [4480/9000 images (50%)]\tLoss: 0.672369\n",
            "Train Epoch: 61 [5120/9000 images (57%)]\tLoss: 0.870440\n",
            "Train Epoch: 61 [5760/9000 images (64%)]\tLoss: 0.691205\n",
            "Train Epoch: 61 [6400/9000 images (71%)]\tLoss: 0.520227\n",
            "Train Epoch: 61 [7040/9000 images (78%)]\tLoss: 0.379075\n",
            "Train Epoch: 61 [7680/9000 images (85%)]\tLoss: 0.461300\n",
            "Train Epoch: 61 [8320/9000 images (92%)]\tLoss: 0.483820\n",
            "Train Epoch: 61 [5600/9000 images (62%)]\tLoss: 0.327813\n",
            "\n",
            "Test set (epoch 61):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.90%\n",
            "    Macro F1-score: 0.3516\n",
            "    Per-pair accuracy (unordered pair): 94.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5265\n",
            "      circles: 0.5612\n",
            "      up     : 0.6498\n",
            "      right  : 0.6613\n",
            "      down   : 0.6183\n",
            "      left   : 0.7317\n",
            "    MAE per class:\n",
            "      squares: 0.3241\n",
            "      circles: 0.3228\n",
            "      up     : 0.3875\n",
            "      right  : 0.3781\n",
            "      down   : 0.3852\n",
            "      left   : 0.4038\n",
            "    RMSE overall: 0.6284\n",
            "    MAE overall: 0.3669\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7803, cnt=0.9871, total=2.2738\n",
            "\n",
            "Train Epoch: 62 [0/9000 images (0%)]\tLoss: 0.337854\n",
            "Train Epoch: 62 [640/9000 images (7%)]\tLoss: 0.607421\n",
            "Train Epoch: 62 [1280/9000 images (14%)]\tLoss: 0.423217\n",
            "Train Epoch: 62 [1920/9000 images (21%)]\tLoss: 0.417935\n",
            "Train Epoch: 62 [2560/9000 images (28%)]\tLoss: 0.458766\n",
            "Train Epoch: 62 [3200/9000 images (36%)]\tLoss: 0.543484\n",
            "Train Epoch: 62 [3840/9000 images (43%)]\tLoss: 0.543630\n",
            "Train Epoch: 62 [4480/9000 images (50%)]\tLoss: 0.552792\n",
            "Train Epoch: 62 [5120/9000 images (57%)]\tLoss: 0.476794\n",
            "Train Epoch: 62 [5760/9000 images (64%)]\tLoss: 0.436723\n",
            "Train Epoch: 62 [6400/9000 images (71%)]\tLoss: 0.756336\n",
            "Train Epoch: 62 [7040/9000 images (78%)]\tLoss: 0.703548\n",
            "Train Epoch: 62 [7680/9000 images (85%)]\tLoss: 0.391890\n",
            "Train Epoch: 62 [8320/9000 images (92%)]\tLoss: 0.693263\n",
            "Train Epoch: 62 [5600/9000 images (62%)]\tLoss: 0.612396\n",
            "\n",
            "Test set (epoch 62):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.50%\n",
            "    Macro F1-score: 0.3673\n",
            "    Per-pair accuracy (unordered pair): 94.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5042\n",
            "      circles: 0.5105\n",
            "      up     : 0.6314\n",
            "      right  : 0.6184\n",
            "      down   : 0.6528\n",
            "      left   : 0.7219\n",
            "    MAE per class:\n",
            "      squares: 0.2990\n",
            "      circles: 0.3173\n",
            "      up     : 0.3985\n",
            "      right  : 0.3447\n",
            "      down   : 0.3762\n",
            "      left   : 0.3974\n",
            "    RMSE overall: 0.6114\n",
            "    MAE overall: 0.3555\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7085, cnt=0.9381, total=2.1776\n",
            "\n",
            "Train Epoch: 63 [0/9000 images (0%)]\tLoss: 0.452232\n",
            "Train Epoch: 63 [640/9000 images (7%)]\tLoss: 0.703502\n",
            "Train Epoch: 63 [1280/9000 images (14%)]\tLoss: 0.504457\n",
            "Train Epoch: 63 [1920/9000 images (21%)]\tLoss: 0.403077\n",
            "Train Epoch: 63 [2560/9000 images (28%)]\tLoss: 0.454654\n",
            "Train Epoch: 63 [3200/9000 images (36%)]\tLoss: 0.482393\n",
            "Train Epoch: 63 [3840/9000 images (43%)]\tLoss: 0.531045\n",
            "Train Epoch: 63 [4480/9000 images (50%)]\tLoss: 0.500186\n",
            "Train Epoch: 63 [5120/9000 images (57%)]\tLoss: 0.479229\n",
            "Train Epoch: 63 [5760/9000 images (64%)]\tLoss: 0.529199\n",
            "Train Epoch: 63 [6400/9000 images (71%)]\tLoss: 0.568148\n",
            "Train Epoch: 63 [7040/9000 images (78%)]\tLoss: 0.444800\n",
            "Train Epoch: 63 [7680/9000 images (85%)]\tLoss: 0.601040\n",
            "Train Epoch: 63 [8320/9000 images (92%)]\tLoss: 0.518739\n",
            "Train Epoch: 63 [5600/9000 images (62%)]\tLoss: 0.638818\n",
            "\n",
            "Test set (epoch 63):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.80%\n",
            "    Macro F1-score: 0.3748\n",
            "    Per-pair accuracy (unordered pair): 94.90%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5189\n",
            "      circles: 0.5182\n",
            "      up     : 0.6126\n",
            "      right  : 0.6110\n",
            "      down   : 0.5829\n",
            "      left   : 0.7417\n",
            "    MAE per class:\n",
            "      squares: 0.3100\n",
            "      circles: 0.3106\n",
            "      up     : 0.3606\n",
            "      right  : 0.3415\n",
            "      down   : 0.3440\n",
            "      left   : 0.3963\n",
            "    RMSE overall: 0.6023\n",
            "    MAE overall: 0.3438\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7746, cnt=0.9100, total=2.2296\n",
            "\n",
            "Train Epoch: 64 [0/9000 images (0%)]\tLoss: 0.385799\n",
            "Train Epoch: 64 [640/9000 images (7%)]\tLoss: 0.506768\n",
            "Train Epoch: 64 [1280/9000 images (14%)]\tLoss: 0.560787\n",
            "Train Epoch: 64 [1920/9000 images (21%)]\tLoss: 0.423984\n",
            "Train Epoch: 64 [2560/9000 images (28%)]\tLoss: 0.492890\n",
            "Train Epoch: 64 [3200/9000 images (36%)]\tLoss: 0.608075\n",
            "Train Epoch: 64 [3840/9000 images (43%)]\tLoss: 0.634585\n",
            "Train Epoch: 64 [4480/9000 images (50%)]\tLoss: 0.615851\n",
            "Train Epoch: 64 [5120/9000 images (57%)]\tLoss: 0.480170\n",
            "Train Epoch: 64 [5760/9000 images (64%)]\tLoss: 0.597758\n",
            "Train Epoch: 64 [6400/9000 images (71%)]\tLoss: 0.598897\n",
            "Train Epoch: 64 [7040/9000 images (78%)]\tLoss: 0.505226\n",
            "Train Epoch: 64 [7680/9000 images (85%)]\tLoss: 0.508384\n",
            "Train Epoch: 64 [8320/9000 images (92%)]\tLoss: 0.576071\n",
            "Train Epoch: 64 [5600/9000 images (62%)]\tLoss: 0.273252\n",
            "\n",
            "Test set (epoch 64):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 51.60%\n",
            "    Macro F1-score: 0.3900\n",
            "    Per-pair accuracy (unordered pair): 94.80%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5293\n",
            "      circles: 0.5012\n",
            "      up     : 0.6124\n",
            "      right  : 0.6021\n",
            "      down   : 0.5887\n",
            "      left   : 0.6947\n",
            "    MAE per class:\n",
            "      squares: 0.3100\n",
            "      circles: 0.3006\n",
            "      up     : 0.3562\n",
            "      right  : 0.3381\n",
            "      down   : 0.3387\n",
            "      left   : 0.3926\n",
            "    RMSE overall: 0.5913\n",
            "    MAE overall: 0.3394\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7136, cnt=0.8865, total=2.1569\n",
            "\n",
            "Train Epoch: 65 [0/9000 images (0%)]\tLoss: 0.452311\n",
            "Train Epoch: 65 [640/9000 images (7%)]\tLoss: 0.396026\n",
            "Train Epoch: 65 [1280/9000 images (14%)]\tLoss: 0.475237\n",
            "Train Epoch: 65 [1920/9000 images (21%)]\tLoss: 0.612053\n",
            "Train Epoch: 65 [2560/9000 images (28%)]\tLoss: 0.547547\n",
            "Train Epoch: 65 [3200/9000 images (36%)]\tLoss: 0.391772\n",
            "Train Epoch: 65 [3840/9000 images (43%)]\tLoss: 0.691869\n",
            "Train Epoch: 65 [4480/9000 images (50%)]\tLoss: 0.516026\n",
            "Train Epoch: 65 [5120/9000 images (57%)]\tLoss: 0.496982\n",
            "Train Epoch: 65 [5760/9000 images (64%)]\tLoss: 0.477536\n",
            "Train Epoch: 65 [6400/9000 images (71%)]\tLoss: 0.471360\n",
            "Train Epoch: 65 [7040/9000 images (78%)]\tLoss: 0.472522\n",
            "Train Epoch: 65 [7680/9000 images (85%)]\tLoss: 0.514590\n",
            "Train Epoch: 65 [8320/9000 images (92%)]\tLoss: 0.714632\n",
            "Train Epoch: 65 [5600/9000 images (62%)]\tLoss: 0.649252\n",
            "\n",
            "Test set (epoch 65):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.90%\n",
            "    Macro F1-score: 0.3633\n",
            "    Per-pair accuracy (unordered pair): 94.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5966\n",
            "      circles: 0.5242\n",
            "      up     : 0.6569\n",
            "      right  : 0.6095\n",
            "      down   : 0.6250\n",
            "      left   : 0.6804\n",
            "    MAE per class:\n",
            "      squares: 0.3251\n",
            "      circles: 0.3020\n",
            "      up     : 0.3972\n",
            "      right  : 0.3544\n",
            "      down   : 0.3426\n",
            "      left   : 0.3855\n",
            "    RMSE overall: 0.6174\n",
            "    MAE overall: 0.3511\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7658, cnt=0.9533, total=2.2424\n",
            "\n",
            "Train Epoch: 66 [0/9000 images (0%)]\tLoss: 0.550216\n",
            "Train Epoch: 66 [640/9000 images (7%)]\tLoss: 0.381466\n",
            "Train Epoch: 66 [1280/9000 images (14%)]\tLoss: 0.362033\n",
            "Train Epoch: 66 [1920/9000 images (21%)]\tLoss: 0.465418\n",
            "Train Epoch: 66 [2560/9000 images (28%)]\tLoss: 0.556955\n",
            "Train Epoch: 66 [3200/9000 images (36%)]\tLoss: 0.422264\n",
            "Train Epoch: 66 [3840/9000 images (43%)]\tLoss: 0.576556\n",
            "Train Epoch: 66 [4480/9000 images (50%)]\tLoss: 0.399033\n",
            "Train Epoch: 66 [5120/9000 images (57%)]\tLoss: 0.637465\n",
            "Train Epoch: 66 [5760/9000 images (64%)]\tLoss: 0.390572\n",
            "Train Epoch: 66 [6400/9000 images (71%)]\tLoss: 0.495693\n",
            "Train Epoch: 66 [7040/9000 images (78%)]\tLoss: 0.448599\n",
            "Train Epoch: 66 [7680/9000 images (85%)]\tLoss: 0.687902\n",
            "Train Epoch: 66 [8320/9000 images (92%)]\tLoss: 0.591881\n",
            "Train Epoch: 66 [5600/9000 images (62%)]\tLoss: 0.516026\n",
            "\n",
            "Test set (epoch 66):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.60%\n",
            "    Macro F1-score: 0.3644\n",
            "    Per-pair accuracy (unordered pair): 94.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5065\n",
            "      circles: 0.5994\n",
            "      up     : 0.6343\n",
            "      right  : 0.6285\n",
            "      down   : 0.5829\n",
            "      left   : 0.7620\n",
            "    MAE per class:\n",
            "      squares: 0.3227\n",
            "      circles: 0.3396\n",
            "      up     : 0.3666\n",
            "      right  : 0.4054\n",
            "      down   : 0.3576\n",
            "      left   : 0.4206\n",
            "    RMSE overall: 0.6237\n",
            "    MAE overall: 0.3688\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7297, cnt=0.9741, total=2.2168\n",
            "\n",
            "Train Epoch: 67 [0/9000 images (0%)]\tLoss: 0.406018\n",
            "Train Epoch: 67 [640/9000 images (7%)]\tLoss: 0.494788\n",
            "Train Epoch: 67 [1280/9000 images (14%)]\tLoss: 0.483773\n",
            "Train Epoch: 67 [1920/9000 images (21%)]\tLoss: 0.554142\n",
            "Train Epoch: 67 [2560/9000 images (28%)]\tLoss: 0.315483\n",
            "Train Epoch: 67 [3200/9000 images (36%)]\tLoss: 0.343054\n",
            "Train Epoch: 67 [3840/9000 images (43%)]\tLoss: 0.458847\n",
            "Train Epoch: 67 [4480/9000 images (50%)]\tLoss: 0.675410\n",
            "Train Epoch: 67 [5120/9000 images (57%)]\tLoss: 0.449677\n",
            "Train Epoch: 67 [5760/9000 images (64%)]\tLoss: 0.642687\n",
            "Train Epoch: 67 [6400/9000 images (71%)]\tLoss: 0.416696\n",
            "Train Epoch: 67 [7040/9000 images (78%)]\tLoss: 0.372856\n",
            "Train Epoch: 67 [7680/9000 images (85%)]\tLoss: 0.469183\n",
            "Train Epoch: 67 [8320/9000 images (92%)]\tLoss: 0.421422\n",
            "Train Epoch: 67 [5600/9000 images (62%)]\tLoss: 0.376426\n",
            "\n",
            "Test set (epoch 67):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.40%\n",
            "    Macro F1-score: 0.3688\n",
            "    Per-pair accuracy (unordered pair): 94.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5303\n",
            "      circles: 0.5013\n",
            "      up     : 0.6116\n",
            "      right  : 0.6016\n",
            "      down   : 0.5945\n",
            "      left   : 0.6853\n",
            "    MAE per class:\n",
            "      squares: 0.2972\n",
            "      circles: 0.2957\n",
            "      up     : 0.3593\n",
            "      right  : 0.3482\n",
            "      down   : 0.3540\n",
            "      left   : 0.3725\n",
            "    RMSE overall: 0.5904\n",
            "    MAE overall: 0.3378\n",
            "\n",
            "  Losses:\n",
            "    cls=1.7988, cnt=0.8848, total=2.2412\n",
            "\n",
            "Train Epoch: 68 [0/9000 images (0%)]\tLoss: 0.468676\n",
            "Train Epoch: 68 [640/9000 images (7%)]\tLoss: 0.457155\n",
            "Train Epoch: 68 [1280/9000 images (14%)]\tLoss: 0.442972\n",
            "Train Epoch: 68 [1920/9000 images (21%)]\tLoss: 0.354521\n",
            "Train Epoch: 68 [2560/9000 images (28%)]\tLoss: 0.462034\n",
            "Train Epoch: 68 [3200/9000 images (36%)]\tLoss: 0.565919\n",
            "Train Epoch: 68 [3840/9000 images (43%)]\tLoss: 0.403242\n",
            "Train Epoch: 68 [4480/9000 images (50%)]\tLoss: 0.412426\n",
            "Train Epoch: 68 [5120/9000 images (57%)]\tLoss: 0.570507\n",
            "Train Epoch: 68 [5760/9000 images (64%)]\tLoss: 0.402042\n",
            "Train Epoch: 68 [6400/9000 images (71%)]\tLoss: 0.395479\n",
            "Train Epoch: 68 [7040/9000 images (78%)]\tLoss: 0.413338\n",
            "Train Epoch: 68 [7680/9000 images (85%)]\tLoss: 0.424595\n",
            "Train Epoch: 68 [8320/9000 images (92%)]\tLoss: 0.634896\n",
            "Train Epoch: 68 [5600/9000 images (62%)]\tLoss: 0.696698\n",
            "\n",
            "Test set (epoch 68):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.80%\n",
            "    Macro F1-score: 0.3651\n",
            "    Per-pair accuracy (unordered pair): 93.80%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5304\n",
            "      circles: 0.5979\n",
            "      up     : 0.6287\n",
            "      right  : 0.6410\n",
            "      down   : 0.6077\n",
            "      left   : 0.6907\n",
            "    MAE per class:\n",
            "      squares: 0.2970\n",
            "      circles: 0.3660\n",
            "      up     : 0.3634\n",
            "      right  : 0.3908\n",
            "      down   : 0.3458\n",
            "      left   : 0.3776\n",
            "    RMSE overall: 0.6180\n",
            "    MAE overall: 0.3568\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9365, cnt=0.9609, total=2.4170\n",
            "\n",
            "Train Epoch: 69 [0/9000 images (0%)]\tLoss: 0.440794\n",
            "Train Epoch: 69 [640/9000 images (7%)]\tLoss: 0.532511\n",
            "Train Epoch: 69 [1280/9000 images (14%)]\tLoss: 0.310807\n",
            "Train Epoch: 69 [1920/9000 images (21%)]\tLoss: 0.349065\n",
            "Train Epoch: 69 [2560/9000 images (28%)]\tLoss: 0.603878\n",
            "Train Epoch: 69 [3200/9000 images (36%)]\tLoss: 0.535805\n",
            "Train Epoch: 69 [3840/9000 images (43%)]\tLoss: 0.328377\n",
            "Train Epoch: 69 [4480/9000 images (50%)]\tLoss: 0.529365\n",
            "Train Epoch: 69 [5120/9000 images (57%)]\tLoss: 0.492339\n",
            "Train Epoch: 69 [5760/9000 images (64%)]\tLoss: 0.459856\n",
            "Train Epoch: 69 [6400/9000 images (71%)]\tLoss: 0.497812\n",
            "Train Epoch: 69 [7040/9000 images (78%)]\tLoss: 0.454149\n",
            "Train Epoch: 69 [7680/9000 images (85%)]\tLoss: 0.415052\n",
            "Train Epoch: 69 [8320/9000 images (92%)]\tLoss: 0.397506\n",
            "Train Epoch: 69 [5600/9000 images (62%)]\tLoss: 0.372246\n",
            "\n",
            "Test set (epoch 69):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 50.30%\n",
            "    Macro F1-score: 0.3743\n",
            "    Per-pair accuracy (unordered pair): 94.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5233\n",
            "      circles: 0.5282\n",
            "      up     : 0.6426\n",
            "      right  : 0.6017\n",
            "      down   : 0.5943\n",
            "      left   : 0.6946\n",
            "    MAE per class:\n",
            "      squares: 0.2990\n",
            "      circles: 0.3201\n",
            "      up     : 0.3771\n",
            "      right  : 0.3470\n",
            "      down   : 0.3507\n",
            "      left   : 0.3819\n",
            "    RMSE overall: 0.6005\n",
            "    MAE overall: 0.3460\n",
            "\n",
            "  Losses:\n",
            "    cls=1.8749, cnt=0.9142, total=2.3320\n",
            "\n",
            "Train Epoch: 70 [0/9000 images (0%)]\tLoss: 0.490679\n",
            "Train Epoch: 70 [640/9000 images (7%)]\tLoss: 0.344763\n",
            "Train Epoch: 70 [1280/9000 images (14%)]\tLoss: 0.379699\n",
            "Train Epoch: 70 [1920/9000 images (21%)]\tLoss: 0.320745\n",
            "Train Epoch: 70 [2560/9000 images (28%)]\tLoss: 0.508548\n",
            "Train Epoch: 70 [3200/9000 images (36%)]\tLoss: 0.499293\n",
            "Train Epoch: 70 [3840/9000 images (43%)]\tLoss: 0.482969\n",
            "Train Epoch: 70 [4480/9000 images (50%)]\tLoss: 0.374900\n",
            "Train Epoch: 70 [5120/9000 images (57%)]\tLoss: 0.424123\n",
            "Train Epoch: 70 [5760/9000 images (64%)]\tLoss: 0.355812\n",
            "Train Epoch: 70 [6400/9000 images (71%)]\tLoss: 0.585085\n",
            "Train Epoch: 70 [7040/9000 images (78%)]\tLoss: 0.636226\n",
            "Train Epoch: 70 [7680/9000 images (85%)]\tLoss: 0.388284\n",
            "Train Epoch: 70 [8320/9000 images (92%)]\tLoss: 0.478561\n",
            "Train Epoch: 70 [5600/9000 images (62%)]\tLoss: 0.491025\n",
            "\n",
            "Test set (epoch 70):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.50%\n",
            "    Macro F1-score: 0.3605\n",
            "    Per-pair accuracy (unordered pair): 95.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5015\n",
            "      circles: 0.5164\n",
            "      up     : 0.6179\n",
            "      right  : 0.6643\n",
            "      down   : 0.6075\n",
            "      left   : 0.6654\n",
            "    MAE per class:\n",
            "      squares: 0.2941\n",
            "      circles: 0.3076\n",
            "      up     : 0.3644\n",
            "      right  : 0.3752\n",
            "      down   : 0.3735\n",
            "      left   : 0.3879\n",
            "    RMSE overall: 0.5990\n",
            "    MAE overall: 0.3505\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9924, cnt=0.9141, total=2.4494\n",
            "\n",
            "Train Epoch: 71 [0/9000 images (0%)]\tLoss: 0.336123\n",
            "Train Epoch: 71 [640/9000 images (7%)]\tLoss: 0.581314\n",
            "Train Epoch: 71 [1280/9000 images (14%)]\tLoss: 0.605989\n",
            "Train Epoch: 71 [1920/9000 images (21%)]\tLoss: 0.460583\n",
            "Train Epoch: 71 [2560/9000 images (28%)]\tLoss: 0.671890\n",
            "Train Epoch: 71 [3200/9000 images (36%)]\tLoss: 0.548478\n",
            "Train Epoch: 71 [3840/9000 images (43%)]\tLoss: 0.574245\n",
            "Train Epoch: 71 [4480/9000 images (50%)]\tLoss: 0.975271\n",
            "Train Epoch: 71 [5120/9000 images (57%)]\tLoss: 0.387885\n",
            "Train Epoch: 71 [5760/9000 images (64%)]\tLoss: 0.664006\n",
            "Train Epoch: 71 [6400/9000 images (71%)]\tLoss: 0.574191\n",
            "Train Epoch: 71 [7040/9000 images (78%)]\tLoss: 0.433685\n",
            "Train Epoch: 71 [7680/9000 images (85%)]\tLoss: 0.446011\n",
            "Train Epoch: 71 [8320/9000 images (92%)]\tLoss: 0.528183\n",
            "Train Epoch: 71 [5600/9000 images (62%)]\tLoss: 0.442526\n",
            "\n",
            "Test set (epoch 71):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.60%\n",
            "    Macro F1-score: 0.3720\n",
            "    Per-pair accuracy (unordered pair): 95.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4962\n",
            "      circles: 0.5120\n",
            "      up     : 0.6107\n",
            "      right  : 0.6100\n",
            "      down   : 0.6069\n",
            "      left   : 0.6899\n",
            "    MAE per class:\n",
            "      squares: 0.2961\n",
            "      circles: 0.2992\n",
            "      up     : 0.3589\n",
            "      right  : 0.3505\n",
            "      down   : 0.3570\n",
            "      left   : 0.3932\n",
            "    RMSE overall: 0.5913\n",
            "    MAE overall: 0.3425\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9428, cnt=0.8911, total=2.3884\n",
            "\n",
            "Train Epoch: 72 [0/9000 images (0%)]\tLoss: 0.516531\n",
            "Train Epoch: 72 [640/9000 images (7%)]\tLoss: 0.474487\n",
            "Train Epoch: 72 [1280/9000 images (14%)]\tLoss: 0.399328\n",
            "Train Epoch: 72 [1920/9000 images (21%)]\tLoss: 0.339550\n",
            "Train Epoch: 72 [2560/9000 images (28%)]\tLoss: 0.291261\n",
            "Train Epoch: 72 [3200/9000 images (36%)]\tLoss: 0.508812\n",
            "Train Epoch: 72 [3840/9000 images (43%)]\tLoss: 0.518225\n",
            "Train Epoch: 72 [4480/9000 images (50%)]\tLoss: 0.502992\n",
            "Train Epoch: 72 [5120/9000 images (57%)]\tLoss: 0.555121\n",
            "Train Epoch: 72 [5760/9000 images (64%)]\tLoss: 0.332860\n",
            "Train Epoch: 72 [6400/9000 images (71%)]\tLoss: 0.378235\n",
            "Train Epoch: 72 [7040/9000 images (78%)]\tLoss: 0.598754\n",
            "Train Epoch: 72 [7680/9000 images (85%)]\tLoss: 0.434234\n",
            "Train Epoch: 72 [8320/9000 images (92%)]\tLoss: 0.471961\n",
            "Train Epoch: 72 [5600/9000 images (62%)]\tLoss: 0.497679\n",
            "\n",
            "Test set (epoch 72):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.20%\n",
            "    Macro F1-score: 0.3642\n",
            "    Per-pair accuracy (unordered pair): 94.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5413\n",
            "      circles: 0.5466\n",
            "      up     : 0.6272\n",
            "      right  : 0.6135\n",
            "      down   : 0.7501\n",
            "      left   : 0.6830\n",
            "    MAE per class:\n",
            "      squares: 0.3532\n",
            "      circles: 0.3336\n",
            "      up     : 0.3800\n",
            "      right  : 0.3712\n",
            "      down   : 0.4232\n",
            "      left   : 0.3918\n",
            "    RMSE overall: 0.6312\n",
            "    MAE overall: 0.3755\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9542, cnt=0.9975, total=2.4530\n",
            "\n",
            "Train Epoch: 73 [0/9000 images (0%)]\tLoss: 0.357430\n",
            "Train Epoch: 73 [640/9000 images (7%)]\tLoss: 0.599969\n",
            "Train Epoch: 73 [1280/9000 images (14%)]\tLoss: 0.594596\n",
            "Train Epoch: 73 [1920/9000 images (21%)]\tLoss: 0.404310\n",
            "Train Epoch: 73 [2560/9000 images (28%)]\tLoss: 0.472498\n",
            "Train Epoch: 73 [3200/9000 images (36%)]\tLoss: 0.427502\n",
            "Train Epoch: 73 [3840/9000 images (43%)]\tLoss: 0.792670\n",
            "Train Epoch: 73 [4480/9000 images (50%)]\tLoss: 0.471164\n",
            "Train Epoch: 73 [5120/9000 images (57%)]\tLoss: 0.344867\n",
            "Train Epoch: 73 [5760/9000 images (64%)]\tLoss: 0.384935\n",
            "Train Epoch: 73 [6400/9000 images (71%)]\tLoss: 0.399383\n",
            "Train Epoch: 73 [7040/9000 images (78%)]\tLoss: 0.392961\n",
            "Train Epoch: 73 [7680/9000 images (85%)]\tLoss: 0.283781\n",
            "Train Epoch: 73 [8320/9000 images (92%)]\tLoss: 0.478706\n",
            "Train Epoch: 73 [5600/9000 images (62%)]\tLoss: 0.371621\n",
            "\n",
            "Test set (epoch 73):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.90%\n",
            "    Macro F1-score: 0.3804\n",
            "    Per-pair accuracy (unordered pair): 94.30%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5481\n",
            "      circles: 0.5176\n",
            "      up     : 0.6715\n",
            "      right  : 0.6835\n",
            "      down   : 0.6143\n",
            "      left   : 0.7057\n",
            "    MAE per class:\n",
            "      squares: 0.3195\n",
            "      circles: 0.3141\n",
            "      up     : 0.3973\n",
            "      right  : 0.4202\n",
            "      down   : 0.3762\n",
            "      left   : 0.3867\n",
            "    RMSE overall: 0.6274\n",
            "    MAE overall: 0.3690\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9202, cnt=0.9931, total=2.4168\n",
            "\n",
            "Train Epoch: 74 [0/9000 images (0%)]\tLoss: 0.323623\n",
            "Train Epoch: 74 [640/9000 images (7%)]\tLoss: 0.556604\n",
            "Train Epoch: 74 [1280/9000 images (14%)]\tLoss: 0.532723\n",
            "Train Epoch: 74 [1920/9000 images (21%)]\tLoss: 0.634894\n",
            "Train Epoch: 74 [2560/9000 images (28%)]\tLoss: 0.306444\n",
            "Train Epoch: 74 [3200/9000 images (36%)]\tLoss: 0.504321\n",
            "Train Epoch: 74 [3840/9000 images (43%)]\tLoss: 0.486277\n",
            "Train Epoch: 74 [4480/9000 images (50%)]\tLoss: 0.439523\n",
            "Train Epoch: 74 [5120/9000 images (57%)]\tLoss: 0.617805\n",
            "Train Epoch: 74 [5760/9000 images (64%)]\tLoss: 0.433430\n",
            "Train Epoch: 74 [6400/9000 images (71%)]\tLoss: 0.448753\n",
            "Train Epoch: 74 [7040/9000 images (78%)]\tLoss: 0.364227\n",
            "Train Epoch: 74 [7680/9000 images (85%)]\tLoss: 0.240276\n",
            "Train Epoch: 74 [8320/9000 images (92%)]\tLoss: 0.525865\n",
            "Train Epoch: 74 [5600/9000 images (62%)]\tLoss: 0.394673\n",
            "\n",
            "Test set (epoch 74):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 50.10%\n",
            "    Macro F1-score: 0.3783\n",
            "    Per-pair accuracy (unordered pair): 94.60%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5377\n",
            "      circles: 0.5629\n",
            "      up     : 0.5969\n",
            "      right  : 0.6777\n",
            "      down   : 0.6460\n",
            "      left   : 0.7147\n",
            "    MAE per class:\n",
            "      squares: 0.3218\n",
            "      circles: 0.3809\n",
            "      up     : 0.3822\n",
            "      right  : 0.3783\n",
            "      down   : 0.3609\n",
            "      left   : 0.3970\n",
            "    RMSE overall: 0.6258\n",
            "    MAE overall: 0.3702\n",
            "\n",
            "  Losses:\n",
            "    cls=2.0850, cnt=0.9824, total=2.5763\n",
            "\n",
            "Train Epoch: 75 [0/9000 images (0%)]\tLoss: 0.353196\n",
            "Train Epoch: 75 [640/9000 images (7%)]\tLoss: 0.403299\n",
            "Train Epoch: 75 [1280/9000 images (14%)]\tLoss: 0.442696\n",
            "Train Epoch: 75 [1920/9000 images (21%)]\tLoss: 0.467819\n",
            "Train Epoch: 75 [2560/9000 images (28%)]\tLoss: 0.364323\n",
            "Train Epoch: 75 [3200/9000 images (36%)]\tLoss: 0.643493\n",
            "Train Epoch: 75 [3840/9000 images (43%)]\tLoss: 0.421277\n",
            "Train Epoch: 75 [4480/9000 images (50%)]\tLoss: 0.546659\n",
            "Train Epoch: 75 [5120/9000 images (57%)]\tLoss: 0.534775\n",
            "Train Epoch: 75 [5760/9000 images (64%)]\tLoss: 0.360350\n",
            "Train Epoch: 75 [6400/9000 images (71%)]\tLoss: 0.353973\n",
            "Train Epoch: 75 [7040/9000 images (78%)]\tLoss: 0.658555\n",
            "Train Epoch: 75 [7680/9000 images (85%)]\tLoss: 0.446116\n",
            "Train Epoch: 75 [8320/9000 images (92%)]\tLoss: 0.387291\n",
            "Train Epoch: 75 [5600/9000 images (62%)]\tLoss: 0.348187\n",
            "\n",
            "Test set (epoch 75):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.30%\n",
            "    Macro F1-score: 0.3696\n",
            "    Per-pair accuracy (unordered pair): 94.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5076\n",
            "      circles: 0.5244\n",
            "      up     : 0.6183\n",
            "      right  : 0.6296\n",
            "      down   : 0.6143\n",
            "      left   : 0.6591\n",
            "    MAE per class:\n",
            "      squares: 0.2975\n",
            "      circles: 0.2993\n",
            "      up     : 0.3693\n",
            "      right  : 0.3822\n",
            "      down   : 0.3564\n",
            "      left   : 0.3702\n",
            "    RMSE overall: 0.5949\n",
            "    MAE overall: 0.3458\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9443, cnt=0.9040, total=2.3963\n",
            "\n",
            "Train Epoch: 76 [0/9000 images (0%)]\tLoss: 0.427173\n",
            "Train Epoch: 76 [640/9000 images (7%)]\tLoss: 0.416537\n",
            "Train Epoch: 76 [1280/9000 images (14%)]\tLoss: 0.373689\n",
            "Train Epoch: 76 [1920/9000 images (21%)]\tLoss: 0.470615\n",
            "Train Epoch: 76 [2560/9000 images (28%)]\tLoss: 0.379154\n",
            "Train Epoch: 76 [3200/9000 images (36%)]\tLoss: 0.380132\n",
            "Train Epoch: 76 [3840/9000 images (43%)]\tLoss: 0.322240\n",
            "Train Epoch: 76 [4480/9000 images (50%)]\tLoss: 0.364579\n",
            "Train Epoch: 76 [5120/9000 images (57%)]\tLoss: 0.380780\n",
            "Train Epoch: 76 [5760/9000 images (64%)]\tLoss: 0.385113\n",
            "Train Epoch: 76 [6400/9000 images (71%)]\tLoss: 0.395804\n",
            "Train Epoch: 76 [7040/9000 images (78%)]\tLoss: 0.559659\n",
            "Train Epoch: 76 [7680/9000 images (85%)]\tLoss: 0.325246\n",
            "Train Epoch: 76 [8320/9000 images (92%)]\tLoss: 0.571315\n",
            "Train Epoch: 76 [5600/9000 images (62%)]\tLoss: 0.685764\n",
            "\n",
            "Test set (epoch 76):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.10%\n",
            "    Macro F1-score: 0.3664\n",
            "    Per-pair accuracy (unordered pair): 94.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5024\n",
            "      circles: 0.5687\n",
            "      up     : 0.6105\n",
            "      right  : 0.6186\n",
            "      down   : 0.5905\n",
            "      left   : 0.6710\n",
            "    MAE per class:\n",
            "      squares: 0.2923\n",
            "      circles: 0.3283\n",
            "      up     : 0.3733\n",
            "      right  : 0.3445\n",
            "      down   : 0.3486\n",
            "      left   : 0.4130\n",
            "    RMSE overall: 0.5958\n",
            "    MAE overall: 0.3500\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9997, cnt=0.9091, total=2.4542\n",
            "\n",
            "Train Epoch: 77 [0/9000 images (0%)]\tLoss: 0.419554\n",
            "Train Epoch: 77 [640/9000 images (7%)]\tLoss: 0.801421\n",
            "Train Epoch: 77 [1280/9000 images (14%)]\tLoss: 0.532802\n",
            "Train Epoch: 77 [1920/9000 images (21%)]\tLoss: 0.455128\n",
            "Train Epoch: 77 [2560/9000 images (28%)]\tLoss: 0.442577\n",
            "Train Epoch: 77 [3200/9000 images (36%)]\tLoss: 0.254780\n",
            "Train Epoch: 77 [3840/9000 images (43%)]\tLoss: 0.545994\n",
            "Train Epoch: 77 [4480/9000 images (50%)]\tLoss: 0.299780\n",
            "Train Epoch: 77 [5120/9000 images (57%)]\tLoss: 0.496089\n",
            "Train Epoch: 77 [5760/9000 images (64%)]\tLoss: 0.429485\n",
            "Train Epoch: 77 [6400/9000 images (71%)]\tLoss: 0.530469\n",
            "Train Epoch: 77 [7040/9000 images (78%)]\tLoss: 0.268005\n",
            "Train Epoch: 77 [7680/9000 images (85%)]\tLoss: 0.530761\n",
            "Train Epoch: 77 [8320/9000 images (92%)]\tLoss: 0.315551\n",
            "Train Epoch: 77 [5600/9000 images (62%)]\tLoss: 0.270942\n",
            "\n",
            "Test set (epoch 77):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.70%\n",
            "    Macro F1-score: 0.3510\n",
            "    Per-pair accuracy (unordered pair): 94.10%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5893\n",
            "      circles: 0.5370\n",
            "      up     : 0.6055\n",
            "      right  : 0.6187\n",
            "      down   : 0.6292\n",
            "      left   : 0.6678\n",
            "    MAE per class:\n",
            "      squares: 0.3315\n",
            "      circles: 0.3221\n",
            "      up     : 0.3530\n",
            "      right  : 0.3615\n",
            "      down   : 0.3993\n",
            "      left   : 0.3784\n",
            "    RMSE overall: 0.6092\n",
            "    MAE overall: 0.3576\n",
            "\n",
            "  Losses:\n",
            "    cls=2.0852, cnt=0.9387, total=2.5546\n",
            "\n",
            "Train Epoch: 78 [0/9000 images (0%)]\tLoss: 0.479274\n",
            "Train Epoch: 78 [640/9000 images (7%)]\tLoss: 0.283092\n",
            "Train Epoch: 78 [1280/9000 images (14%)]\tLoss: 0.361669\n",
            "Train Epoch: 78 [1920/9000 images (21%)]\tLoss: 0.276284\n",
            "Train Epoch: 78 [2560/9000 images (28%)]\tLoss: 0.563432\n",
            "Train Epoch: 78 [3200/9000 images (36%)]\tLoss: 0.443822\n",
            "Train Epoch: 78 [3840/9000 images (43%)]\tLoss: 0.630176\n",
            "Train Epoch: 78 [4480/9000 images (50%)]\tLoss: 0.613963\n",
            "Train Epoch: 78 [5120/9000 images (57%)]\tLoss: 0.509774\n",
            "Train Epoch: 78 [5760/9000 images (64%)]\tLoss: 0.440606\n",
            "Train Epoch: 78 [6400/9000 images (71%)]\tLoss: 0.324783\n",
            "Train Epoch: 78 [7040/9000 images (78%)]\tLoss: 0.506623\n",
            "Train Epoch: 78 [7680/9000 images (85%)]\tLoss: 0.403000\n",
            "Train Epoch: 78 [8320/9000 images (92%)]\tLoss: 0.539947\n",
            "Train Epoch: 78 [5600/9000 images (62%)]\tLoss: 0.428625\n",
            "\n",
            "Test set (epoch 78):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.80%\n",
            "    Macro F1-score: 0.3702\n",
            "    Per-pair accuracy (unordered pair): 94.30%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4933\n",
            "      circles: 0.5561\n",
            "      up     : 0.5972\n",
            "      right  : 0.6128\n",
            "      down   : 0.5947\n",
            "      left   : 0.7265\n",
            "    MAE per class:\n",
            "      squares: 0.2925\n",
            "      circles: 0.3533\n",
            "      up     : 0.3559\n",
            "      right  : 0.3676\n",
            "      down   : 0.3465\n",
            "      left   : 0.3996\n",
            "    RMSE overall: 0.6009\n",
            "    MAE overall: 0.3526\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9946, cnt=0.9181, total=2.4536\n",
            "\n",
            "Train Epoch: 79 [0/9000 images (0%)]\tLoss: 0.453944\n",
            "Train Epoch: 79 [640/9000 images (7%)]\tLoss: 0.556486\n",
            "Train Epoch: 79 [1280/9000 images (14%)]\tLoss: 0.349005\n",
            "Train Epoch: 79 [1920/9000 images (21%)]\tLoss: 0.332096\n",
            "Train Epoch: 79 [2560/9000 images (28%)]\tLoss: 0.306360\n",
            "Train Epoch: 79 [3200/9000 images (36%)]\tLoss: 0.312794\n",
            "Train Epoch: 79 [3840/9000 images (43%)]\tLoss: 0.363350\n",
            "Train Epoch: 79 [4480/9000 images (50%)]\tLoss: 0.386546\n",
            "Train Epoch: 79 [5120/9000 images (57%)]\tLoss: 0.344794\n",
            "Train Epoch: 79 [5760/9000 images (64%)]\tLoss: 0.470659\n",
            "Train Epoch: 79 [6400/9000 images (71%)]\tLoss: 0.378914\n",
            "Train Epoch: 79 [7040/9000 images (78%)]\tLoss: 0.406255\n",
            "Train Epoch: 79 [7680/9000 images (85%)]\tLoss: 0.306637\n",
            "Train Epoch: 79 [8320/9000 images (92%)]\tLoss: 0.392221\n",
            "Train Epoch: 79 [5600/9000 images (62%)]\tLoss: 0.286361\n",
            "\n",
            "Test set (epoch 79):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.80%\n",
            "    Macro F1-score: 0.3723\n",
            "    Per-pair accuracy (unordered pair): 93.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5128\n",
            "      circles: 0.5433\n",
            "      up     : 0.6127\n",
            "      right  : 0.6517\n",
            "      down   : 0.5883\n",
            "      left   : 0.6876\n",
            "    MAE per class:\n",
            "      squares: 0.3033\n",
            "      circles: 0.3144\n",
            "      up     : 0.3896\n",
            "      right  : 0.3825\n",
            "      down   : 0.3578\n",
            "      left   : 0.3998\n",
            "    RMSE overall: 0.6024\n",
            "    MAE overall: 0.3579\n",
            "\n",
            "  Losses:\n",
            "    cls=2.0301, cnt=0.9233, total=2.4918\n",
            "\n",
            "Train Epoch: 80 [0/9000 images (0%)]\tLoss: 0.325213\n",
            "Train Epoch: 80 [640/9000 images (7%)]\tLoss: 0.484796\n",
            "Train Epoch: 80 [1280/9000 images (14%)]\tLoss: 0.440913\n",
            "Train Epoch: 80 [1920/9000 images (21%)]\tLoss: 0.448292\n",
            "Train Epoch: 80 [2560/9000 images (28%)]\tLoss: 0.619278\n",
            "Train Epoch: 80 [3200/9000 images (36%)]\tLoss: 0.549736\n",
            "Train Epoch: 80 [3840/9000 images (43%)]\tLoss: 0.373752\n",
            "Train Epoch: 80 [4480/9000 images (50%)]\tLoss: 0.426204\n",
            "Train Epoch: 80 [5120/9000 images (57%)]\tLoss: 0.480255\n",
            "Train Epoch: 80 [5760/9000 images (64%)]\tLoss: 0.341361\n",
            "Train Epoch: 80 [6400/9000 images (71%)]\tLoss: 0.380847\n",
            "Train Epoch: 80 [7040/9000 images (78%)]\tLoss: 0.317851\n",
            "Train Epoch: 80 [7680/9000 images (85%)]\tLoss: 0.579528\n",
            "Train Epoch: 80 [8320/9000 images (92%)]\tLoss: 0.389954\n",
            "Train Epoch: 80 [5600/9000 images (62%)]\tLoss: 0.214732\n",
            "\n",
            "Test set (epoch 80):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.00%\n",
            "    Macro F1-score: 0.3597\n",
            "    Per-pair accuracy (unordered pair): 94.10%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5145\n",
            "      circles: 0.5167\n",
            "      up     : 0.6210\n",
            "      right  : 0.5968\n",
            "      down   : 0.6080\n",
            "      left   : 0.6744\n",
            "    MAE per class:\n",
            "      squares: 0.2912\n",
            "      circles: 0.3076\n",
            "      up     : 0.3607\n",
            "      right  : 0.3680\n",
            "      down   : 0.3562\n",
            "      left   : 0.3903\n",
            "    RMSE overall: 0.5913\n",
            "    MAE overall: 0.3457\n",
            "\n",
            "  Losses:\n",
            "    cls=2.0826, cnt=0.8927, total=2.5290\n",
            "\n",
            "Train Epoch: 81 [0/9000 images (0%)]\tLoss: 0.415715\n",
            "Train Epoch: 81 [640/9000 images (7%)]\tLoss: 0.357987\n",
            "Train Epoch: 81 [1280/9000 images (14%)]\tLoss: 0.491942\n",
            "Train Epoch: 81 [1920/9000 images (21%)]\tLoss: 0.411670\n",
            "Train Epoch: 81 [2560/9000 images (28%)]\tLoss: 0.385992\n",
            "Train Epoch: 81 [3200/9000 images (36%)]\tLoss: 0.713342\n",
            "Train Epoch: 81 [3840/9000 images (43%)]\tLoss: 0.238201\n",
            "Train Epoch: 81 [4480/9000 images (50%)]\tLoss: 0.299592\n",
            "Train Epoch: 81 [5120/9000 images (57%)]\tLoss: 0.393979\n",
            "Train Epoch: 81 [5760/9000 images (64%)]\tLoss: 0.381655\n",
            "Train Epoch: 81 [6400/9000 images (71%)]\tLoss: 0.489291\n",
            "Train Epoch: 81 [7040/9000 images (78%)]\tLoss: 0.433938\n",
            "Train Epoch: 81 [7680/9000 images (85%)]\tLoss: 0.254824\n",
            "Train Epoch: 81 [8320/9000 images (92%)]\tLoss: 0.410437\n",
            "Train Epoch: 81 [5600/9000 images (62%)]\tLoss: 0.225098\n",
            "\n",
            "Test set (epoch 81):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.20%\n",
            "    Macro F1-score: 0.3666\n",
            "    Per-pair accuracy (unordered pair): 94.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5143\n",
            "      circles: 0.5199\n",
            "      up     : 0.6001\n",
            "      right  : 0.5984\n",
            "      down   : 0.5904\n",
            "      left   : 0.6731\n",
            "    MAE per class:\n",
            "      squares: 0.3044\n",
            "      circles: 0.3056\n",
            "      up     : 0.3489\n",
            "      right  : 0.3401\n",
            "      down   : 0.3572\n",
            "      left   : 0.4046\n",
            "    RMSE overall: 0.5852\n",
            "    MAE overall: 0.3435\n",
            "\n",
            "  Losses:\n",
            "    cls=2.1223, cnt=0.8742, total=2.5594\n",
            "\n",
            "Train Epoch: 82 [0/9000 images (0%)]\tLoss: 0.453693\n",
            "Train Epoch: 82 [640/9000 images (7%)]\tLoss: 0.458051\n",
            "Train Epoch: 82 [1280/9000 images (14%)]\tLoss: 0.399596\n",
            "Train Epoch: 82 [1920/9000 images (21%)]\tLoss: 0.690913\n",
            "Train Epoch: 82 [2560/9000 images (28%)]\tLoss: 0.358269\n",
            "Train Epoch: 82 [3200/9000 images (36%)]\tLoss: 0.423320\n",
            "Train Epoch: 82 [3840/9000 images (43%)]\tLoss: 0.287919\n",
            "Train Epoch: 82 [4480/9000 images (50%)]\tLoss: 0.314124\n",
            "Train Epoch: 82 [5120/9000 images (57%)]\tLoss: 0.397762\n",
            "Train Epoch: 82 [5760/9000 images (64%)]\tLoss: 0.404971\n",
            "Train Epoch: 82 [6400/9000 images (71%)]\tLoss: 0.337968\n",
            "Train Epoch: 82 [7040/9000 images (78%)]\tLoss: 0.446168\n",
            "Train Epoch: 82 [7680/9000 images (85%)]\tLoss: 0.365984\n",
            "Train Epoch: 82 [8320/9000 images (92%)]\tLoss: 0.510816\n",
            "Train Epoch: 82 [5600/9000 images (62%)]\tLoss: 0.466227\n",
            "\n",
            "Test set (epoch 82):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.60%\n",
            "    Macro F1-score: 0.3691\n",
            "    Per-pair accuracy (unordered pair): 94.60%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5185\n",
            "      circles: 0.5170\n",
            "      up     : 0.6225\n",
            "      right  : 0.6272\n",
            "      down   : 0.6661\n",
            "      left   : 0.6911\n",
            "    MAE per class:\n",
            "      squares: 0.3397\n",
            "      circles: 0.3190\n",
            "      up     : 0.3854\n",
            "      right  : 0.3637\n",
            "      down   : 0.3833\n",
            "      left   : 0.3822\n",
            "    RMSE overall: 0.6108\n",
            "    MAE overall: 0.3622\n",
            "\n",
            "  Losses:\n",
            "    cls=2.0980, cnt=0.9389, total=2.5674\n",
            "\n",
            "Train Epoch: 83 [0/9000 images (0%)]\tLoss: 0.521138\n",
            "Train Epoch: 83 [640/9000 images (7%)]\tLoss: 0.454460\n",
            "Train Epoch: 83 [1280/9000 images (14%)]\tLoss: 0.611326\n",
            "Train Epoch: 83 [1920/9000 images (21%)]\tLoss: 0.315272\n",
            "Train Epoch: 83 [2560/9000 images (28%)]\tLoss: 0.374627\n",
            "Train Epoch: 83 [3200/9000 images (36%)]\tLoss: 0.348295\n",
            "Train Epoch: 83 [3840/9000 images (43%)]\tLoss: 0.377049\n",
            "Train Epoch: 83 [4480/9000 images (50%)]\tLoss: 0.444589\n",
            "Train Epoch: 83 [5120/9000 images (57%)]\tLoss: 0.380076\n",
            "Train Epoch: 83 [5760/9000 images (64%)]\tLoss: 0.279610\n",
            "Train Epoch: 83 [6400/9000 images (71%)]\tLoss: 0.560782\n",
            "Train Epoch: 83 [7040/9000 images (78%)]\tLoss: 0.449633\n",
            "Train Epoch: 83 [7680/9000 images (85%)]\tLoss: 0.319012\n",
            "Train Epoch: 83 [8320/9000 images (92%)]\tLoss: 0.466464\n",
            "Train Epoch: 83 [5600/9000 images (62%)]\tLoss: 0.457702\n",
            "\n",
            "Test set (epoch 83):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 51.00%\n",
            "    Macro F1-score: 0.3781\n",
            "    Per-pair accuracy (unordered pair): 94.30%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5083\n",
            "      circles: 0.5499\n",
            "      up     : 0.6549\n",
            "      right  : 0.5965\n",
            "      down   : 0.6117\n",
            "      left   : 0.6745\n",
            "    MAE per class:\n",
            "      squares: 0.3000\n",
            "      circles: 0.3279\n",
            "      up     : 0.3860\n",
            "      right  : 0.3503\n",
            "      down   : 0.3881\n",
            "      left   : 0.3966\n",
            "    RMSE overall: 0.6020\n",
            "    MAE overall: 0.3582\n",
            "\n",
            "  Losses:\n",
            "    cls=2.0371, cnt=0.9207, total=2.4975\n",
            "\n",
            "Train Epoch: 84 [0/9000 images (0%)]\tLoss: 0.299646\n",
            "Train Epoch: 84 [640/9000 images (7%)]\tLoss: 0.463025\n",
            "Train Epoch: 84 [1280/9000 images (14%)]\tLoss: 0.524518\n",
            "Train Epoch: 84 [1920/9000 images (21%)]\tLoss: 0.755532\n",
            "Train Epoch: 84 [2560/9000 images (28%)]\tLoss: 0.431988\n",
            "Train Epoch: 84 [3200/9000 images (36%)]\tLoss: 0.301606\n",
            "Train Epoch: 84 [3840/9000 images (43%)]\tLoss: 0.449413\n",
            "Train Epoch: 84 [4480/9000 images (50%)]\tLoss: 0.413605\n",
            "Train Epoch: 84 [5120/9000 images (57%)]\tLoss: 0.289120\n",
            "Train Epoch: 84 [5760/9000 images (64%)]\tLoss: 0.460232\n",
            "Train Epoch: 84 [6400/9000 images (71%)]\tLoss: 0.454758\n",
            "Train Epoch: 84 [7040/9000 images (78%)]\tLoss: 0.476246\n",
            "Train Epoch: 84 [7680/9000 images (85%)]\tLoss: 0.403878\n",
            "Train Epoch: 84 [8320/9000 images (92%)]\tLoss: 0.610462\n",
            "Train Epoch: 84 [5600/9000 images (62%)]\tLoss: 0.425601\n",
            "\n",
            "Test set (epoch 84):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.30%\n",
            "    Macro F1-score: 0.3534\n",
            "    Per-pair accuracy (unordered pair): 94.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5266\n",
            "      circles: 0.5435\n",
            "      up     : 0.6484\n",
            "      right  : 0.6387\n",
            "      down   : 0.5909\n",
            "      left   : 0.6812\n",
            "    MAE per class:\n",
            "      squares: 0.3134\n",
            "      circles: 0.3166\n",
            "      up     : 0.3806\n",
            "      right  : 0.3909\n",
            "      down   : 0.3605\n",
            "      left   : 0.4034\n",
            "    RMSE overall: 0.6075\n",
            "    MAE overall: 0.3609\n",
            "\n",
            "  Losses:\n",
            "    cls=2.1003, cnt=0.9329, total=2.5668\n",
            "\n",
            "Train Epoch: 85 [0/9000 images (0%)]\tLoss: 0.306987\n",
            "Train Epoch: 85 [640/9000 images (7%)]\tLoss: 0.542526\n",
            "Train Epoch: 85 [1280/9000 images (14%)]\tLoss: 0.345457\n",
            "Train Epoch: 85 [1920/9000 images (21%)]\tLoss: 0.382689\n",
            "Train Epoch: 85 [2560/9000 images (28%)]\tLoss: 0.362195\n",
            "Train Epoch: 85 [3200/9000 images (36%)]\tLoss: 0.363075\n",
            "Train Epoch: 85 [3840/9000 images (43%)]\tLoss: 0.394240\n",
            "Train Epoch: 85 [4480/9000 images (50%)]\tLoss: 0.298685\n",
            "Train Epoch: 85 [5120/9000 images (57%)]\tLoss: 0.288330\n",
            "Train Epoch: 85 [5760/9000 images (64%)]\tLoss: 0.256979\n",
            "Train Epoch: 85 [6400/9000 images (71%)]\tLoss: 0.434780\n",
            "Train Epoch: 85 [7040/9000 images (78%)]\tLoss: 0.410235\n",
            "Train Epoch: 85 [7680/9000 images (85%)]\tLoss: 0.396521\n",
            "Train Epoch: 85 [8320/9000 images (92%)]\tLoss: 0.446849\n",
            "Train Epoch: 85 [5600/9000 images (62%)]\tLoss: 0.440802\n",
            "\n",
            "Test set (epoch 85):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.10%\n",
            "    Macro F1-score: 0.3537\n",
            "    Per-pair accuracy (unordered pair): 94.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5047\n",
            "      circles: 0.6286\n",
            "      up     : 0.6225\n",
            "      right  : 0.6638\n",
            "      down   : 0.7303\n",
            "      left   : 0.6812\n",
            "    MAE per class:\n",
            "      squares: 0.3201\n",
            "      circles: 0.4330\n",
            "      up     : 0.3764\n",
            "      right  : 0.3799\n",
            "      down   : 0.4232\n",
            "      left   : 0.3850\n",
            "    RMSE overall: 0.6423\n",
            "    MAE overall: 0.3863\n",
            "\n",
            "  Losses:\n",
            "    cls=2.2504, cnt=1.0338, total=2.7673\n",
            "\n",
            "Train Epoch: 86 [0/9000 images (0%)]\tLoss: 0.539188\n",
            "Train Epoch: 86 [640/9000 images (7%)]\tLoss: 0.504327\n",
            "Train Epoch: 86 [1280/9000 images (14%)]\tLoss: 0.264290\n",
            "Train Epoch: 86 [1920/9000 images (21%)]\tLoss: 0.284584\n",
            "Train Epoch: 86 [2560/9000 images (28%)]\tLoss: 0.346162\n",
            "Train Epoch: 86 [3200/9000 images (36%)]\tLoss: 0.255797\n",
            "Train Epoch: 86 [3840/9000 images (43%)]\tLoss: 0.452262\n",
            "Train Epoch: 86 [4480/9000 images (50%)]\tLoss: 0.404423\n",
            "Train Epoch: 86 [5120/9000 images (57%)]\tLoss: 0.472410\n",
            "Train Epoch: 86 [5760/9000 images (64%)]\tLoss: 0.334344\n",
            "Train Epoch: 86 [6400/9000 images (71%)]\tLoss: 0.488506\n",
            "Train Epoch: 86 [7040/9000 images (78%)]\tLoss: 0.429199\n",
            "Train Epoch: 86 [7680/9000 images (85%)]\tLoss: 0.468236\n",
            "Train Epoch: 86 [8320/9000 images (92%)]\tLoss: 0.245746\n",
            "Train Epoch: 86 [5600/9000 images (62%)]\tLoss: 0.324232\n",
            "\n",
            "Test set (epoch 86):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.80%\n",
            "    Macro F1-score: 0.3763\n",
            "    Per-pair accuracy (unordered pair): 95.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5104\n",
            "      circles: 0.5174\n",
            "      up     : 0.6154\n",
            "      right  : 0.6475\n",
            "      down   : 0.5696\n",
            "      left   : 0.6860\n",
            "    MAE per class:\n",
            "      squares: 0.3159\n",
            "      circles: 0.3402\n",
            "      up     : 0.3625\n",
            "      right  : 0.3738\n",
            "      down   : 0.3377\n",
            "      left   : 0.3913\n",
            "    RMSE overall: 0.5946\n",
            "    MAE overall: 0.3536\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9819, cnt=0.9015, total=2.4327\n",
            "\n",
            "Train Epoch: 87 [0/9000 images (0%)]\tLoss: 0.389364\n",
            "Train Epoch: 87 [640/9000 images (7%)]\tLoss: 0.295341\n",
            "Train Epoch: 87 [1280/9000 images (14%)]\tLoss: 0.576149\n",
            "Train Epoch: 87 [1920/9000 images (21%)]\tLoss: 0.219879\n",
            "Train Epoch: 87 [2560/9000 images (28%)]\tLoss: 0.400732\n",
            "Train Epoch: 87 [3200/9000 images (36%)]\tLoss: 0.384258\n",
            "Train Epoch: 87 [3840/9000 images (43%)]\tLoss: 0.573604\n",
            "Train Epoch: 87 [4480/9000 images (50%)]\tLoss: 0.409699\n",
            "Train Epoch: 87 [5120/9000 images (57%)]\tLoss: 0.303311\n",
            "Train Epoch: 87 [5760/9000 images (64%)]\tLoss: 0.374185\n",
            "Train Epoch: 87 [6400/9000 images (71%)]\tLoss: 0.400255\n",
            "Train Epoch: 87 [7040/9000 images (78%)]\tLoss: 0.379140\n",
            "Train Epoch: 87 [7680/9000 images (85%)]\tLoss: 0.458263\n",
            "Train Epoch: 87 [8320/9000 images (92%)]\tLoss: 0.338482\n",
            "Train Epoch: 87 [5600/9000 images (62%)]\tLoss: 0.432389\n",
            "\n",
            "Test set (epoch 87):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.40%\n",
            "    Macro F1-score: 0.3626\n",
            "    Per-pair accuracy (unordered pair): 95.20%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4973\n",
            "      circles: 0.5284\n",
            "      up     : 0.6171\n",
            "      right  : 0.5936\n",
            "      down   : 0.6133\n",
            "      left   : 0.6613\n",
            "    MAE per class:\n",
            "      squares: 0.2914\n",
            "      circles: 0.3178\n",
            "      up     : 0.3725\n",
            "      right  : 0.3561\n",
            "      down   : 0.3532\n",
            "      left   : 0.3695\n",
            "    RMSE overall: 0.5878\n",
            "    MAE overall: 0.3434\n",
            "\n",
            "  Losses:\n",
            "    cls=2.0674, cnt=0.8832, total=2.5090\n",
            "\n",
            "Train Epoch: 88 [0/9000 images (0%)]\tLoss: 0.327181\n",
            "Train Epoch: 88 [640/9000 images (7%)]\tLoss: 0.370520\n",
            "Train Epoch: 88 [1280/9000 images (14%)]\tLoss: 0.300252\n",
            "Train Epoch: 88 [1920/9000 images (21%)]\tLoss: 0.574388\n",
            "Train Epoch: 88 [2560/9000 images (28%)]\tLoss: 0.332483\n",
            "Train Epoch: 88 [3200/9000 images (36%)]\tLoss: 0.255985\n",
            "Train Epoch: 88 [3840/9000 images (43%)]\tLoss: 0.525957\n",
            "Train Epoch: 88 [4480/9000 images (50%)]\tLoss: 0.297937\n",
            "Train Epoch: 88 [5120/9000 images (57%)]\tLoss: 0.304512\n",
            "Train Epoch: 88 [5760/9000 images (64%)]\tLoss: 0.326617\n",
            "Train Epoch: 88 [6400/9000 images (71%)]\tLoss: 0.475264\n",
            "Train Epoch: 88 [7040/9000 images (78%)]\tLoss: 0.291907\n",
            "Train Epoch: 88 [7680/9000 images (85%)]\tLoss: 0.264065\n",
            "Train Epoch: 88 [8320/9000 images (92%)]\tLoss: 0.430117\n",
            "Train Epoch: 88 [5600/9000 images (62%)]\tLoss: 0.430527\n",
            "\n",
            "Test set (epoch 88):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.70%\n",
            "    Macro F1-score: 0.3672\n",
            "    Per-pair accuracy (unordered pair): 95.10%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4996\n",
            "      circles: 0.5141\n",
            "      up     : 0.6024\n",
            "      right  : 0.5820\n",
            "      down   : 0.6877\n",
            "      left   : 0.6695\n",
            "    MAE per class:\n",
            "      squares: 0.3118\n",
            "      circles: 0.3103\n",
            "      up     : 0.3494\n",
            "      right  : 0.3549\n",
            "      down   : 0.3912\n",
            "      left   : 0.3848\n",
            "    RMSE overall: 0.5968\n",
            "    MAE overall: 0.3504\n",
            "\n",
            "  Losses:\n",
            "    cls=2.1554, cnt=0.9061, total=2.6084\n",
            "\n",
            "Train Epoch: 89 [0/9000 images (0%)]\tLoss: 0.368865\n",
            "Train Epoch: 89 [640/9000 images (7%)]\tLoss: 0.416810\n",
            "Train Epoch: 89 [1280/9000 images (14%)]\tLoss: 0.288551\n",
            "Train Epoch: 89 [1920/9000 images (21%)]\tLoss: 0.345853\n",
            "Train Epoch: 89 [2560/9000 images (28%)]\tLoss: 0.419399\n",
            "Train Epoch: 89 [3200/9000 images (36%)]\tLoss: 0.389461\n",
            "Train Epoch: 89 [3840/9000 images (43%)]\tLoss: 0.337323\n",
            "Train Epoch: 89 [4480/9000 images (50%)]\tLoss: 0.369101\n",
            "Train Epoch: 89 [5120/9000 images (57%)]\tLoss: 0.325516\n",
            "Train Epoch: 89 [5760/9000 images (64%)]\tLoss: 0.372503\n",
            "Train Epoch: 89 [6400/9000 images (71%)]\tLoss: 0.392513\n",
            "Train Epoch: 89 [7040/9000 images (78%)]\tLoss: 0.252640\n",
            "Train Epoch: 89 [7680/9000 images (85%)]\tLoss: 0.377074\n",
            "Train Epoch: 89 [8320/9000 images (92%)]\tLoss: 0.349635\n",
            "Train Epoch: 89 [5600/9000 images (62%)]\tLoss: 0.227034\n",
            "\n",
            "Test set (epoch 89):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.40%\n",
            "    Macro F1-score: 0.3753\n",
            "    Per-pair accuracy (unordered pair): 94.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5377\n",
            "      circles: 0.5065\n",
            "      up     : 0.6676\n",
            "      right  : 0.6078\n",
            "      down   : 0.6046\n",
            "      left   : 0.6754\n",
            "    MAE per class:\n",
            "      squares: 0.3117\n",
            "      circles: 0.3075\n",
            "      up     : 0.3898\n",
            "      right  : 0.3858\n",
            "      down   : 0.4069\n",
            "      left   : 0.3854\n",
            "    RMSE overall: 0.6031\n",
            "    MAE overall: 0.3645\n",
            "\n",
            "  Losses:\n",
            "    cls=1.9738, cnt=0.9317, total=2.4396\n",
            "\n",
            "Train Epoch: 90 [0/9000 images (0%)]\tLoss: 0.491955\n",
            "Train Epoch: 90 [640/9000 images (7%)]\tLoss: 0.302217\n",
            "Train Epoch: 90 [1280/9000 images (14%)]\tLoss: 0.428509\n",
            "Train Epoch: 90 [1920/9000 images (21%)]\tLoss: 0.350333\n",
            "Train Epoch: 90 [2560/9000 images (28%)]\tLoss: 0.430576\n",
            "Train Epoch: 90 [3200/9000 images (36%)]\tLoss: 0.358096\n",
            "Train Epoch: 90 [3840/9000 images (43%)]\tLoss: 0.310286\n",
            "Train Epoch: 90 [4480/9000 images (50%)]\tLoss: 0.328065\n",
            "Train Epoch: 90 [5120/9000 images (57%)]\tLoss: 0.353073\n",
            "Train Epoch: 90 [5760/9000 images (64%)]\tLoss: 0.287672\n",
            "Train Epoch: 90 [6400/9000 images (71%)]\tLoss: 0.293780\n",
            "Train Epoch: 90 [7040/9000 images (78%)]\tLoss: 0.459226\n",
            "Train Epoch: 90 [7680/9000 images (85%)]\tLoss: 0.305789\n",
            "Train Epoch: 90 [8320/9000 images (92%)]\tLoss: 0.312238\n",
            "Train Epoch: 90 [5600/9000 images (62%)]\tLoss: 0.277234\n",
            "\n",
            "Test set (epoch 90):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.50%\n",
            "    Macro F1-score: 0.3472\n",
            "    Per-pair accuracy (unordered pair): 93.50%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5068\n",
            "      circles: 0.5284\n",
            "      up     : 0.6098\n",
            "      right  : 0.5937\n",
            "      down   : 0.5912\n",
            "      left   : 0.6674\n",
            "    MAE per class:\n",
            "      squares: 0.3296\n",
            "      circles: 0.3041\n",
            "      up     : 0.3598\n",
            "      right  : 0.3406\n",
            "      down   : 0.3492\n",
            "      left   : 0.3779\n",
            "    RMSE overall: 0.5853\n",
            "    MAE overall: 0.3435\n",
            "\n",
            "  Losses:\n",
            "    cls=2.1559, cnt=0.8769, total=2.5943\n",
            "\n",
            "Train Epoch: 91 [0/9000 images (0%)]\tLoss: 0.406880\n",
            "Train Epoch: 91 [640/9000 images (7%)]\tLoss: 0.307668\n",
            "Train Epoch: 91 [1280/9000 images (14%)]\tLoss: 0.365838\n",
            "Train Epoch: 91 [1920/9000 images (21%)]\tLoss: 0.282162\n",
            "Train Epoch: 91 [2560/9000 images (28%)]\tLoss: 0.253411\n",
            "Train Epoch: 91 [3200/9000 images (36%)]\tLoss: 0.509652\n",
            "Train Epoch: 91 [3840/9000 images (43%)]\tLoss: 0.359819\n",
            "Train Epoch: 91 [4480/9000 images (50%)]\tLoss: 0.250763\n",
            "Train Epoch: 91 [5120/9000 images (57%)]\tLoss: 0.269400\n",
            "Train Epoch: 91 [5760/9000 images (64%)]\tLoss: 0.472756\n",
            "Train Epoch: 91 [6400/9000 images (71%)]\tLoss: 0.348355\n",
            "Train Epoch: 91 [7040/9000 images (78%)]\tLoss: 0.739138\n",
            "Train Epoch: 91 [7680/9000 images (85%)]\tLoss: 0.521363\n",
            "Train Epoch: 91 [8320/9000 images (92%)]\tLoss: 0.260880\n",
            "Train Epoch: 91 [5600/9000 images (62%)]\tLoss: 0.175497\n",
            "\n",
            "Test set (epoch 91):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.60%\n",
            "    Macro F1-score: 0.3551\n",
            "    Per-pair accuracy (unordered pair): 94.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5371\n",
            "      circles: 0.5391\n",
            "      up     : 0.6099\n",
            "      right  : 0.5938\n",
            "      down   : 0.5732\n",
            "      left   : 0.7009\n",
            "    MAE per class:\n",
            "      squares: 0.3108\n",
            "      circles: 0.3183\n",
            "      up     : 0.3679\n",
            "      right  : 0.3767\n",
            "      down   : 0.3420\n",
            "      left   : 0.4071\n",
            "    RMSE overall: 0.5949\n",
            "    MAE overall: 0.3538\n",
            "\n",
            "  Losses:\n",
            "    cls=2.1890, cnt=0.9036, total=2.6408\n",
            "\n",
            "Train Epoch: 92 [0/9000 images (0%)]\tLoss: 0.266089\n",
            "Train Epoch: 92 [640/9000 images (7%)]\tLoss: 0.250145\n",
            "Train Epoch: 92 [1280/9000 images (14%)]\tLoss: 0.400636\n",
            "Train Epoch: 92 [1920/9000 images (21%)]\tLoss: 0.186395\n",
            "Train Epoch: 92 [2560/9000 images (28%)]\tLoss: 0.353438\n",
            "Train Epoch: 92 [3200/9000 images (36%)]\tLoss: 0.408308\n",
            "Train Epoch: 92 [3840/9000 images (43%)]\tLoss: 0.380606\n",
            "Train Epoch: 92 [4480/9000 images (50%)]\tLoss: 0.377995\n",
            "Train Epoch: 92 [5120/9000 images (57%)]\tLoss: 0.376757\n",
            "Train Epoch: 92 [5760/9000 images (64%)]\tLoss: 0.256812\n",
            "Train Epoch: 92 [6400/9000 images (71%)]\tLoss: 0.229123\n",
            "Train Epoch: 92 [7040/9000 images (78%)]\tLoss: 0.328959\n",
            "Train Epoch: 92 [7680/9000 images (85%)]\tLoss: 0.423906\n",
            "Train Epoch: 92 [8320/9000 images (92%)]\tLoss: 0.303337\n",
            "Train Epoch: 92 [5600/9000 images (62%)]\tLoss: 0.331540\n",
            "\n",
            "Test set (epoch 92):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.50%\n",
            "    Macro F1-score: 0.3495\n",
            "    Per-pair accuracy (unordered pair): 93.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5399\n",
            "      circles: 0.5629\n",
            "      up     : 0.6366\n",
            "      right  : 0.5814\n",
            "      down   : 0.5814\n",
            "      left   : 0.6719\n",
            "    MAE per class:\n",
            "      squares: 0.3278\n",
            "      circles: 0.3192\n",
            "      up     : 0.3707\n",
            "      right  : 0.3675\n",
            "      down   : 0.3454\n",
            "      left   : 0.3711\n",
            "    RMSE overall: 0.5974\n",
            "    MAE overall: 0.3503\n",
            "\n",
            "  Losses:\n",
            "    cls=2.1713, cnt=0.9091, total=2.6258\n",
            "\n",
            "Train Epoch: 93 [0/9000 images (0%)]\tLoss: 0.431838\n",
            "Train Epoch: 93 [640/9000 images (7%)]\tLoss: 0.373540\n",
            "Train Epoch: 93 [1280/9000 images (14%)]\tLoss: 0.317698\n",
            "Train Epoch: 93 [1920/9000 images (21%)]\tLoss: 0.444335\n",
            "Train Epoch: 93 [2560/9000 images (28%)]\tLoss: 0.254493\n",
            "Train Epoch: 93 [3200/9000 images (36%)]\tLoss: 0.240394\n",
            "Train Epoch: 93 [3840/9000 images (43%)]\tLoss: 0.365410\n",
            "Train Epoch: 93 [4480/9000 images (50%)]\tLoss: 0.231411\n",
            "Train Epoch: 93 [5120/9000 images (57%)]\tLoss: 0.342728\n",
            "Train Epoch: 93 [5760/9000 images (64%)]\tLoss: 0.520191\n",
            "Train Epoch: 93 [6400/9000 images (71%)]\tLoss: 0.414971\n",
            "Train Epoch: 93 [7040/9000 images (78%)]\tLoss: 0.410001\n",
            "Train Epoch: 93 [7680/9000 images (85%)]\tLoss: 0.271603\n",
            "Train Epoch: 93 [8320/9000 images (92%)]\tLoss: 0.309287\n",
            "Train Epoch: 93 [5600/9000 images (62%)]\tLoss: 0.575767\n",
            "\n",
            "Test set (epoch 93):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.20%\n",
            "    Macro F1-score: 0.3531\n",
            "    Per-pair accuracy (unordered pair): 93.80%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4996\n",
            "      circles: 0.5208\n",
            "      up     : 0.6187\n",
            "      right  : 0.6206\n",
            "      down   : 0.6297\n",
            "      left   : 0.8238\n",
            "    MAE per class:\n",
            "      squares: 0.3265\n",
            "      circles: 0.3109\n",
            "      up     : 0.3777\n",
            "      right  : 0.3873\n",
            "      down   : 0.3982\n",
            "      left   : 0.4588\n",
            "    RMSE overall: 0.6277\n",
            "    MAE overall: 0.3766\n",
            "\n",
            "  Losses:\n",
            "    cls=2.3726, cnt=0.9884, total=2.8668\n",
            "\n",
            "Train Epoch: 94 [0/9000 images (0%)]\tLoss: 0.303380\n",
            "Train Epoch: 94 [640/9000 images (7%)]\tLoss: 0.375849\n",
            "Train Epoch: 94 [1280/9000 images (14%)]\tLoss: 0.302087\n",
            "Train Epoch: 94 [1920/9000 images (21%)]\tLoss: 0.404039\n",
            "Train Epoch: 94 [2560/9000 images (28%)]\tLoss: 0.329971\n",
            "Train Epoch: 94 [3200/9000 images (36%)]\tLoss: 0.226927\n",
            "Train Epoch: 94 [3840/9000 images (43%)]\tLoss: 0.288499\n",
            "Train Epoch: 94 [4480/9000 images (50%)]\tLoss: 0.506964\n",
            "Train Epoch: 94 [5120/9000 images (57%)]\tLoss: 0.371635\n",
            "Train Epoch: 94 [5760/9000 images (64%)]\tLoss: 0.425691\n",
            "Train Epoch: 94 [6400/9000 images (71%)]\tLoss: 0.326410\n",
            "Train Epoch: 94 [7040/9000 images (78%)]\tLoss: 0.304839\n",
            "Train Epoch: 94 [7680/9000 images (85%)]\tLoss: 0.469242\n",
            "Train Epoch: 94 [8320/9000 images (92%)]\tLoss: 0.370654\n",
            "Train Epoch: 94 [5600/9000 images (62%)]\tLoss: 0.478657\n",
            "\n",
            "Test set (epoch 94):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 47.20%\n",
            "    Macro F1-score: 0.3532\n",
            "    Per-pair accuracy (unordered pair): 93.70%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5019\n",
            "      circles: 0.5137\n",
            "      up     : 0.6763\n",
            "      right  : 0.5756\n",
            "      down   : 0.6038\n",
            "      left   : 0.6821\n",
            "    MAE per class:\n",
            "      squares: 0.3042\n",
            "      circles: 0.3024\n",
            "      up     : 0.3982\n",
            "      right  : 0.3454\n",
            "      down   : 0.3623\n",
            "      left   : 0.3850\n",
            "    RMSE overall: 0.5964\n",
            "    MAE overall: 0.3496\n",
            "\n",
            "  Losses:\n",
            "    cls=2.1519, cnt=0.9024, total=2.6031\n",
            "\n",
            "Train Epoch: 95 [0/9000 images (0%)]\tLoss: 0.361802\n",
            "Train Epoch: 95 [640/9000 images (7%)]\tLoss: 0.374850\n",
            "Train Epoch: 95 [1280/9000 images (14%)]\tLoss: 0.332994\n",
            "Train Epoch: 95 [1920/9000 images (21%)]\tLoss: 0.348610\n",
            "Train Epoch: 95 [2560/9000 images (28%)]\tLoss: 0.274278\n",
            "Train Epoch: 95 [3200/9000 images (36%)]\tLoss: 0.291844\n",
            "Train Epoch: 95 [3840/9000 images (43%)]\tLoss: 0.258096\n",
            "Train Epoch: 95 [4480/9000 images (50%)]\tLoss: 0.279379\n",
            "Train Epoch: 95 [5120/9000 images (57%)]\tLoss: 0.500072\n",
            "Train Epoch: 95 [5760/9000 images (64%)]\tLoss: 0.433198\n",
            "Train Epoch: 95 [6400/9000 images (71%)]\tLoss: 0.271534\n",
            "Train Epoch: 95 [7040/9000 images (78%)]\tLoss: 0.279862\n",
            "Train Epoch: 95 [7680/9000 images (85%)]\tLoss: 0.277721\n",
            "Train Epoch: 95 [8320/9000 images (92%)]\tLoss: 0.254270\n",
            "Train Epoch: 95 [5600/9000 images (62%)]\tLoss: 0.272054\n",
            "\n",
            "Test set (epoch 95):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.20%\n",
            "    Macro F1-score: 0.3620\n",
            "    Per-pair accuracy (unordered pair): 93.80%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4948\n",
            "      circles: 0.5045\n",
            "      up     : 0.6496\n",
            "      right  : 0.5922\n",
            "      down   : 0.5887\n",
            "      left   : 0.6902\n",
            "    MAE per class:\n",
            "      squares: 0.3088\n",
            "      circles: 0.2964\n",
            "      up     : 0.3830\n",
            "      right  : 0.3415\n",
            "      down   : 0.3668\n",
            "      left   : 0.3759\n",
            "    RMSE overall: 0.5909\n",
            "    MAE overall: 0.3454\n",
            "\n",
            "  Losses:\n",
            "    cls=2.3112, cnt=0.8879, total=2.7551\n",
            "\n",
            "Train Epoch: 96 [0/9000 images (0%)]\tLoss: 0.272337\n",
            "Train Epoch: 96 [640/9000 images (7%)]\tLoss: 0.422174\n",
            "Train Epoch: 96 [1280/9000 images (14%)]\tLoss: 0.344686\n",
            "Train Epoch: 96 [1920/9000 images (21%)]\tLoss: 0.313446\n",
            "Train Epoch: 96 [2560/9000 images (28%)]\tLoss: 0.286100\n",
            "Train Epoch: 96 [3200/9000 images (36%)]\tLoss: 0.334775\n",
            "Train Epoch: 96 [3840/9000 images (43%)]\tLoss: 0.491656\n",
            "Train Epoch: 96 [4480/9000 images (50%)]\tLoss: 0.212337\n",
            "Train Epoch: 96 [5120/9000 images (57%)]\tLoss: 0.315747\n",
            "Train Epoch: 96 [5760/9000 images (64%)]\tLoss: 0.453670\n",
            "Train Epoch: 96 [6400/9000 images (71%)]\tLoss: 0.284970\n",
            "Train Epoch: 96 [7040/9000 images (78%)]\tLoss: 0.370592\n",
            "Train Epoch: 96 [7680/9000 images (85%)]\tLoss: 0.390398\n",
            "Train Epoch: 96 [8320/9000 images (92%)]\tLoss: 0.240696\n",
            "Train Epoch: 96 [5600/9000 images (62%)]\tLoss: 0.188336\n",
            "\n",
            "Test set (epoch 96):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.60%\n",
            "    Macro F1-score: 0.3709\n",
            "    Per-pair accuracy (unordered pair): 94.00%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5409\n",
            "      circles: 0.5029\n",
            "      up     : 0.5953\n",
            "      right  : 0.5853\n",
            "      down   : 0.5875\n",
            "      left   : 0.6739\n",
            "    MAE per class:\n",
            "      squares: 0.3088\n",
            "      circles: 0.3146\n",
            "      up     : 0.3486\n",
            "      right  : 0.3460\n",
            "      down   : 0.3418\n",
            "      left   : 0.3755\n",
            "    RMSE overall: 0.5834\n",
            "    MAE overall: 0.3392\n",
            "\n",
            "  Losses:\n",
            "    cls=2.2266, cnt=0.8721, total=2.6627\n",
            "\n",
            "Train Epoch: 97 [0/9000 images (0%)]\tLoss: 0.305202\n",
            "Train Epoch: 97 [640/9000 images (7%)]\tLoss: 0.380405\n",
            "Train Epoch: 97 [1280/9000 images (14%)]\tLoss: 0.377789\n",
            "Train Epoch: 97 [1920/9000 images (21%)]\tLoss: 0.196921\n",
            "Train Epoch: 97 [2560/9000 images (28%)]\tLoss: 0.272219\n",
            "Train Epoch: 97 [3200/9000 images (36%)]\tLoss: 0.537023\n",
            "Train Epoch: 97 [3840/9000 images (43%)]\tLoss: 0.343010\n",
            "Train Epoch: 97 [4480/9000 images (50%)]\tLoss: 0.569209\n",
            "Train Epoch: 97 [5120/9000 images (57%)]\tLoss: 0.411207\n",
            "Train Epoch: 97 [5760/9000 images (64%)]\tLoss: 0.507526\n",
            "Train Epoch: 97 [6400/9000 images (71%)]\tLoss: 0.271727\n",
            "Train Epoch: 97 [7040/9000 images (78%)]\tLoss: 0.268292\n",
            "Train Epoch: 97 [7680/9000 images (85%)]\tLoss: 0.254057\n",
            "Train Epoch: 97 [8320/9000 images (92%)]\tLoss: 0.403260\n",
            "Train Epoch: 97 [5600/9000 images (62%)]\tLoss: 0.483142\n",
            "\n",
            "Test set (epoch 97):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 48.50%\n",
            "    Macro F1-score: 0.3616\n",
            "    Per-pair accuracy (unordered pair): 94.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.5155\n",
            "      circles: 0.5285\n",
            "      up     : 0.6050\n",
            "      right  : 0.5931\n",
            "      down   : 0.5909\n",
            "      left   : 0.6650\n",
            "    MAE per class:\n",
            "      squares: 0.2869\n",
            "      circles: 0.3058\n",
            "      up     : 0.3570\n",
            "      right  : 0.3563\n",
            "      down   : 0.3583\n",
            "      left   : 0.3715\n",
            "    RMSE overall: 0.5851\n",
            "    MAE overall: 0.3393\n",
            "\n",
            "  Losses:\n",
            "    cls=2.2617, cnt=0.8778, total=2.7006\n",
            "\n",
            "Train Epoch: 98 [0/9000 images (0%)]\tLoss: 0.368326\n",
            "Train Epoch: 98 [640/9000 images (7%)]\tLoss: 0.278959\n",
            "Train Epoch: 98 [1280/9000 images (14%)]\tLoss: 0.246044\n",
            "Train Epoch: 98 [1920/9000 images (21%)]\tLoss: 0.344758\n",
            "Train Epoch: 98 [2560/9000 images (28%)]\tLoss: 0.287949\n",
            "Train Epoch: 98 [3200/9000 images (36%)]\tLoss: 0.227682\n",
            "Train Epoch: 98 [3840/9000 images (43%)]\tLoss: 0.210084\n",
            "Train Epoch: 98 [4480/9000 images (50%)]\tLoss: 0.387472\n",
            "Train Epoch: 98 [5120/9000 images (57%)]\tLoss: 0.229007\n",
            "Train Epoch: 98 [5760/9000 images (64%)]\tLoss: 0.554994\n",
            "Train Epoch: 98 [6400/9000 images (71%)]\tLoss: 0.325676\n",
            "Train Epoch: 98 [7040/9000 images (78%)]\tLoss: 0.565916\n",
            "Train Epoch: 98 [7680/9000 images (85%)]\tLoss: 0.263024\n",
            "Train Epoch: 98 [8320/9000 images (92%)]\tLoss: 0.474234\n",
            "Train Epoch: 98 [5600/9000 images (62%)]\tLoss: 0.375663\n",
            "\n",
            "Test set (epoch 98):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 46.90%\n",
            "    Macro F1-score: 0.3539\n",
            "    Per-pair accuracy (unordered pair): 93.80%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4862\n",
            "      circles: 0.5147\n",
            "      up     : 0.6018\n",
            "      right  : 0.6755\n",
            "      down   : 0.6227\n",
            "      left   : 0.6790\n",
            "    MAE per class:\n",
            "      squares: 0.2972\n",
            "      circles: 0.3393\n",
            "      up     : 0.3687\n",
            "      right  : 0.3941\n",
            "      down   : 0.3662\n",
            "      left   : 0.3929\n",
            "    RMSE overall: 0.6012\n",
            "    MAE overall: 0.3597\n",
            "\n",
            "  Losses:\n",
            "    cls=2.2593, cnt=0.9212, total=2.7199\n",
            "\n",
            "Train Epoch: 99 [0/9000 images (0%)]\tLoss: 0.314059\n",
            "Train Epoch: 99 [640/9000 images (7%)]\tLoss: 0.414255\n",
            "Train Epoch: 99 [1280/9000 images (14%)]\tLoss: 0.342012\n",
            "Train Epoch: 99 [1920/9000 images (21%)]\tLoss: 0.413217\n",
            "Train Epoch: 99 [2560/9000 images (28%)]\tLoss: 0.370062\n",
            "Train Epoch: 99 [3200/9000 images (36%)]\tLoss: 0.378949\n",
            "Train Epoch: 99 [3840/9000 images (43%)]\tLoss: 0.491520\n",
            "Train Epoch: 99 [4480/9000 images (50%)]\tLoss: 0.320232\n",
            "Train Epoch: 99 [5120/9000 images (57%)]\tLoss: 0.307268\n",
            "Train Epoch: 99 [5760/9000 images (64%)]\tLoss: 0.209748\n",
            "Train Epoch: 99 [6400/9000 images (71%)]\tLoss: 0.448731\n",
            "Train Epoch: 99 [7040/9000 images (78%)]\tLoss: 0.268682\n",
            "Train Epoch: 99 [7680/9000 images (85%)]\tLoss: 0.186191\n",
            "Train Epoch: 99 [8320/9000 images (92%)]\tLoss: 0.193724\n",
            "Train Epoch: 99 [5600/9000 images (62%)]\tLoss: 0.198810\n",
            "\n",
            "Test set (epoch 99):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 49.40%\n",
            "    Macro F1-score: 0.3709\n",
            "    Per-pair accuracy (unordered pair): 94.10%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.4827\n",
            "      circles: 0.5046\n",
            "      up     : 0.6240\n",
            "      right  : 0.6376\n",
            "      down   : 0.5951\n",
            "      left   : 0.6701\n",
            "    MAE per class:\n",
            "      squares: 0.2907\n",
            "      circles: 0.3015\n",
            "      up     : 0.3858\n",
            "      right  : 0.3709\n",
            "      down   : 0.3435\n",
            "      left   : 0.3787\n",
            "    RMSE overall: 0.5897\n",
            "    MAE overall: 0.3452\n",
            "\n",
            "  Losses:\n",
            "    cls=2.3184, cnt=0.8836, total=2.7601\n",
            "\n",
            "Train Epoch: 100 [0/9000 images (0%)]\tLoss: 0.246701\n",
            "Train Epoch: 100 [640/9000 images (7%)]\tLoss: 0.239251\n",
            "Train Epoch: 100 [1280/9000 images (14%)]\tLoss: 0.264311\n",
            "Train Epoch: 100 [1920/9000 images (21%)]\tLoss: 0.291036\n",
            "Train Epoch: 100 [2560/9000 images (28%)]\tLoss: 0.245695\n",
            "Train Epoch: 100 [3200/9000 images (36%)]\tLoss: 0.323295\n",
            "Train Epoch: 100 [3840/9000 images (43%)]\tLoss: 0.317401\n",
            "Train Epoch: 100 [4480/9000 images (50%)]\tLoss: 0.295498\n",
            "Train Epoch: 100 [5120/9000 images (57%)]\tLoss: 0.476833\n",
            "Train Epoch: 100 [5760/9000 images (64%)]\tLoss: 0.352830\n",
            "Train Epoch: 100 [6400/9000 images (71%)]\tLoss: 0.319965\n",
            "Train Epoch: 100 [7040/9000 images (78%)]\tLoss: 0.354442\n",
            "Train Epoch: 100 [7680/9000 images (85%)]\tLoss: 0.342353\n",
            "Train Epoch: 100 [8320/9000 images (92%)]\tLoss: 0.680364\n",
            "Train Epoch: 100 [5600/9000 images (62%)]\tLoss: 0.575993\n",
            "\n",
            "Test set (epoch 100):\n",
            "  Classification (135-way):\n",
            "    Top-1 accuracy: 45.30%\n",
            "    Macro F1-score: 0.3381\n",
            "    Per-pair accuracy (unordered pair): 93.40%\n",
            "\n",
            "  Regression (6-D counts):\n",
            "    RMSE per class:\n",
            "      squares: 0.6164\n",
            "      circles: 0.6370\n",
            "      up     : 0.8654\n",
            "      right  : 0.6226\n",
            "      down   : 0.6160\n",
            "      left   : 0.6981\n",
            "    MAE per class:\n",
            "      squares: 0.3697\n",
            "      circles: 0.4184\n",
            "      up     : 0.4980\n",
            "      right  : 0.3687\n",
            "      down   : 0.3617\n",
            "      left   : 0.4192\n",
            "    RMSE overall: 0.6818\n",
            "    MAE overall: 0.4059\n",
            "\n",
            "  Losses:\n",
            "    cls=2.5721, cnt=1.1452, total=3.1447\n",
            "\n"
          ]
        }
      ]
    }
  ]
}